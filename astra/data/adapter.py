"""
æ•°æ®é€‚é…å±‚ï¼šå°† DynamicGraph è½¬æ¢ä¸ºè‡ªå®šä¹‰å›¾æ ¼å¼

æœ¬æ¨¡å—å®ç° GraphDataConverter ç±»ï¼Œè´Ÿè´£ï¼š
1. å°† parser.py äº§ç”Ÿçš„ DynamicGraph å¯¹è±¡è½¬æ¢ä¸º HeteroGraph åºåˆ—
2. å¤„ç†èŠ‚ç‚¹å’Œè¾¹çš„ç‰¹å¾ç¼–ç ï¼ˆç¦»æ•£ç‰¹å¾ LabelEncoderï¼Œè¿ç»­ç‰¹å¾æ ‡å‡†åŒ–ï¼‰
3. æ„å»ºæ ‡ç­¾ï¼ˆy_agent: æ•…éšœæºèŠ‚ç‚¹åˆ†ç±»ï¼Œy_step: æ•…éšœæ—¶é—´æ­¥å›å½’/åˆ†ç±»ï¼‰
"""

import torch
import numpy as np
import re
from typing import Dict, List, Any, Optional, Tuple
from collections import defaultdict
from sklearn.preprocessing import LabelEncoder, StandardScaler
from astra.data.graph_data import HeteroGraph

# å¯¼å…¥ parser æ¨¡å—ä¸­çš„ç±»å‹
import sys
import os
import importlib.util
from pathlib import Path

# è·å–å½“å‰æ–‡ä»¶çš„ç›®å½•å¹¶æ„å»º parser.py çš„è·¯å¾„
# parser ç°åœ¨åœ¨ astra/parsing/dhcg_parser/ ç›®å½•ä¸‹
current_dir = Path(__file__).parent.absolute()
# ä» astra/data/ å›åˆ° astra/ï¼Œç„¶ååˆ° astra/parsing/dhcg_parser/
astra_dir = current_dir.parent
parser_path = astra_dir / "parsing" / "dhcg_parser" / "parser.py"

# ä½¿ç”¨ importlib ç›´æ¥åŠ è½½æ¨¡å—
if not parser_path.exists():
    raise ImportError(f"Cannot find parser.py at {parser_path}")

spec = importlib.util.spec_from_file_location("dhcg_parser.parser", parser_path)
parser_module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(parser_module)

# ä»æ¨¡å—ä¸­æå–éœ€è¦çš„ç±»
DynamicGraph = parser_module.DynamicGraph
Node = parser_module.Node
Edge = parser_module.Edge


def robust_clean_agent_name(name: str) -> str:
    """
    ç»ˆææ¸…æ´—é€»è¾‘ï¼šå°†åå­—å‹ç¼©ä¸ºæœ€ç®€å½¢å¼ä»¥ä¾¿åŒ¹é…
    ä¾‹å¦‚: "Verification_Expert_0" -> "verificationexpert"
    """
    if not name:
        return ""
    
    # è½¬å­—ç¬¦ä¸²å¹¶è½¬å°å†™
    name = str(name).lower()
    
    # ç§»é™¤æ‹¬å·åŠå†…å®¹
    name = re.sub(r'\s*\(.*?\)', '', name)
    
    # ç§»é™¤æœ«å°¾çš„æ•°å­—åç¼€ (ä¾‹å¦‚ _0, .1)
    name = re.sub(r'[_\.]\d+$', '', name)
    
    # ç§»é™¤æ‰€æœ‰éå­—æ¯æ•°å­—å­—ç¬¦ (ä¸‹åˆ’çº¿ã€ç©ºæ ¼ã€ç‚¹)
    # è¿™ä¸€æ­¥æ˜¯å…³é”®ï¼šè®© "Verification_Expert" å’Œ "VerificationExpert" å˜æˆä¸€æ ·
    name = re.sub(r'[^a-z0-9]', '', name)
    
    return name


class GraphDataConverter:
    """
    å°† DynamicGraph è½¬æ¢ä¸º HeteroGraph åºåˆ—çš„æ•°æ®é€‚é…å™¨
    ä¿®å¤ç‰ˆï¼šå¢åŠ äº† Agent Name Encoding ä»¥è§£å†³ Hand-Crafted æ•°æ®é›†çš„æ³›åŒ–é—®é¢˜
    
    æ¯ä¸ªæ—¶é—´æ­¥ t å¯¹åº”ä¸€ä¸ª HeteroGraph å¿«ç…§ï¼ŒåŒ…å«ï¼š
    - èŠ‚ç‚¹ç‰¹å¾çŸ©é˜µ (node_features)
    - è¾¹ç´¢å¼• (edge_indices)
    - è¾¹ç‰¹å¾ (edge_features)
    - æ ‡ç­¾ (y_agent, y_step)
    
    æ ¸å¿ƒä¿®å¤ï¼šæ˜¾å¼ç¼–ç  Agent åå­—ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤ŸåŒºåˆ†ä¸åŒçš„ Agentï¼ˆå¦‚ WebSurfer vs PythonExpertï¼‰ï¼Œ
    è§£å†³ Zero-Shot åœºæ™¯ä¸‹çš„ Domain Gap é—®é¢˜ã€‚
    """
    
    # èŠ‚ç‚¹ç±»å‹
    NODE_TYPES = ['Agent', 'Tool', 'Artifact', 'Environment']
    
    # è¾¹ç±»å‹ï¼ˆå…ƒç»„æ ¼å¼ï¼š(source_type, edge_type, target_type)ï¼‰
    EDGE_TYPES = [
        ('Agent', 'Invoke', 'Tool'),
        ('Tool', 'Return', 'Agent'),
        ('Agent', 'Reference', 'Artifact'),
        ('Agent', 'Communicate', 'Agent'),
        ('Environment', 'Affect', 'Agent'),
        ('Environment', 'Affect', 'Tool'),
        ('Environment', 'Affect', 'Artifact'),
    ]
    
    def __init__(self, 
                 node_feat_dim: int = 8192,  # ğŸ”¥ Qwen-8B: 4096 (åµŒå…¥) + 4096 (å…ƒæ•°æ®)
                 edge_feat_dim: int = 32,
                 normalize_features: bool = True):
        """
        åˆå§‹åŒ–è½¬æ¢å™¨
        
        Args:
            node_feat_dim: èŠ‚ç‚¹ç‰¹å¾ç»Ÿä¸€ç»´åº¦
            edge_feat_dim: è¾¹ç‰¹å¾ç»´åº¦
            normalize_features: æ˜¯å¦å¯¹è¿ç»­ç‰¹å¾è¿›è¡Œæ ‡å‡†åŒ–
        """
        self.node_feat_dim = node_feat_dim
        self.edge_feat_dim = edge_feat_dim
        self.normalize_features = normalize_features
        
        # èŠ‚ç‚¹ç‰¹å¾ç¼–ç å™¨
        self.node_type_encoder = LabelEncoder()
        # === [æ··åˆç‰¹å¾ç¼–ç ] åŒé‡ Agent ç¼–ç å™¨ ===
        # ID Encoder: ç”¨äºåŒºåˆ†åŒä¸€å›¾ä¸­ä¸åŒçš„ Agent å®ä¾‹ (å¦‚ WebSurfer_0 vs WebSurfer_1)
        self.agent_id_encoder = LabelEncoder()
        # Role Encoder: ç”¨äºè·¨æ•°æ®é›†æ³›åŒ– (å¦‚ WebSurfer è¡¨ç¤ºåŒä¸€è§’è‰²)
        self.agent_role_encoder = LabelEncoder()
        # ======================================
        self.artifact_type_encoder = LabelEncoder()
        self.exitcode_status_encoder = LabelEncoder()
        self.env_event_type_encoder = LabelEncoder()
        
        # è¾¹ç‰¹å¾ç¼–ç å™¨
        self.edge_intent_encoder = LabelEncoder()
        self.edge_status_encoder = LabelEncoder()
        
        # æ ‡å‡†åŒ–å™¨ï¼ˆç”¨äºè¿ç»­ç‰¹å¾ï¼‰
        self.scalers = {
            'active_ratio': StandardScaler(),
            'mention_count': StandardScaler(),
        }
        
        # å­˜å‚¨æ‰€æœ‰å¯èƒ½çš„å€¼ï¼ˆç”¨äº fitï¼‰
        self._node_type_values = set()
        self._agent_id_values = set()      # åŸå§‹ ID (WebSurfer_0)
        self._agent_role_values = set()    # æ¸…æ´—åçš„ Role (WebSurfer)
        self._artifact_type_values = set()
        self._exitcode_status_values = set()
        self._env_event_type_values = set()
        self._edge_intent_values = set()
        self._edge_status_values = set()
        
        # æ˜¯å¦å·²æ‹Ÿåˆç¼–ç å™¨
        self._fitted = False
    
    def fit(self, graphs: List[DynamicGraph]):
        """
        åœ¨æ‰€æœ‰å›¾ä¸Šæ‹Ÿåˆç¼–ç å™¨å’Œæ ‡å‡†åŒ–å™¨
        
        Args:
            graphs: DynamicGraph å¯¹è±¡åˆ—è¡¨
        """
        print("æ­£åœ¨æ”¶é›†æ‰€æœ‰å¯èƒ½çš„å€¼ä»¥æ‹Ÿåˆç¼–ç å™¨ (Hybrid ID + Role)...")
        
        # æ”¶é›†æ‰€æœ‰ç¦»æ•£ç‰¹å¾çš„å¯èƒ½å€¼
        for graph in graphs:
            # èŠ‚ç‚¹ç‰¹å¾
            for node in graph.nodes.values():
                self._node_type_values.add(node.type)
                
                # === [æ··åˆç‰¹å¾ç¼–ç ] åŒæ—¶æ”¶é›† ID å’Œ Role ===
                if node.type == 'Agent':
                    # 1. ID: åŸå§‹ node_id (ç”¨äºåŒºåˆ†å®ä¾‹ï¼Œå¦‚ WebSurfer_0)
                    self._agent_id_values.add(node.id)
                    # 2. Role: æ¸…æ´—åçš„åå­— (ç”¨äºæ³›åŒ–ï¼Œå¦‚ WebSurfer)
                    role = self._clean_agent_name(node.id)
                    self._agent_role_values.add(role)
                # ==========================================
                
                if node.type == 'Artifact':
                    if node.artifact_type:
                        self._artifact_type_values.add(node.artifact_type)
                    # ä¹Ÿä»åŠ¨æ€ç‰¹å¾ä¸­æ”¶é›†
                    for t, features in node.features.items():
                        if 'artifact_type' in features:
                            self._artifact_type_values.add(features['artifact_type'])
                
                # æ”¶é›† Tool çš„ exitcode_status
                for t, features in node.features.items():
                    if node.type == 'Tool' and 'exitcode_status' in features:
                        self._exitcode_status_values.add(features['exitcode_status'])
                    
                    if node.type == 'Environment' and 'env_event_type' in features:
                        self._env_event_type_values.add(features['env_event_type'])
            
            # è¾¹ç‰¹å¾
            for edge in graph.edges:
                if 'intent' in edge.features:
                    self._edge_intent_values.add(edge.features['intent'])
                if 'status' in edge.features:
                    self._edge_status_values.add(edge.features['status'])
        
        # æ‹Ÿåˆç¼–ç å™¨
        if self._node_type_values:
            self.node_type_encoder.fit(list(self._node_type_values))
        
        # === [æ··åˆç‰¹å¾ç¼–ç ] æ‹ŸåˆåŒé‡ Agent ç¼–ç å™¨ ===
        # ID Encoder (éœ€åŒ…å« unknown)
        agent_ids = list(self._agent_id_values)
        if 'unknown' not in agent_ids:
            agent_ids.append('unknown')
        if agent_ids:
            self.agent_id_encoder.fit(agent_ids)
        
        # Role Encoder (éœ€åŒ…å« unknown)
        agent_roles = list(self._agent_role_values)
        if 'unknown' not in agent_roles:
            agent_roles.append('unknown')
        if agent_roles:
            self.agent_role_encoder.fit(agent_roles)
        # ============================================
        
        if self._artifact_type_values:
            self.artifact_type_encoder.fit(list(self._artifact_type_values))
        if self._exitcode_status_values:
            self.exitcode_status_encoder.fit(list(self._exitcode_status_values))
        if self._env_event_type_values:
            self.env_event_type_encoder.fit(list(self._env_event_type_values))
        if self._edge_intent_values:
            self.edge_intent_encoder.fit(list(self._edge_intent_values))
        if self._edge_status_values:
            self.edge_status_encoder.fit(list(self._edge_status_values))
        
        # æ”¶é›†è¿ç»­ç‰¹å¾ç”¨äºæ ‡å‡†åŒ–
        if self.normalize_features:
            active_ratios = []
            mention_counts = []
            
            for graph in graphs:
                for node in graph.nodes.values():
                    for t, features in node.features.items():
                        if node.type == 'Agent' and 'active_ratio' in features:
                            active_ratios.append(features['active_ratio'])
                        if node.type == 'Artifact' and 'mention_count' in features:
                            mention_counts.append(features['mention_count'])
            
            # æ‹Ÿåˆ scalerï¼Œå¦‚æœæ²¡æœ‰æ•°æ®åˆ™ç”¨é»˜è®¤å€¼ [0.0] åˆå§‹åŒ–
            if active_ratios:
                self.scalers['active_ratio'].fit(np.array(active_ratios).reshape(-1, 1))
            else:
                # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œç”¨é»˜è®¤å€¼åˆå§‹åŒ–ï¼Œé¿å…åç»­ä½¿ç”¨æ—¶å‡ºé”™
                self.scalers['active_ratio'].fit(np.array([0.0]).reshape(-1, 1))
            
            if mention_counts:
                self.scalers['mention_count'].fit(np.array(mention_counts).reshape(-1, 1))
            else:
                # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œç”¨é»˜è®¤å€¼åˆå§‹åŒ–ï¼Œé¿å…åç»­ä½¿ç”¨æ—¶å‡ºé”™
                self.scalers['mention_count'].fit(np.array([0.0]).reshape(-1, 1))
        
        self._fitted = True
        id_count = 0
        role_count = 0
        if hasattr(self.agent_id_encoder, 'classes_') and self.agent_id_encoder.classes_ is not None:
            id_count = len(self.agent_id_encoder.classes_)
        if hasattr(self.agent_role_encoder, 'classes_') and self.agent_role_encoder.classes_ is not None:
            role_count = len(self.agent_role_encoder.classes_)
        print(f"âœ“ ç¼–ç å™¨æ‹Ÿåˆå®Œæˆã€‚IDæ•°: {id_count}, Roleæ•°: {role_count}")
    
    def _get_encoder_num_classes(self, encoder, default: int) -> int:
        """
        å®‰å…¨åœ°è·å–ç¼–ç å™¨çš„ç±»åˆ«æ•°é‡
        
        Args:
            encoder: LabelEncoder å¯¹è±¡
            default: å¦‚æœç¼–ç å™¨æœªæ‹Ÿåˆï¼Œè¿”å›çš„é»˜è®¤å€¼
            
        Returns:
            ç±»åˆ«æ•°é‡
        """
        if self._fitted and hasattr(encoder, 'classes_') and encoder.classes_ is not None:
            return len(encoder.classes_)
        return default
    
    def _is_value_in_encoder(self, encoder, value: str) -> bool:
        """
        å®‰å…¨åœ°æ£€æŸ¥å€¼æ˜¯å¦åœ¨ç¼–ç å™¨ä¸­
        
        Args:
            encoder: LabelEncoder å¯¹è±¡
            value: è¦æ£€æŸ¥çš„å€¼
            
        Returns:
            æ˜¯å¦åœ¨ç¼–ç å™¨ä¸­
        """
        if self._fitted and hasattr(encoder, 'classes_') and encoder.classes_ is not None:
            return value in encoder.classes_
        return False
    
    def _is_scaler_fitted(self, scaler_name: str) -> bool:
        """
        æ£€æŸ¥ scaler æ˜¯å¦å·²æ‹Ÿåˆ
        
        Args:
            scaler_name: scaler çš„åç§°ï¼ˆå¦‚ 'active_ratio', 'mention_count'ï¼‰
            
        Returns:
            scaler æ˜¯å¦å·²æ‹Ÿåˆ
        """
        if scaler_name not in self.scalers:
            return False
        scaler = self.scalers[scaler_name]
        # æ£€æŸ¥ scaler æ˜¯å¦æœ‰ mean_ å±æ€§ï¼ˆStandardScaler æ‹Ÿåˆåä¼šæœ‰çš„å±æ€§ï¼‰
        return hasattr(scaler, 'mean_') and scaler.mean_ is not None
    
    def _get_one_hot(self, encoder, value: str, unknown_val: str = 'unknown') -> torch.Tensor:
        """
        è¾…åŠ©æ–¹æ³•ï¼šç”Ÿæˆ One-Hot ç¼–ç å‘é‡
        
        Args:
            encoder: LabelEncoder å¯¹è±¡
            value: è¦ç¼–ç çš„å€¼
            unknown_val: æœªçŸ¥å€¼çš„æ›¿ä»£å€¼
            
        Returns:
            One-Hot ç¼–ç å‘é‡
        """
        num_classes = self._get_encoder_num_classes(encoder, 10)
        vec = torch.zeros(num_classes)
        
        # ç¡®å®šç›®æ ‡å€¼ï¼šå¦‚æœåœ¨ç¼–ç å™¨ä¸­åˆ™ç›´æ¥ä½¿ç”¨ï¼Œå¦åˆ™ä½¿ç”¨ unknown
        target = value if self._is_value_in_encoder(encoder, value) else unknown_val
        
        if self._is_value_in_encoder(encoder, target):
            idx = encoder.transform([target])[0]
            vec[idx] = 1.0
        elif self._fitted and hasattr(encoder, 'classes_') and encoder.classes_ is not None:
            # Fallback: å¦‚æœ unknown åœ¨ç¼–ç å™¨ä¸­ï¼Œä½¿ç”¨ unknown
            if unknown_val in encoder.classes_:
                idx = encoder.transform([unknown_val])[0]
                vec[idx] = 1.0
        
        return vec
    
    def _clean_agent_name(self, raw_name: str) -> str:
        """
        æ¸…æ´— Agent åå­—ï¼Œæå–çœŸæ­£çš„èº«ä»½æ ‡è¯†ï¼ˆå¢å¼ºç‰ˆï¼‰
        
        ğŸ”¥ æ ¸å¿ƒä¿®å¤ï¼š
        1. å»æ‰æ•°å­—åç¼€: WebSurfer_0 -> WebSurfer
        2. å»é™¤æ‹¬å·è¯´æ˜: Orchestrator (-> WebSurfer) -> Orchestrator
        3. å¤„ç†æ‹¬å·ä¸­çš„ç®­å¤´æŒ‡å‘: æå–æ‹¬å·å†…æŒ‡å‘çš„ Agent åå­—ï¼ˆå¦‚æœæœ‰ï¼‰
        
        Args:
            raw_name: åŸå§‹çš„ Agent åå­—ï¼ˆå¯èƒ½æ˜¯ node_idï¼‰
            
        Returns:
            æ¸…æ´—åçš„ Agent åå­—
        """
        if not isinstance(raw_name, str) or not raw_name:
            return str(raw_name) if raw_name else raw_name
        
        name = raw_name
        
        # 1. å¤„ç†æ‹¬å· (é’ˆå¯¹ Orchestrator (-> WebSurfer) è¿™ç§æƒ…å†µ)
        # ç›´æ¥å»æ‰æ‹¬å·åŠé‡Œé¢çš„æ‰€æœ‰å†…å®¹
        if "(" in name:
            name = name.split("(")[0].strip()
        
        # 2. å»æ‰ "_DIGIT" åç¼€ï¼ˆå¦‚ "WebSurfer_1" -> "WebSurfer"ï¼‰
        # ä½†ä¿ç•™ "_" å¼€å¤´çš„æƒ…å†µï¼ˆå¦‚ "_system"ï¼‰
        if "_" in name:
            parts = name.split("_")
            # æ£€æŸ¥æœ€åä¸€ä¸ªéƒ¨åˆ†æ˜¯å¦ä¸ºçº¯æ•°å­—
            if len(parts) > 1 and parts[-1].isdigit():
                # å»æ‰æœ€åä¸€ä¸ªæ•°å­—éƒ¨åˆ†
                clean_name = "_".join(parts[:-1])
                name = clean_name if clean_name else name  # é˜²æ­¢å…¨éƒ¨è¢«å»æ‰
        
        return name.strip()
    
    def _extract_node_features(self, node: Node, t: int) -> torch.Tensor:
        """
        æå–èŠ‚ç‚¹åœ¨æ—¶é—´æ­¥ t çš„ç‰¹å¾å‘é‡
        
        Args:
            node: èŠ‚ç‚¹å¯¹è±¡
            t: æ—¶é—´æ­¥
        
        Returns:
            ç‰¹å¾å‘é‡ (node_feat_dim,)
        """
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šå‘å‰å¡«å……ï¼ˆForward Fillï¼‰ç­–ç•¥
        # å¦‚æœèŠ‚ç‚¹åœ¨æ—¶é—´æ­¥ t æ²¡æœ‰ featuresï¼Œä½¿ç”¨æœ€åä¸€ä¸ªæœ‰æ•ˆæ—¶é—´æ­¥çš„ features
        features = node.features.get(t, {})
        if not features and node.features:
            # æ‰¾åˆ°æœ€åä¸€ä¸ªæœ‰æ•ˆæ—¶é—´æ­¥ï¼ˆ<= tï¼‰
            valid_timesteps = [ts for ts in node.features.keys() if ts <= t]
            if valid_timesteps:
                last_valid_t = max(valid_timesteps)
                features = node.features[last_valid_t]
                # è®°å½•å‘å‰å¡«å……çš„æƒ…å†µï¼ˆç”¨äºè°ƒè¯•ï¼‰
                import os
                debug_file = os.environ.get('HC_EMB_DEBUG_FILE', None)
                if debug_file and node.type == 'Agent':
                    try:
                        with open(debug_file, 'a', encoding='utf-8') as f:
                            f.write(f"FORWARD_FILL: node_id='{node.id}', t={t}, using t={last_valid_t}\n")
                    except:
                        pass
        
        # === [Embedding å›é€€] ç›´æ¥ä½¿ç”¨ JSON è‡ªå¸¦çš„ 384 ç»´ Embedding (Sentence-BERT) ===
        # ä¸å†ä½¿ç”¨ Ollama APIï¼Œç›´æ¥ä½¿ç”¨ parser.py åœ¨è§£ææ—¶ç”Ÿæˆçš„ 384 ç»´ Sentence-BERT embedding
        # JSON æ–‡ä»¶ä¸­çš„ content_embedding å­—æ®µå·²ç»åŒ…å«äº†å®Œæ•´çš„æ–‡æœ¬åµŒå…¥å‘é‡
        emb_list = features.get('content_embedding', [])
        if not emb_list:
            # å¦‚æœæ²¡æœ‰ embeddingï¼Œä½¿ç”¨é›¶å‘é‡
            content_embedding = torch.zeros(384)
            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šè®°å½• Hand-Crafted æ•°æ®çš„é›¶ embedding æƒ…å†µ
            import os
            debug_file = os.environ.get('HC_EMB_DEBUG_FILE', None)
            if debug_file and node.type == 'Agent':
                try:
                    with open(debug_file, 'a', encoding='utf-8') as f:
                        f.write(f"ZERO_EMB: node_id='{node.id}', node_type='{node.type}', t={t}\n")
                except:
                    pass
        else:
            # å°†åˆ—è¡¨è½¬æ¢ä¸º tensor
            if isinstance(emb_list, list):
                content_embedding = torch.tensor(emb_list, dtype=torch.float32)
            else:
                content_embedding = torch.tensor(emb_list, dtype=torch.float32)
            
            # ç¡®ä¿æ˜¯ 384 ç»´ï¼ˆSentence-BERT æ ‡å‡†ç»´åº¦ï¼‰
            if content_embedding.shape[0] != 384:
                if content_embedding.shape[0] < 384:
                    # å¦‚æœç»´åº¦ä¸è¶³ï¼Œç”¨é›¶å¡«å……
                    padding = torch.zeros(384 - content_embedding.shape[0])
                    content_embedding = torch.cat([content_embedding, padding])
                else:
                    # å¦‚æœç»´åº¦è¿‡å¤šï¼Œæˆªæ–­åˆ° 384
                    content_embedding = content_embedding[:384]
            
            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ£€æŸ¥ embedding æ˜¯å¦å…¨ä¸º 0ï¼ˆHand-Crafted æ•°æ®ç‰¹å¾æå–å¤±è´¥ï¼‰
            emb_sum = content_embedding.abs().sum().item()
            is_handcrafted_likely = any(
                keyword in node.id.lower() 
                for keyword in ['surfer', 'orchestrator', 'excel', 'researcher', 'analyst', 'planner', 'executor']
            )
            
            if emb_sum < 1e-6 and node.type == 'Agent':
                import os
                debug_file = os.environ.get('HC_EMB_DEBUG_FILE', None)
                if debug_file:
                    try:
                        with open(debug_file, 'a', encoding='utf-8') as f:
                            f.write(f"NEAR_ZERO_EMB: node_id='{node.id}', emb_sum={emb_sum:.6f}, is_hc_likely={is_handcrafted_likely}\n")
                    except:
                        pass
            
            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šå¯¹äº Hand-Crafted æ•°æ®ï¼Œé¢å¤–æ£€æŸ¥ embedding è´¨é‡
            if is_handcrafted_likely and emb_sum < 0.1:
                # Hand-Crafted æ•°æ®çš„ embedding å¼‚å¸¸å°ï¼Œå¯èƒ½æ˜¯ç‰¹å¾æå–å¤±è´¥
                import os
                debug_file = os.environ.get('HC_EMB_DEBUG_FILE', None)
                if debug_file:
                    try:
                        with open(debug_file, 'a', encoding='utf-8') as f:
                            f.write(f"HC_LOW_EMB: node_id='{node.id}', emb_sum={emb_sum:.6f}, emb_mean={content_embedding.mean().item():.6f}\n")
                    except:
                        pass
        # ==========================================
        
        # 2. èŠ‚ç‚¹ç±»å‹ç¼–ç  (one-hot)
        num_node_types = self._get_encoder_num_classes(self.node_type_encoder, 4)
        node_type_encoded = torch.zeros(num_node_types)
        if self._is_value_in_encoder(self.node_type_encoder, node.type):
            idx = self.node_type_encoder.transform([node.type])[0]
            node_type_encoded[idx] = 1.0
        
        # 3. ç±»å‹ç‰¹å®šç‰¹å¾
        type_specific_features = []
        
        if node.type == 'Agent':
            # === [æ··åˆç‰¹å¾ç¼–ç ] åŒé‡ç¼–ç ï¼šID + Role ===
            raw_name = node.id
            
            # A. Role Feature (æ³›åŒ–è¯­ä¹‰): æ¸…æ´—åçš„åå­—
            role = self._clean_agent_name(raw_name)
            role_vec = self._get_one_hot(self.agent_role_encoder, role)
            
            # B. ID Feature (åŒºåˆ†å®ä¾‹): åŸå§‹ node_id
            id_vec = self._get_one_hot(self.agent_id_encoder, raw_name)
            # ===========================================

            # is_terminate (bool -> float)
            is_terminate = float(features.get('is_terminate', False))
            # plan_signal (bool -> float)
            plan_signal = float(features.get('plan_signal', False))
            # active_ratio (float)
            active_ratio = features.get('active_ratio', 0.0)
            if self.normalize_features and self._is_scaler_fitted('active_ratio'):
                active_ratio = self.scalers['active_ratio'].transform([[active_ratio]])[0, 0]
            
            # æ‹¼æ¥: [å¸¸è§„ç‰¹å¾] + [Role] + [ID]
            type_specific_features = [is_terminate, plan_signal, active_ratio] + role_vec.tolist() + id_vec.tolist()
        
        elif node.type == 'Tool':
            # exitcode_status (one-hot)
            num_exitcode_status = self._get_encoder_num_classes(self.exitcode_status_encoder, 3)
            exitcode_status_encoded = torch.zeros(num_exitcode_status)
            exitcode_status = features.get('exitcode_status', 'unknown')
            if self._is_value_in_encoder(self.exitcode_status_encoder, exitcode_status):
                idx = self.exitcode_status_encoder.transform([exitcode_status])[0]
                exitcode_status_encoded[idx] = 1.0
            type_specific_features = exitcode_status_encoded.tolist()
        
        elif node.type == 'Artifact':
            # artifact_type (one-hot)
            num_artifact_types = self._get_encoder_num_classes(self.artifact_type_encoder, 2)
            artifact_type_encoded = torch.zeros(num_artifact_types)
            artifact_type = features.get('artifact_type', node.artifact_type or 'file')
            if self._is_value_in_encoder(self.artifact_type_encoder, artifact_type):
                idx = self.artifact_type_encoder.transform([artifact_type])[0]
                artifact_type_encoded[idx] = 1.0
            # mention_count (int -> float, normalized)
            mention_count = float(features.get('mention_count', 0))
            if self.normalize_features and self._is_scaler_fitted('mention_count'):
                mention_count = self.scalers['mention_count'].transform([[mention_count]])[0, 0]
            type_specific_features = artifact_type_encoded.tolist() + [mention_count]
        
        elif node.type == 'Environment':
            # env_event_type (one-hot)
            num_env_event_types = self._get_encoder_num_classes(self.env_event_type_encoder, 5)
            env_event_type_encoded = torch.zeros(num_env_event_types)
            env_event_type = features.get('env_event_type', 'none')
            if self._is_value_in_encoder(self.env_event_type_encoder, env_event_type):
                idx = self.env_event_type_encoder.transform([env_event_type])[0]
                env_event_type_encoded[idx] = 1.0
            type_specific_features = env_event_type_encoded.tolist()
        
        # æ‹¼æ¥æ‰€æœ‰ç‰¹å¾
        type_specific_tensor = torch.tensor(type_specific_features, dtype=torch.float32)
        all_features = torch.cat([
            content_embedding,  # 384 (Sentence-BERT from JSON)
            node_type_encoded,  # ~4
            type_specific_tensor  # å¯å˜
        ])
        
        # å¦‚æœç‰¹å¾ç»´åº¦å°äºç›®æ ‡ç»´åº¦ï¼Œç”¨é›¶å¡«å……
        if all_features.shape[0] < self.node_feat_dim:
            padding = torch.zeros(self.node_feat_dim - all_features.shape[0])
            all_features = torch.cat([all_features, padding])
        # å¦‚æœå¤§äºç›®æ ‡ç»´åº¦ï¼Œæˆªæ–­
        elif all_features.shape[0] > self.node_feat_dim:
            all_features = all_features[:self.node_feat_dim]
        
        return all_features
    
    def _extract_edge_features(self, edge: Edge) -> torch.Tensor:
        """
        æå–è¾¹ç‰¹å¾å‘é‡
        
        Args:
            edge: è¾¹å¯¹è±¡
        
        Returns:
            ç‰¹å¾å‘é‡ (edge_feat_dim,)
        """
        features = edge.features
        
        # 1. intent ç¼–ç  (one-hot)
        num_intents = self._get_encoder_num_classes(self.edge_intent_encoder, 5)
        intent_encoded = torch.zeros(num_intents)
        intent = features.get('intent', 'Inform')
        if self._is_value_in_encoder(self.edge_intent_encoder, intent):
            idx = self.edge_intent_encoder.transform([intent])[0]
            intent_encoded[idx] = 1.0
        
        # 2. status ç¼–ç  (one-hot)
        num_statuses = self._get_encoder_num_classes(self.edge_status_encoder, 3)
        status_encoded = torch.zeros(num_statuses)
        status = features.get('status', 'unknown')
        if self._is_value_in_encoder(self.edge_status_encoder, status):
            idx = self.edge_status_encoder.transform([status])[0]
            status_encoded[idx] = 1.0
        
        # æ‹¼æ¥ç‰¹å¾
        edge_features = torch.cat([intent_encoded, status_encoded])
        
        # è°ƒæ•´ç»´åº¦
        if edge_features.shape[0] < self.edge_feat_dim:
            padding = torch.zeros(self.edge_feat_dim - edge_features.shape[0])
            edge_features = torch.cat([edge_features, padding])
        elif edge_features.shape[0] > self.edge_feat_dim:
            edge_features = edge_features[:self.edge_feat_dim]
        
        return edge_features
    
    def convert(self, graph: DynamicGraph) -> Tuple[List[HeteroGraph], Dict[str, Any]]:
        """
        å°†å•ä¸ª DynamicGraph è½¬æ¢ä¸º HeteroGraph åºåˆ—
        
        Args:
            graph: DynamicGraph å¯¹è±¡
        
        Returns:
            (hetero_graph_list, labels_dict)
            - hetero_graph_list: List[HeteroGraph]ï¼Œæ¯ä¸ªå…ƒç´ å¯¹åº”ä¸€ä¸ªæ—¶é—´æ­¥çš„å¿«ç…§
            - labels_dict: åŒ…å« y_agent å’Œ y_step çš„å­—å…¸
        """
        if not self._fitted:
            raise RuntimeError("è½¬æ¢å™¨å°šæœªæ‹Ÿåˆï¼Œè¯·å…ˆè°ƒç”¨ fit() æ–¹æ³•")
        
        # ç¡®å®šæ—¶é—´æ­¥èŒƒå›´
        # max_actual_t: å®é™…æ—¥å¿—ä¸­çš„æœ€å¤§æ—¶é—´æ­¥ï¼ˆæœ‰æ•°æ®çš„æ—¶é—´æ­¥ï¼‰
        max_actual_t = 0
        for edge in graph.edges:
            max_actual_t = max(max_actual_t, edge.timestamp)
        for node in graph.nodes.values():
            if node.features:
                max_actual_t = max(max_actual_t, max(node.features.keys()))
        
        # ä¿®å¤ï¼šæ£€æŸ¥ mistake_step æ˜¯å¦è¶Šç•Œï¼Œå¦‚æœè¶Šç•Œåˆ™æ‰©å±• num_timesteps
        # mistake_step å¯èƒ½åŸºäºå¯¹è¯å†å²ç´¢å¼•ï¼Œè€Œå›¾çš„æ—¶é—´æˆ³å¯èƒ½æ›´çŸ­
        gt = graph.ground_truth
        mistake_step_str = gt.get('mistake_step', '')
        max_t = max_actual_t  # åˆå§‹åŒ–ä¸ºå®é™…æœ€å¤§æ—¶é—´æ­¥
        if mistake_step_str:
            try:
                mistake_step_int = int(mistake_step_str)
                # å¦‚æœ mistake_step è¶…å‡ºå½“å‰èŒƒå›´ï¼Œæ‰©å±• num_timesteps
                if mistake_step_int >= 0 and mistake_step_int >= max_actual_t + 1:
                    max_t = mistake_step_int
            except (ValueError, TypeError):
                pass  # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨åŸæ¥çš„ max_t
        
        num_timesteps = max_t + 1
        
        # æ„å»ºèŠ‚ç‚¹IDåˆ°ç´¢å¼•çš„æ˜ å°„ï¼ˆæŒ‰ç±»å‹åˆ†ç»„ï¼‰
        node_id_to_idx = {}
        node_idx_to_id = {}
        node_type_groups = {nt: [] for nt in self.NODE_TYPES}
        
        for node_id, node in graph.nodes.items():
            node_type = node.type
            if node_type in node_type_groups:
                idx = len(node_type_groups[node_type])
                node_id_to_idx[node_id] = (node_type, idx)
                node_idx_to_id[(node_type, idx)] = node_id
                node_type_groups[node_type].append(node_id)
        
        # ä¸ºæ¯ä¸ªæ—¶é—´æ­¥åˆ›å»º HeteroGraph
        hetero_graph_list = []
        # å­˜å‚¨æœ€åä¸€ä¸ªæœ‰æ•ˆæ—¶é—´æ­¥çš„ç‰¹å¾ï¼ˆç”¨äºå¡«å……æœªæ¥æ—¶é—´æ­¥ï¼‰
        last_valid_features = {}  # Dict[node_type, Tensor]
        last_valid_edges = {}  # Dict[edge_type_tuple, (edge_index, edge_attr)]
        
        for t in range(num_timesteps):
            hetero_graph = HeteroGraph()
            
            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šå¦‚æœ t > max_actual_tï¼Œè¯´æ˜è¿™æ˜¯å¡«å……çš„æœªæ¥æ—¶é—´æ­¥
            # å¤åˆ¶æœ€åä¸€ä¸ªæœ‰æ•ˆæ—¶é—´æ­¥çš„ç‰¹å¾ï¼Œè€Œä¸æ˜¯ä½¿ç”¨å…¨é›¶
            is_padding_step = t > max_actual_t
            
            if is_padding_step:
                # ä½¿ç”¨æœ€åä¸€ä¸ªæœ‰æ•ˆæ—¶é—´æ­¥çš„ç‰¹å¾ï¼ˆæ¨¡æ‹Ÿ"ç³»ç»Ÿå¡æ­»"æˆ–"çŠ¶æ€å»¶ç»­"ï¼‰
                # ä» last_valid_features å¤åˆ¶èŠ‚ç‚¹ç‰¹å¾
                for node_type in self.NODE_TYPES:
                    if node_type in last_valid_features:
                        # æ·±æ‹·è´ç‰¹å¾ï¼Œé¿å…å¼•ç”¨é—®é¢˜
                        hetero_graph.node_features[node_type] = last_valid_features[node_type].clone()
                    else:
                        # å¦‚æœæ²¡æœ‰è¯¥èŠ‚ç‚¹ç±»å‹çš„å†å²ç‰¹å¾ï¼Œä½¿ç”¨ç©ºå¼ é‡
                        hetero_graph.node_features[node_type] = torch.zeros(0, self.node_feat_dim)
                
                # ä» last_valid_edges å¤åˆ¶è¾¹ï¼ˆä½†è¾¹çš„æ—¶é—´æˆ³ä¿¡æ¯ä¸å¤åˆ¶ï¼Œå› ä¸ºè¿™æ˜¯å¡«å……æ­¥ï¼‰
                # æ³¨æ„ï¼šå¡«å……æ­¥é€šå¸¸æ²¡æœ‰æ–°çš„è¾¹ï¼Œæ‰€ä»¥è¿™é‡Œå¯ä»¥é€‰æ‹©ä¸å¤åˆ¶è¾¹ï¼Œæˆ–è€…å¤åˆ¶ä½†æ ‡è®°ä¸ºå†å²è¾¹
                # ä¸ºäº†ç®€åŒ–ï¼Œå¡«å……æ­¥ä¸å¤åˆ¶è¾¹ï¼ˆè¡¨ç¤ºç³»ç»ŸçŠ¶æ€å»¶ç»­ä½†æ²¡æœ‰æ–°äº¤äº’ï¼‰
                # å¦‚æœéœ€è¦ï¼Œå¯ä»¥å–æ¶ˆä¸‹é¢çš„æ³¨é‡Šæ¥å¤åˆ¶è¾¹
                # for edge_type_tuple in self.EDGE_TYPES:
                #     if edge_type_tuple in last_valid_edges:
                #         edge_index, edge_attr = last_valid_edges[edge_type_tuple]
                #         hetero_graph.edge_indices[edge_type_tuple] = edge_index.clone()
                #         hetero_graph.edge_features[edge_type_tuple] = edge_attr.clone()
            else:
                # æ­£å¸¸æ—¶é—´æ­¥ï¼šæå–å®é™…ç‰¹å¾
                # 1. æ·»åŠ èŠ‚ç‚¹ç‰¹å¾
                # ç¡®ä¿æ‰€æœ‰èŠ‚ç‚¹ç±»å‹éƒ½è¢«æ·»åŠ ï¼Œå³ä½¿èŠ‚ç‚¹æ•°ä¸º0ï¼ˆä½¿ç”¨ç©ºå¼ é‡ï¼‰
                for node_type in self.NODE_TYPES:
                    node_ids = node_type_groups[node_type]
                    
                    # ä¸ºæ¯ä¸ªèŠ‚ç‚¹æå–ç‰¹å¾
                    node_features_list = []
                    for node_id in node_ids:
                        node = graph.nodes[node_id]
                        # å¦‚æœèŠ‚ç‚¹åœ¨æ—¶é—´æ­¥ t å­˜åœ¨ï¼Œæå–ç‰¹å¾ï¼›å¦åˆ™ç”¨é›¶å‘é‡
                        if node.created_at <= t:
                            feat = self._extract_node_features(node, t)
                        else:
                            feat = torch.zeros(self.node_feat_dim)
                        node_features_list.append(feat)
                    
                    # å³ä½¿èŠ‚ç‚¹åˆ—è¡¨ä¸ºç©ºï¼Œä¹Ÿæ·»åŠ è¯¥èŠ‚ç‚¹ç±»å‹ï¼ˆä½¿ç”¨ç©ºå¼ é‡ï¼‰
                    # è¿™æ ·ç¡®ä¿æ‰€æœ‰æ—¶é—´æ­¥éƒ½åŒ…å«æ‰€æœ‰èŠ‚ç‚¹ç±»å‹
                    if node_features_list:
                        node_features_tensor = torch.stack(node_features_list)
                        hetero_graph.node_features[node_type] = node_features_tensor
                        # ä¿å­˜æœ€åä¸€ä¸ªæœ‰æ•ˆæ—¶é—´æ­¥çš„ç‰¹å¾
                        last_valid_features[node_type] = node_features_tensor.clone()
                    else:
                        # åˆ›å»ºç©ºå¼ é‡ [0, node_feat_dim]ï¼Œä¿æŒç»´åº¦ä¸€è‡´æ€§
                        hetero_graph.node_features[node_type] = torch.zeros(0, self.node_feat_dim)
                        # ç©ºå¼ é‡ä¹Ÿä¿å­˜ï¼ˆè™½ç„¶ä¸ºç©ºï¼Œä½†ä¿æŒä¸€è‡´æ€§ï¼‰
                        last_valid_features[node_type] = torch.zeros(0, self.node_feat_dim)
                
                # 2. æ·»åŠ è¾¹
                for edge_type_tuple in self.EDGE_TYPES:
                    src_type, edge_type, dst_type = edge_type_tuple
                    
                    # ç­›é€‰å½“å‰æ—¶é—´æ­¥çš„è¾¹
                    edge_indices = []
                    edge_attrs = []
                    
                    for edge in graph.edges:
                        if edge.type == edge_type and edge.timestamp == t:
                            src_node = graph.nodes.get(edge.source)
                            dst_node = graph.nodes.get(edge.target)
                            
                            if src_node and dst_node:
                                src_type_actual = src_node.type
                                dst_type_actual = dst_node.type
                                
                                # æ£€æŸ¥ç±»å‹æ˜¯å¦åŒ¹é…
                                if src_type_actual == src_type and dst_type_actual == dst_type:
                                    src_idx = node_id_to_idx[edge.source][1]
                                    dst_idx = node_id_to_idx[edge.target][1]
                                    
                                    edge_indices.append([src_idx, dst_idx])
                                    edge_attrs.append(self._extract_edge_features(edge))
                    
                    if edge_indices:
                        edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()
                        edge_attr = torch.stack(edge_attrs)
                        hetero_graph.edge_indices[edge_type_tuple] = edge_index
                        hetero_graph.edge_features[edge_type_tuple] = edge_attr
                        # ä¿å­˜æœ€åä¸€ä¸ªæœ‰æ•ˆæ—¶é—´æ­¥çš„è¾¹
                        last_valid_edges[edge_type_tuple] = (edge_index.clone(), edge_attr.clone())
            
            hetero_graph.node_id_to_idx = node_id_to_idx
            hetero_graph_list.append(hetero_graph)
        
        # 3. æ„å»ºæ ‡ç­¾
        labels = self._build_labels(graph, node_id_to_idx, num_timesteps)
        
        return hetero_graph_list, labels
    
    def _build_labels(self, 
                     graph: DynamicGraph, 
                     node_id_to_idx: Dict[str, Tuple[str, int]], 
                     num_timesteps: int) -> Dict[str, Any]:
        """
        æ„å»ºæ ‡ç­¾ (ä¿®å¤ç‰ˆ V4ï¼šæ— è§†ç±»å‹çš„å¼ºåˆ¶åŒ¹é…)
        """
        gt = graph.ground_truth
        mistake_agent_str = gt.get('mistake_agent')
        mistake_step_str = gt.get('mistake_step')
        
        # 1. æ£€æŸ¥ Healed
        is_healed = (mistake_agent_str is None or 
                    (isinstance(mistake_agent_str, str) and not mistake_agent_str.strip()))
        
        if is_healed:
            return {
                'y_agent': -100,
                'y_step': -100,
                'mistake_agent_name': '',
                'mistake_step_str': '',
            }
        
        # 2. Agent åŒ¹é… (ç»ˆæä¿®å¤ï¼šä¸å†è¿‡æ»¤ node_type)
        y_agent = -1
        target_clean = robust_clean_agent_name(mistake_agent_str)
        
        # ç­–ç•¥ A: åœ¨æ‰€æœ‰èŠ‚ç‚¹ä¸­å¯»æ‰¾ï¼ˆä¸ä»…ä»…æ˜¯ Agent ç±»å‹çš„èŠ‚ç‚¹ï¼‰
        # å› ä¸ºæœ‰æ—¶å€™ Tool æˆ– Environment ä¹Ÿä¼šè¢«è¯¯æ ‡ä¸º Agent
        best_match_idx = -1
        best_match_score = 0
        
        for node_id, (node_type, idx) in node_id_to_idx.items():
            # åªè€ƒè™‘ Agent ç±»å‹çš„èŠ‚ç‚¹ä½œä¸ºå€™é€‰ï¼Œé™¤éå®Œå…¨åŒ¹é…å¤±è´¥
            is_agent_type = (node_type == 'Agent')
            
            current_clean = robust_clean_agent_name(node_id)
            
            # 1. ç²¾ç¡®åŒ¹é… (æœ€é«˜ä¼˜å…ˆçº§)
            if current_clean == target_clean:
                if is_agent_type:
                    y_agent = idx
                    break # æ‰¾åˆ°å®Œç¾çš„ Agentï¼Œç›´æ¥é€€å‡º
                else:
                    # æ‰¾åˆ°äº†åå­—å¯¹çš„ï¼Œä½†ç±»å‹ä¸æ˜¯ Agentï¼Œæš‚å­˜
                    if best_match_score < 3:
                        best_match_score = 3
                        best_match_idx = idx
            
            # 2. åŒ…å«åŒ¹é… (User in UserProxy)
            elif (target_clean in current_clean or current_clean in target_clean) and is_agent_type:
                if best_match_score < 2:
                    best_match_score = 2
                    best_match_idx = idx
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å®Œç¾åŒ¹é… (y_agent == -1)ï¼Œä½¿ç”¨æœ€ä½³å¤‡é€‰
        if y_agent == -1 and best_match_idx != -1:
            y_agent = best_match_idx
            # print(f"âš ï¸ [Fuzzy Match] '{mistake_agent_str}' -> Node Index {y_agent} (Score: {best_match_score})")

        # 3. Step åŒ¹é… (ä¿æŒä¸å˜)
        y_step = -1
        if mistake_step_str is not None:
            try:
                # æœ‰äº› step æ˜¯ "Step 13"ï¼Œéœ€è¦æ¸…æ´—
                step_val_str = str(mistake_step_str).lower().replace('step', '').strip()
                val = int(float(step_val_str)) # å¤„ç† "13.0"
                if 0 <= val < num_timesteps:
                    y_step = val
                else:
                    # å¦‚æœè¶Šç•Œï¼Œæˆªæ–­åˆ°æœ€åä¸€æ­¥ (é˜²æ­¢ Loss NaN)
                    y_step = min(val, num_timesteps - 1)
            except (ValueError, TypeError):
                y_step = -1

        # ğŸš¨ æœ€ç»ˆä¿åº•æ£€æŸ¥ï¼šå¦‚æœæ˜¯ Fatal æ ·æœ¬ä½†æ²¡åŒ¹é…åˆ° Agentï¼Œè®°å½•è¯¦ç»†ä¿¡æ¯
        if not is_healed and y_agent == -1:
            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šè®°å½• Hand-Crafted æ•°æ®çš„åŒ¹é…å¤±è´¥ä¿¡æ¯ï¼ˆç”¨äºè¯Šæ–­ï¼‰
            # æ£€æŸ¥æ˜¯å¦æ˜¯ Hand-Crafted æ•°æ®ï¼ˆé€šè¿‡ ground_truth æˆ–å…¶ä»–æ–¹å¼åˆ¤æ–­ï¼‰
            # è¿™é‡Œæˆ‘ä»¬è®°å½•æ‰€æœ‰åŒ¹é…å¤±è´¥çš„æƒ…å†µï¼Œåç»­å¯ä»¥é€šè¿‡æ—¥å¿—åˆ†æ
            import os
            debug_file = os.environ.get('HC_DEBUG_FILE', None)
            if debug_file:
                try:
                    with open(debug_file, 'a', encoding='utf-8') as f:
                        f.write(f"MATCH_FAILED: mistake_agent='{mistake_agent_str}', "
                               f"target_clean='{target_clean}', "
                               f"available_nodes={list(node_id_to_idx.keys())[:10]}\n")
                except:
                    pass
            # è¿™ç§æƒ…å†µéå¸¸å±é™©ï¼Œä¼šå¯¼è‡´ Loss è®¡ç®—è¢«å¿½ç•¥
            # ä½†ä¸ºäº†é¿å…æ—¥å¿—è¿‡å¤šï¼Œæˆ‘ä»¬åªåœ¨ç‰¹å®šæ¡ä»¶ä¸‹æ‰“å°

        return {
            'y_agent': y_agent if y_agent != -1 else -100, # å¦‚æœå®åœ¨æ²¡æ‰¾åˆ°ï¼Œè®¾ä¸º -100 å¿½ç•¥
            'y_step': y_step,
            'mistake_agent_name': mistake_agent_str if mistake_agent_str else '',
            'mistake_step_str': mistake_step_str if mistake_step_str else '',
            'matched_node_idx': y_agent
        }


def reconstruct_graph_from_json(json_data: Dict[str, Any]) -> DynamicGraph:
    """
    ä» JSON æ•°æ®é‡å»º DynamicGraph å¯¹è±¡ (ä¿®å¤ç‰ˆ V3ï¼šç»ˆæå…³é”®è¯è¦†ç›–)
    """
    # ğŸ”¥ æ ¸å¿ƒä¿®å¤ A: æ‰©å……å¼ºåˆ¶è½¬æ­£çš„å…³é”®è¯åˆ—è¡¨ï¼ˆå®šä¹‰åœ¨å‡½æ•°å¼€å¤´ï¼Œä¾›æ•´ä¸ªå‡½æ•°ä½¿ç”¨ï¼‰
    # åªè¦åå­—é‡ŒåŒ…å«è¿™äº›è¯ï¼Œä¸€å¾‹è§†ä¸º Agentï¼Œç¡®ä¿èƒ½è¢«æ ‡ç­¾åŒ¹é…åˆ°
    agent_keywords = [
        "expert", "orchestrator", "user", "agent", # åŸæœ‰è¯
        "terminal", "coder", "analyst", "surfer", "assistant", "planner", "executor" # æ–°å¢è¯
    ]
    
    # 1. åˆ›å»º DynamicGraph å¯¹è±¡
    question = json_data.get('question', '')
    ground_truth_raw = json_data.get('ground_truth', {})
    
    # ğŸ”¥ ä¿®å¤ï¼šå¤„ç† ground_truth å¯èƒ½æ˜¯å­—ç¬¦ä¸²çš„æƒ…å†µ
    # å¦‚æœ ground_truth æ˜¯å­—ç¬¦ä¸²ï¼Œåˆ™ä» JSON é¡¶å±‚æå–å­—æ®µæ„å»ºå­—å…¸
    if isinstance(ground_truth_raw, str):
        ground_truth = {
            'mistake_agent': json_data.get('mistake_agent', ''),
            'mistake_step': json_data.get('mistake_step', ''),
            'mistake_reason': json_data.get('mistake_reason', ''),
            'ground_truth': ground_truth_raw
        }
    elif isinstance(ground_truth_raw, dict):
        # å¦‚æœå·²ç»æ˜¯å­—å…¸ï¼Œç¡®ä¿åŒ…å«æ‰€æœ‰å¿…è¦å­—æ®µ
        ground_truth = {
            'mistake_agent': ground_truth_raw.get('mistake_agent', json_data.get('mistake_agent', '')),
            'mistake_step': ground_truth_raw.get('mistake_step', json_data.get('mistake_step', '')),
            'mistake_reason': ground_truth_raw.get('mistake_reason', json_data.get('mistake_reason', '')),
            'ground_truth': ground_truth_raw.get('ground_truth', ground_truth_raw)
        }
    else:
        # å¦‚æœæ—¢ä¸æ˜¯å­—ç¬¦ä¸²ä¹Ÿä¸æ˜¯å­—å…¸ï¼Œå°è¯•ä»é¡¶å±‚æå–
        ground_truth = {
            'mistake_agent': json_data.get('mistake_agent', ''),
            'mistake_step': json_data.get('mistake_step', ''),
            'mistake_reason': json_data.get('mistake_reason', ''),
            'ground_truth': str(ground_truth_raw) if ground_truth_raw else ''
        }
    
    graph = DynamicGraph(question=question, ground_truth=ground_truth)
    
    # 2. é‡å»ºèŠ‚ç‚¹ (ä» nodes åˆ—è¡¨)
    nodes_data = json_data.get('nodes', {})
    for node_id, node_data in nodes_data.items():
        original_type = node_data.get('type', 'Agent')
        created_at = node_data.get('created_at', 0)
        artifact_type = node_data.get('artifact_type', None)
        
        lower_id = node_id.lower()
        
        if any(keyword in lower_id for keyword in agent_keywords):
            final_type = 'Agent'
        else:
            final_type = original_type
            
        node = Node(
            node_id=node_id,
            node_type=final_type,
            creation_time=created_at,
            artifact_type=artifact_type
        )
        
        # é‡å»º features
        features_data = node_data.get('features', {})
        for t_str, feat_dict in features_data.items():
            try:
                t = int(t_str)
                node.features[t] = feat_dict
            except (ValueError, TypeError):
                continue
        
        graph.add_node(node)
    
    # 3. é‡å»ºè¾¹ & è‡ªåŠ¨å¤æ´»ç¼ºå¤±çš„å¹½çµèŠ‚ç‚¹
    edges_data = json_data.get('edges', [])
    for edge_data in edges_data:
        source = edge_data.get('source', '')
        target = edge_data.get('target', '')
        edge_type = edge_data.get('type', 'Communicate')
        timestamp = edge_data.get('timestamp', 0)
        features = edge_data.get('features', {})
        
        # ğŸ”¥ æ ¸å¿ƒä¿®å¤ B: æ£€æŸ¥ source/target æ˜¯å¦å·²å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™è‡ªåŠ¨åˆ›å»º
        # åŒæ ·åº”ç”¨å¼ºåˆ¶ä¿®æ­£é€»è¾‘
        if source and source not in graph.nodes:
            lower_s = source.lower()
            ghost_type = 'Agent' if any(k in lower_s for k in agent_keywords) else 'Agent' # é»˜è®¤å¹½çµç”±äºä¹Ÿæ˜¯GTæŒ‡æ§å¯¹è±¡ï¼Œå€¾å‘äºè®¾ä¸ºAgent
            graph.add_node(Node(node_id=source, node_type=ghost_type, creation_time=0))
            
        if target and target not in graph.nodes:
            lower_t = target.lower()
            ghost_type = 'Agent' if any(k in lower_t for k in agent_keywords) else 'Agent'
            graph.add_node(Node(node_id=target, node_type=ghost_type, creation_time=0))

        # åˆ›å»ºè¾¹
        edge = Edge(
            source_id=source,
            target_id=target,
            edge_type=edge_type,
            timestamp=timestamp,
            features=features
        )
        graph.add_edge(edge)
    
    # 4. GT å¤æ´»ä¿åº•
    mistake_agent = ground_truth.get('mistake_agent')
    if mistake_agent and mistake_agent not in graph.nodes:
        # GT æŒ‡æ§çš„ä¸€å®šæ˜¯ Agent
        graph.add_node(Node(node_id=mistake_agent, node_type='Agent', creation_time=0))

    return graph


def test_data_adapter():
    """æµ‹è¯•æ•°æ®é€‚é…å™¨"""
    import json
    from pathlib import Path
    
    # æŸ¥æ‰¾å¯ç”¨çš„æµ‹è¯•æ–‡ä»¶ï¼ˆä½¿ç”¨æ–°çš„å‘½åæ ¼å¼ï¼‰
    output_dir = Path("outputs")
    test_file = None
    
    # ä¼˜å…ˆæŸ¥æ‰¾ Algorithm-Generated æ–‡ä»¶
    for pattern in ["Algorithm-Generated_*_graph.json", "Hand-Crafted_*_graph.json"]:
        files = sorted(output_dir.glob(pattern))
        if files:
            test_file = files[0]
            break
    
    if test_file is None or not test_file.exists():
        print(f"æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·ç¡®ä¿ outputs ç›®å½•ä¸‹æœ‰ Algorithm-Generated_*_graph.json æˆ– Hand-Crafted_*_graph.json æ–‡ä»¶")
        return
    
    print(f"ä½¿ç”¨æµ‹è¯•æ–‡ä»¶: {test_file}")
    
    with open(test_file, 'r', encoding='utf-8') as f:
        graph_data = json.load(f)
    
    # ä» JSON æ•°æ®é‡å»º DynamicGraphï¼ˆä¸å†ä½¿ç”¨ MainParserï¼‰
    graph = reconstruct_graph_from_json(graph_data)
    
    print(f"åŠ è½½çš„å›¾: {graph}")
    print(f"èŠ‚ç‚¹æ•°: {len(graph.nodes)}")
    print(f"è¾¹æ•°: {len(graph.edges)}")
    
    # åˆ›å»ºè½¬æ¢å™¨
    converter = GraphDataConverter(node_feat_dim=4096, edge_feat_dim=32)  # ğŸ”¥ å¿…é¡»æ”¹æˆ 4096ï¼(æ¶µç›– 3635 éœ€æ±‚)
    
    # æ‹Ÿåˆï¼ˆä½¿ç”¨å•ä¸ªå›¾ï¼‰
    converter.fit([graph])
    
    # è½¬æ¢
    hetero_graph_list, labels = converter.convert(graph)
    
    print(f"\nè½¬æ¢ç»“æœ:")
    print(f"æ—¶é—´æ­¥æ•°: {len(hetero_graph_list)}")
    print(f"æ ‡ç­¾: {labels}")
    
    # æ£€æŸ¥ç¬¬ä¸€ä¸ªæ—¶é—´æ­¥çš„æ•°æ®
    if hetero_graph_list:
        first_snapshot = hetero_graph_list[0]
        print(f"\nç¬¬ä¸€ä¸ªæ—¶é—´æ­¥çš„å¿«ç…§:")
        print(f"èŠ‚ç‚¹ç±»å‹: {first_snapshot.get_node_types()}")
        print(f"è¾¹ç±»å‹: {first_snapshot.get_edge_types()}")
        for node_type in first_snapshot.get_node_types():
            if node_type in first_snapshot.node_features:
                print(f"  {node_type}: {first_snapshot.node_features[node_type].shape}")


if __name__ == "__main__":
    test_data_adapter()
