"""
é˜¶æ®µä¸‰è¯„ä¼°è„šæœ¬ï¼šCoarse-to-Fine ç³»ç»Ÿé›†æˆè¯„ä¼°
å®ç°å®Œæ•´çš„ GNN + LLM æµç¨‹ï¼Œå¹¶åœ¨åŸå§‹æµ‹è¯•é›†ä¸Šè®¡ç®—å‡†ç¡®ç‡

æµç¨‹ï¼š
1. GNN é¢„æµ‹ Top-K å€™é€‰Agent
2. æå–å€™é€‰Agentçš„æ—¥å¿—
3. LLM åˆ†ææ—¥å¿—å¹¶è¾“å‡ºæœ€ç»ˆæŠ¥å‘Š
4. è®¡ç®— Agent å’Œ Step å‡†ç¡®ç‡
"""
import torch
import json
import re
from pathlib import Path
from tqdm import tqdm
import numpy as np
from typing import Dict, List, Tuple, Optional
from datetime import datetime
import argparse
import os

# GNN ç›¸å…³
from astra.model.gnn import ASTRAMoE
from astra.data.adapter import GraphDataConverter, reconstruct_graph_from_json
from astra.training.train_gnn import collate_fn, compute_metrics
from torch.utils.data import DataLoader

# LLM ç›¸å…³
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel

# æ—¥å¿—æå–
from astra.training.prep_llm_data import extract_agent_logs, format_instruction_for_stage2

# ============================================================================
# Token ç»Ÿè®¡å™¨
# ============================================================================
class TokenCounter:
    """Tokenä½¿ç”¨ç»Ÿè®¡å™¨"""
    def __init__(self):
        self.reset()
    
    def reset(self):
        """é‡ç½®ç»Ÿè®¡"""
        self.llm_input_tokens = 0
        self.llm_output_tokens = 0
        self.llm_total_tokens = 0
        self.llm_calls = 0
        
    def add_llm_call(self, input_tokens: int, output_tokens: int):
        """è®°å½•ä¸€æ¬¡LLMè°ƒç”¨"""
        self.llm_input_tokens += input_tokens
        self.llm_output_tokens += output_tokens
        self.llm_total_tokens += (input_tokens + output_tokens)
        self.llm_calls += 1
    
    def get_summary(self) -> dict:
        """è·å–ç»Ÿè®¡æ‘˜è¦"""
        return {
            'llm_calls': self.llm_calls,
            'llm_input_tokens': self.llm_input_tokens,
            'llm_output_tokens': self.llm_output_tokens,
            'llm_total_tokens': self.llm_total_tokens,
            'avg_input_tokens_per_call': self.llm_input_tokens / self.llm_calls if self.llm_calls > 0 else 0,
            'avg_output_tokens_per_call': self.llm_output_tokens / self.llm_calls if self.llm_calls > 0 else 0,
            'avg_total_tokens_per_call': self.llm_total_tokens / self.llm_calls if self.llm_calls > 0 else 0
        }
    
    def print_summary(self):
        """æ‰“å°ç»Ÿè®¡æ‘˜è¦"""
        summary = self.get_summary()
        print("\n" + "="*80)
        print("ğŸ“Š Token ä½¿ç”¨ç»Ÿè®¡æŠ¥å‘Š")
        print("="*80)
        print(f"LLM è°ƒç”¨æ¬¡æ•°:           {summary['llm_calls']:,}")
        print(f"LLM è¾“å…¥ Token æ€»æ•°:     {summary['llm_input_tokens']:,}")
        print(f"LLM è¾“å‡º Token æ€»æ•°:     {summary['llm_output_tokens']:,}")
        print(f"LLM æ€» Token æ•°:         {summary['llm_total_tokens']:,}")
        print(f"å¹³å‡æ¯æ¬¡è¾“å…¥ Token:      {summary['avg_input_tokens_per_call']:.2f}")
        print(f"å¹³å‡æ¯æ¬¡è¾“å‡º Token:      {summary['avg_output_tokens_per_call']:.2f}")
        print(f"å¹³å‡æ¯æ¬¡æ€» Token:        {summary['avg_total_tokens_per_call']:.2f}")
        print("="*80 + "\n")

# å…¨å±€Tokenç»Ÿè®¡å™¨
token_counter = TokenCounter()


def load_gnn_model(checkpoint_path: str, converter_path: str, device: torch.device):
    """åŠ è½½ GNN æ¨¡å‹"""
    print(f"ğŸ“¥ åŠ è½½ GNN æ¨¡å‹: {checkpoint_path}")
    
    # åŠ è½½æ£€æŸ¥ç‚¹
    # ä¿®æ”¹å âœ”ï¸ æ ¸å¿ƒæ”¹åŠ¨ï¼šå¢åŠ   weights_only=False
    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)
    
    # è·å–æ¨¡å‹é…ç½®ï¼ˆä»æ£€æŸ¥ç‚¹è¯»å–ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤å€¼ï¼‰
    # æ£€æŸ¥ç‚¹å¯èƒ½æœ‰ä¸¤ç§æ ¼å¼ï¼šç›´æ¥ model_config æˆ–åµŒå¥—åœ¨ config ä¸­
    if 'config' in checkpoint and 'model_config' in checkpoint['config']:
        model_config = checkpoint['config']['model_config']
    else:
        model_config = checkpoint.get('model_config', {})
    
    # ä» state_dict æ¨æ–­å®é™…é…ç½®ï¼ˆå¦‚æœé…ç½®ä¸å®Œæ•´æˆ–ä¸åŒ¹é…ï¼‰
    state_dict = checkpoint.get('model_state_dict', checkpoint)
    
    # ä» state_dict æ¨æ–­ num_classesï¼ˆä» moe_head.experts.0.3.weight çš„å½¢çŠ¶ï¼‰
    num_classes = model_config.get('num_classes', 1)
    if 'moe_head.experts.0.3.weight' in state_dict:
        inferred_num_classes = state_dict['moe_head.experts.0.3.weight'].shape[0]
        if inferred_num_classes != num_classes:
            print(f"   âš ï¸  ä» state_dict æ¨æ–­ num_classes: {inferred_num_classes} (é…ç½®ä¸­ä¸º {num_classes})")
            num_classes = inferred_num_classes
    
    # ä» state_dict æ¨æ–­ meta_mlp è¾“å…¥ç»´åº¦ï¼Œç„¶ååæ¨ node_feat_dim
    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ ¹æ®text_projçš„ç»´åº¦æ¨æ–­text_dimï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç 384
    node_feat_dim = model_config.get('node_feat_dim', 8192)
    
    # é¦–å…ˆä»text_projæ¨æ–­text_dim
    text_dim = 4096  # é»˜è®¤å€¼ï¼šQwen-8B
    text_proj_key = None
    for key in state_dict.keys():
        if 'text_proj' in key and 'weight' in key:
            text_proj_key = key
            break
    
    if text_proj_key:
        inferred_text_dim = state_dict[text_proj_key].shape[1]
        text_dim = inferred_text_dim
        print(f"   âœ… ä» state_dict æ¨æ–­ text_dim: {text_dim} (text_projè¾“å…¥ç»´åº¦, é”®: {text_proj_key})")
    else:
        print(f"   âš ï¸  æœªæ‰¾åˆ°text_proj.weightï¼Œä½¿ç”¨é»˜è®¤text_dim: {text_dim}")
        # å°è¯•ä»model_configè¯»å–
        if 'text_dim' in model_config:
            text_dim = model_config['text_dim']
            print(f"   âœ… ä»model_configè¯»å–text_dim: {text_dim}")
    
    # ç„¶åä»meta_mlpæ¨æ–­meta_dimï¼Œå¹¶è®¡ç®—node_feat_dim
    meta_mlp_key = None
    for key in state_dict.keys():
        if 'meta_mlp' in key and '.0.weight' in key:
            meta_mlp_key = key
            break
    
    if meta_mlp_key:
        inferred_meta_dim = state_dict[meta_mlp_key].shape[1]
        inferred_node_feat_dim = inferred_meta_dim + text_dim
        print(f"   âœ… ä» state_dict æ¨æ–­ meta_dim: {inferred_meta_dim} (é”®: {meta_mlp_key})")
        print(f"   âœ… è®¡ç®—çš„ node_feat_dim: {inferred_node_feat_dim} = {inferred_meta_dim} (meta) + {text_dim} (text)")
        
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨ä»state_dictæ¨æ–­çš„å€¼ï¼Œå› ä¸ºå®ƒåæ˜ å®é™…çš„æ¨¡å‹ç»“æ„
        if inferred_node_feat_dim != node_feat_dim:
            print(f"   âš ï¸  ä» state_dict æ¨æ–­çš„ node_feat_dim ({inferred_node_feat_dim}) ä¸é…ç½®ä¸­çš„ ({node_feat_dim}) ä¸åŒï¼Œä½¿ç”¨æ¨æ–­å€¼")
            node_feat_dim = inferred_node_feat_dim
    else:
        print(f"   âš ï¸  æœªæ‰¾åˆ°meta_mlp.0.weightï¼Œä½¿ç”¨é…ç½®ä¸­çš„node_feat_dim: {node_feat_dim}")
    
    # ä»æ£€æŸ¥ç‚¹è¯»å–å…¶ä»–é…ç½®å‚æ•°
    edge_feat_dim = model_config.get('edge_feat_dim', 32)
    max_agents = model_config.get('max_agents', 50)
    max_seq_len = model_config.get('max_seq_len', 50)
    d_model = model_config.get('d_model', 256)
    num_hgt_layers = model_config.get('num_hgt_layers', 2)
    num_heads = model_config.get('num_heads', 4)
    num_experts = model_config.get('num_experts', 4)
    num_temporal_layers = model_config.get('num_temporal_layers', 2)
    dropout = model_config.get('dropout', 0.5)
    
    # ğŸ”¥ ä» state_dict æ¨æ–­ num_hgt_layersï¼ˆSTGAT å±‚æ•°ï¼‰
    # æ£€æŸ¥ spatial_encoder.stgat.layers.X çš„æœ€å¤§ç´¢å¼•
    max_layer_idx = -1
    for key in state_dict.keys():
        if 'spatial_encoder.stgat.layers.' in key:
            # æå–å±‚ç´¢å¼•ï¼Œä¾‹å¦‚ "spatial_encoder.stgat.layers.1.spatial_attn.query.weight" -> 1
            parts = key.split('spatial_encoder.stgat.layers.')
            if len(parts) > 1:
                layer_idx_str = parts[1].split('.')[0]
                try:
                    layer_idx = int(layer_idx_str)
                    max_layer_idx = max(max_layer_idx, layer_idx)
                except ValueError:
                    pass
    
    if max_layer_idx >= 0:
        inferred_num_hgt_layers = max_layer_idx + 1  # å±‚ç´¢å¼•ä»0å¼€å§‹ï¼Œæ‰€ä»¥+1
        if inferred_num_hgt_layers != num_hgt_layers:
            print(f"   âš ï¸  ä» state_dict æ¨æ–­ num_hgt_layers: {inferred_num_hgt_layers} (é…ç½®ä¸­ä¸º {num_hgt_layers})")
            num_hgt_layers = inferred_num_hgt_layers
    
    print(f"   ä»æ£€æŸ¥ç‚¹è¯»å–é…ç½®:")
    print(f"   - node_feat_dim: {node_feat_dim}")
    print(f"   - edge_feat_dim: {edge_feat_dim}")
    print(f"   - d_model: {d_model}")
    print(f"   - max_agents: {max_agents}")
    print(f"   - max_seq_len: {max_seq_len}")
    print(f"   - num_classes: {num_classes}")
    print(f"   - num_hgt_layers: {num_hgt_layers}")
    
    # åŠ è½½ converterï¼ˆç›´æ¥ä½¿ç”¨ torch.loadï¼Œå› ä¸º converter æ˜¯ç›´æ¥ä¿å­˜çš„æ•´ä¸ªå¯¹è±¡ï¼‰
    if not Path(converter_path).exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° Converter æ–‡ä»¶: {converter_path}")
    
    map_location = device if device.type == 'cpu' else None
    converter = torch.load(converter_path, map_location=map_location, weights_only=False)
    
    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ£€æŸ¥ converter çš„ node_feat_dim å’Œ meta_dimï¼Œç¡®ä¿ä¸æ¨¡å‹åŒ¹é…
    converter_node_feat_dim = getattr(converter, 'node_feat_dim', 8192)
    # ğŸ”¥ ä¿®å¤ï¼šä»text_projæ¨æ–­text_dimï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç 384
    converter_text_dim = text_dim  # ä½¿ç”¨ä¸Šé¢æ¨æ–­çš„text_dim
    converter_meta_dim = converter_node_feat_dim - converter_text_dim
    
    # ä»æ£€æŸ¥ç‚¹è·å–å®é™…çš„ meta_dimï¼ˆä» meta_mlp.0.weight çš„è¾“å…¥ç»´åº¦ï¼‰
    checkpoint_meta_dim = None
    if 'micro_encoder.meta_mlp.0.weight' in state_dict:
        checkpoint_meta_dim = state_dict['micro_encoder.meta_mlp.0.weight'].shape[1]
    
    # æ£€æŸ¥ node_feat_dim åŒ¹é…
    if converter_node_feat_dim != node_feat_dim:
        print(f"\n   âš ï¸  ä¸¥é‡è­¦å‘Šï¼šConverter node_feat_dim ({converter_node_feat_dim}) ä¸æ¨¡å‹ node_feat_dim ({node_feat_dim}) ä¸åŒ¹é…ï¼")
        print(f"   âš ï¸  è¿™ä¼šå¯¼è‡´ç»´åº¦ä¸åŒ¹é…é”™è¯¯ï¼Œæ¨¡å‹æ— æ³•æ­£ç¡®åŠ è½½æƒé‡ã€‚")
        print(f"   âš ï¸  è§£å†³æ–¹æ¡ˆï¼š")
        print(f"      1. ä½¿ç”¨ä¸ converter åŒ¹é…çš„æ¨¡å‹æ£€æŸ¥ç‚¹ï¼ˆnode_feat_dim={converter_node_feat_dim}ï¼‰")
        print(f"      2. æˆ–è€…ä½¿ç”¨ä¸æ¨¡å‹åŒ¹é…çš„ converterï¼ˆnode_feat_dim={node_feat_dim}ï¼‰")
        print(f"\n   âŒ æ— æ³•ç»§ç»­ï¼šæ¨¡å‹å’Œ converter çš„ node_feat_dim å¿…é¡»åŒ¹é…ï¼")
        print(f"   ğŸ’¡ è¯·æŸ¥æ‰¾ä¸ converter (node_feat_dim={converter_node_feat_dim}) åŒ¹é…çš„æ¨¡å‹æ£€æŸ¥ç‚¹")
        raise ValueError(f"Converter node_feat_dim ({converter_node_feat_dim}) ä¸æ¨¡å‹ node_feat_dim ({node_feat_dim}) ä¸åŒ¹é…ï¼")
    
    # ğŸ”¥ é¢å¤–æ£€æŸ¥ï¼šmeta_dim å¿…é¡»åŒ¹é…ï¼ˆè¿™æ˜¯æœ€å…³é”®çš„ï¼Œå› ä¸º meta_mlp çš„è¾“å…¥ç»´åº¦å¿…é¡»åŒ¹é…ï¼‰
    if checkpoint_meta_dim is not None and checkpoint_meta_dim != converter_meta_dim:
        print(f"\n   âŒ è‡´å‘½é”™è¯¯ï¼šæ£€æŸ¥ç‚¹çš„ meta_dim ({checkpoint_meta_dim}) ä¸ converter çš„ meta_dim ({converter_meta_dim}) ä¸åŒ¹é…ï¼")
        print(f"   âŒ è¿™ä¼šå¯¼è‡´è¿è¡Œæ—¶é”™è¯¯ï¼šmat1 and mat2 shapes cannot be multiplied")
        print(f"   âŒ Converter è¾“å‡º: meta_dim={converter_meta_dim} (node_feat_dim={converter_node_feat_dim}, text_dim={converter_text_dim})")
        print(f"   âŒ æ£€æŸ¥ç‚¹æœŸæœ›: meta_dim={checkpoint_meta_dim} (node_feat_dim={checkpoint_meta_dim + text_dim}, text_dim={text_dim})")
        print(f"\n   ğŸ’¡ è§£å†³æ–¹æ¡ˆï¼š")
        print(f"      1. æŸ¥æ‰¾ meta_dim={converter_meta_dim} çš„æ£€æŸ¥ç‚¹ï¼ˆå³ node_feat_dim={converter_node_feat_dim}ï¼‰")
        print(f"      2. æˆ–è€…é‡æ–°è®­ç»ƒæ¨¡å‹ä»¥åŒ¹é…å½“å‰çš„ converter")
        print(f"\n   âš ï¸  æ³¨æ„ï¼šå³ä½¿æ£€æŸ¥ç‚¹çš„é…ç½®æ˜¾ç¤º node_feat_dim={node_feat_dim}ï¼Œ")
        print(f"      ä½†å®é™…çš„ meta_mlp æƒé‡å½¢çŠ¶è¡¨æ˜å®ƒæ˜¯åœ¨ node_feat_dim={checkpoint_meta_dim + text_dim} ä¸‹è®­ç»ƒçš„ã€‚")
        raise ValueError(f"æ£€æŸ¥ç‚¹çš„ meta_dim ({checkpoint_meta_dim}) ä¸ converter çš„ meta_dim ({converter_meta_dim}) ä¸åŒ¹é…ï¼")
    
    print(f"âœ… Converter åŠ è½½å®Œæˆ (node_feat_dim={converter_node_feat_dim}, meta_dim={converter_meta_dim})")
    if checkpoint_meta_dim is not None:
        print(f"âœ… æ£€æŸ¥ç‚¹ meta_dim åŒ¹é… (meta_dim={checkpoint_meta_dim})")
    
    # åˆ›å»ºæ¨¡å‹ï¼ˆä½¿ç”¨åŒ¹é…çš„ node_feat_dimï¼‰
    model = ASTRAMoE(
        node_feat_dim=node_feat_dim,  # ä½¿ç”¨åŒ¹é…çš„ node_feat_dim
        edge_feat_dim=edge_feat_dim,
        d_model=d_model,
        num_heads=num_heads,
        num_hgt_layers=num_hgt_layers,
        num_temporal_layers=num_temporal_layers,
        num_experts=num_experts,
        num_classes=num_classes,  # ä½¿ç”¨æ£€æŸ¥ç‚¹ä¸­çš„ num_classes
        dropout=dropout,
        max_seq_len=max_seq_len
    )
    
    # åŠ è½½æƒé‡ï¼ˆä½¿ç”¨ strict=False å…è®¸éƒ¨åˆ†åŠ è½½ï¼Œå…¼å®¹ä¸åŒæ¶æ„çš„æ£€æŸ¥ç‚¹ï¼‰
    try:
        if 'model_state_dict' in checkpoint:
            missing_keys, unexpected_keys = model.load_state_dict(checkpoint['model_state_dict'], strict=False)
        else:
            missing_keys, unexpected_keys = model.load_state_dict(checkpoint, strict=False)
        
        if missing_keys:
            print(f"   âš ï¸  ç¼ºå¤±çš„é”®ï¼ˆå·²å¿½ç•¥ï¼‰: {len(missing_keys)} ä¸ª")
            if len(missing_keys) <= 5:
                for key in missing_keys[:5]:
                    print(f"      - {key}")
            else:
                for key in missing_keys[:5]:
                    print(f"      - {key}")
                print(f"      ... è¿˜æœ‰ {len(missing_keys) - 5} ä¸ªç¼ºå¤±çš„é”®")
        
        if unexpected_keys:
            print(f"   âš ï¸  æ„å¤–çš„é”®ï¼ˆå·²å¿½ç•¥ï¼‰: {len(unexpected_keys)} ä¸ª")
            if len(unexpected_keys) <= 5:
                for key in unexpected_keys[:5]:
                    print(f"      - {key}")
            else:
                for key in unexpected_keys[:5]:
                    print(f"      - {key}")
                print(f"      ... è¿˜æœ‰ {len(unexpected_keys) - 5} ä¸ªæ„å¤–çš„é”®")
        
        print(f"âœ… æ¨¡å‹æƒé‡åŠ è½½å®Œæˆ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹æƒé‡åŠ è½½å¤±è´¥: {e}")
        print(f"   è¿™å¯èƒ½æ˜¯ç”±äºæ¨¡å‹æ¶æ„ä¸åŒ¹é…å¯¼è‡´çš„")
        print(f"   è¯·æ£€æŸ¥æ£€æŸ¥ç‚¹æ˜¯å¦ä¸å½“å‰ä»£ç ç‰ˆæœ¬å…¼å®¹")
        raise
    
    model.to(device)
    model.eval()
    
    print(f"âœ… GNN æ¨¡å‹åŠ è½½å®Œæˆ")
    print(f"   é…ç½®: max_agents={max_agents}, max_seq_len={max_seq_len}, d_model={d_model}")
    
    return model, converter, {
        'max_agents': max_agents,
        'max_seq_len': max_seq_len,
        'd_model': d_model
    }


def load_llm_model(adapter_path: str, base_model_name: str = "Qwen/Qwen3-8B", device: torch.device = None, use_4bit: bool = True):
    """
    åŠ è½½å¾®è°ƒåçš„ LLM æ¨¡å‹ï¼ˆå†…å­˜ä¼˜åŒ–ç‰ˆï¼Œæ”¯æŒé‡åŒ–ï¼‰
    
    Args:
        adapter_path: é€‚é…å™¨è·¯å¾„
        base_model_name: åŸºç¡€æ¨¡å‹åç§°
        device: è®¾å¤‡
        use_4bit: æ˜¯å¦ä½¿ç”¨ 4-bit é‡åŒ–ï¼ˆé»˜è®¤ Trueï¼ŒèŠ‚çœæ˜¾å­˜ï¼‰
    """
    # ğŸ”¥ ä¿®å¤ï¼šè‡ªåŠ¨æŸ¥æ‰¾æœ¬åœ°ç¼“å­˜çš„ snapshot ç›®å½•
    original_model_name = base_model_name
    
    # å°è¯•æŸ¥æ‰¾æœ¬åœ°ç¼“å­˜ï¼ˆæ”¯æŒå¤šç§æ¨¡å‹ï¼‰
    model_cache_patterns = {
        "Qwen/Qwen1.5-4B-Chat": "models--Qwen--Qwen1.5-4B-Chat",
        "Qwen/Qwen2.5-4B-Instruct": "models--Qwen--Qwen2.5-4B-Instruct",
        "Qwen/Qwen2.5-7B-Instruct": "models--Qwen--Qwen2.5-7B-Instruct",
    }
    
    cache_dir_name = model_cache_patterns.get(base_model_name)
    if cache_dir_name:
        cache_dir = Path.home() / ".cache/huggingface/hub" / cache_dir_name
        if cache_dir.exists():
            # æŸ¥æ‰¾ snapshots ç›®å½•
            snapshot_dirs = sorted((cache_dir / "snapshots").glob("*"))
            if snapshot_dirs:
                base_model_name = str(snapshot_dirs[-1])  # ä½¿ç”¨æœ€æ–°çš„ snapshot
                print(f"âœ“ ä½¿ç”¨æœ¬åœ°ç¼“å­˜: {base_model_name}")
    
    # å¦‚æœæŒ‡å®šäº†æœ¬åœ°è·¯å¾„ï¼ˆå¦‚ ./models/Qwen2.5-7B-Instructï¼‰ï¼Œç›´æ¥ä½¿ç”¨
    if base_model_name.startswith("./") or base_model_name.startswith("/"):
        print(f"âœ“ ä½¿ç”¨æœ¬åœ°è·¯å¾„: {base_model_name}")
    
    print(f"ğŸ“¥ åŠ è½½ LLM æ¨¡å‹: {original_model_name}")
    print(f"   é€‚é…å™¨: {adapter_path}")
    
    if device is None:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # ğŸ”¥ğŸ”¥ğŸ”¥ å†…å­˜ä¼˜åŒ–ï¼šä½¿ç”¨ 4-bit é‡åŒ–ï¼ˆèŠ‚çœæ˜¾å­˜ï¼‰
    if use_4bit:
        try:
            from transformers import BitsAndBytesConfig
            print(f"   âœ… ä½¿ç”¨ 4-bit é‡åŒ–æ¨¡å¼ï¼ˆèŠ‚çœæ˜¾å­˜ï¼‰")
            quantization_config = BitsAndBytesConfig(
                load_in_4bit=True,
                bnb_4bit_compute_dtype=torch.float16,
                bnb_4bit_use_double_quant=True,
                bnb_4bit_quant_type="nf4"
            )
            # ğŸ”¥ ä¿®å¤ï¼š4-bit é‡åŒ–å¿…é¡»å…¨éƒ¨åœ¨ GPU ä¸Šï¼Œä¸èƒ½ offload åˆ° CPU
            # å¦‚æœ GPU æ˜¾å­˜ä¸è¶³ï¼Œå°†è‡ªåŠ¨å›é€€åˆ° FP16 æ¨¡å¼
            model_kwargs = {
                "quantization_config": quantization_config,
                "device_map": {"": device},  # æ˜ç¡®æŒ‡å®šè®¾å¤‡ï¼Œä¸å…è®¸ CPU offload
                "low_cpu_mem_usage": True,
                "trust_remote_code": True,
            }
        except ImportError:
            print(f"   âš ï¸  BitsAndBytes æœªå®‰è£…ï¼Œä½¿ç”¨ FP16 æ¨¡å¼")
            print(f"   å®‰è£…å‘½ä»¤: pip install bitsandbytes")
            use_4bit = False
    
    if not use_4bit:
        # å›é€€åˆ° FP16
        print(f"   âš ï¸  å†…å­˜ä¼˜åŒ–æ¨¡å¼ï¼šä½¿ç”¨ FP16 + low_cpu_mem_usage")
        model_kwargs = {
            "torch_dtype": torch.float16,
            "device_map": "auto",  # è‡ªåŠ¨åˆ†é…è®¾å¤‡
            "low_cpu_mem_usage": True,
            "trust_remote_code": True,
        }
    
    # å°è¯•åŠ è½½æ¨¡å‹ï¼ˆå…ˆå°è¯•æœ¬åœ°ï¼Œå¤±è´¥åˆ™ä»ç½‘ç»œä¸‹è½½ï¼‰
    # ğŸ”¥ ä¿®å¤ï¼šå¦‚æœ 4-bit é‡åŒ–å¤±è´¥ï¼ˆæ˜¾å­˜ä¸è¶³ï¼‰ï¼Œè‡ªåŠ¨å›é€€åˆ° FP16
    try:
        base_model = AutoModelForCausalLM.from_pretrained(
            base_model_name,
            local_files_only=False,  # å…è®¸ä»ç½‘ç»œä¸‹è½½ï¼ˆå¦‚æœæœ¬åœ°æ²¡æœ‰ï¼‰
            **model_kwargs
        )
    except ValueError as e:
        # æ£€æŸ¥æ˜¯å¦æ˜¯ 4-bit é‡åŒ–æ˜¾å­˜ä¸è¶³çš„é”™è¯¯
        error_msg = str(e)
        if "Some modules are dispatched on the CPU" in error_msg and use_4bit:
            print(f"âš ï¸  4-bit é‡åŒ–å¤±è´¥ï¼ˆGPU æ˜¾å­˜ä¸è¶³ï¼Œæ— æ³•å®Œå…¨åŠ è½½åˆ° GPUï¼‰")
            print(f"   è‡ªåŠ¨å›é€€åˆ° FP16 æ¨¡å¼ï¼ˆå…è®¸ CPU offloadï¼‰")
            use_4bit = False
            # ä½¿ç”¨ FP16 æ¨¡å¼ï¼Œå…è®¸ CPU offload
            model_kwargs = {
                "torch_dtype": torch.float16,
                "device_map": "auto",  # è‡ªåŠ¨åˆ†é…è®¾å¤‡ï¼ˆå…è®¸ CPU offloadï¼‰
                "low_cpu_mem_usage": True,
                "trust_remote_code": True,
                "max_memory": {0: "18GB", "cpu": "50GB"}  # é™åˆ¶ GPU æ˜¾å­˜ï¼Œå…è®¸ CPU æ‰©å±•
            }
            # é‡æ–°å°è¯•åŠ è½½
            try:
                base_model = AutoModelForCausalLM.from_pretrained(
                    base_model_name,
                    local_files_only=False,
                    **model_kwargs
                )
            except Exception as e2:
                print(f"âš ï¸  ä½¿ç”¨ FP16 æ¨¡å¼åŠ è½½ä¹Ÿå¤±è´¥: {e2}")
                print(f"   å°è¯•ä»ç½‘ç»œä¸‹è½½: {original_model_name}")
                base_model = AutoModelForCausalLM.from_pretrained(
                    original_model_name,
                    **model_kwargs
                )
        else:
            # å…¶ä»–é”™è¯¯ï¼Œå°è¯•ä»ç½‘ç»œä¸‹è½½
            print(f"âš ï¸  åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            print(f"   å°è¯•ä»ç½‘ç»œä¸‹è½½: {original_model_name}")
            base_model = AutoModelForCausalLM.from_pretrained(
                original_model_name,
            **model_kwargs
        )
    except Exception as e:
        print(f"âš ï¸  åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        print(f"   å°è¯•ä»ç½‘ç»œä¸‹è½½: {original_model_name}")
        base_model = AutoModelForCausalLM.from_pretrained(
            original_model_name,
            **model_kwargs
        )
    
    # æ£€æŸ¥é€‚é…å™¨è·¯å¾„æ˜¯å¦å­˜åœ¨ï¼ˆå¦‚æœæä¾›ï¼‰
    if not adapter_path or adapter_path.strip() == "":
        print("ğŸ”¬ [æ¶ˆèå®éªŒ] æœªæä¾›é€‚é…å™¨è·¯å¾„ï¼Œä½¿ç”¨æœªå¾®è°ƒçš„åŸºç¡€æ¨¡å‹")
        print(f"   åŸºç¡€æ¨¡å‹: {base_model_name}")
        print(f"   æ³¨æ„ï¼šè¿™æ˜¯æ¶ˆèå®éªŒé…ç½®ï¼Œæ¨¡å‹æœªç»è¿‡å¾®è°ƒæˆ–å¼ºåŒ–å­¦ä¹ ")
        tokenizer = AutoTokenizer.from_pretrained(
            base_model_name,
            trust_remote_code=True,
            local_files_only=False  # å…è®¸ä»ç½‘ç»œä¸‹è½½ï¼ˆå¦‚æœæœ¬åœ°æ²¡æœ‰ï¼‰
        )
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token
        return base_model, tokenizer
    
    adapter_path_obj = Path(adapter_path)
    if not adapter_path_obj.exists():
        print(f"ğŸ”¬ [æ¶ˆèå®éªŒ] é€‚é…å™¨è·¯å¾„ä¸å­˜åœ¨: {adapter_path}")
        print(f"   å°†ä½¿ç”¨æœªå¾®è°ƒçš„åŸºç¡€æ¨¡å‹")
        print(f"   åŸºç¡€æ¨¡å‹: {base_model_name}")
        print(f"   æ³¨æ„ï¼šè¿™æ˜¯æ¶ˆèå®éªŒé…ç½®ï¼Œæ¨¡å‹æœªç»è¿‡å¾®è°ƒæˆ–å¼ºåŒ–å­¦ä¹ ")
        tokenizer = AutoTokenizer.from_pretrained(
            base_model_name,
            trust_remote_code=True,
            local_files_only=False  # å…è®¸ä»ç½‘ç»œä¸‹è½½ï¼ˆå¦‚æœæœ¬åœ°æ²¡æœ‰ï¼‰
        )
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token
        return base_model, tokenizer
    
    # æ£€æŸ¥é€‚é…å™¨é…ç½®æ–‡ä»¶
    adapter_config = adapter_path_obj / "adapter_config.json"
    if not adapter_config.exists():
        print(f"âš ï¸  è­¦å‘Š: é€‚é…å™¨é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {adapter_config}")
        print(f"   å°†ä½¿ç”¨åŸºç¡€æ¨¡å‹ï¼ˆæ— å¾®è°ƒï¼‰")
        tokenizer = AutoTokenizer.from_pretrained(
            base_model_name,
            trust_remote_code=True
        )
        return base_model, tokenizer
    
    # ğŸ”¥ æ–°å¢ï¼šé¢„æ£€æŸ¥é€‚é…å™¨å…¼å®¹æ€§
    import json
    try:
        with open(adapter_config, 'r', encoding='utf-8') as f:
            adapter_config_data = json.load(f)
        
        # æ£€æŸ¥é€‚é…å™¨çš„åŸºç¡€æ¨¡å‹åç§°
        adapter_base_model = adapter_config_data.get('base_model_name', '')
        if adapter_base_model:
            # æ ‡å‡†åŒ–æ¨¡å‹åç§°è¿›è¡Œæ¯”è¾ƒ
            def normalize_model_name(name):
                """æ ‡å‡†åŒ–æ¨¡å‹åç§°ä»¥ä¾¿æ¯”è¾ƒ"""
                name = name.lower().replace('\\', '/')
                # ç§»é™¤è·¯å¾„å‰ç¼€
                if '/' in name:
                    name = name.split('/')[-1]
                # ç§»é™¤å¸¸è§åç¼€
                for suffix in ['-instruct', '-chat', '-thinking', '-8b', '-7b', '-4b']:
                    if name.endswith(suffix):
                        name = name[:-len(suffix)]
                return name
            
            current_model_normalized = normalize_model_name(base_model_name)
            adapter_model_normalized = normalize_model_name(adapter_base_model)
            
            # æ£€æŸ¥æ˜¯å¦æ˜æ˜¾ä¸åŒ¹é…ï¼ˆå¦‚ qwen2.5 vs qwen3ï¼‰
            if 'qwen2.5' in adapter_base_model.lower() and 'qwen3' in base_model_name.lower():
                print(f"âš ï¸  é€‚é…å™¨å…¼å®¹æ€§æ£€æŸ¥å¤±è´¥")
                print(f"   é€‚é…å™¨åŸºç¡€æ¨¡å‹: {adapter_base_model}")
                print(f"   å½“å‰åŸºç¡€æ¨¡å‹: {base_model_name}")
                print(f"ğŸ’¡ é€‚é…å™¨æ˜¯ä¸º Qwen2.5 è®­ç»ƒçš„ï¼Œä½†å½“å‰ä½¿ç”¨çš„æ˜¯ Qwen3")
                print(f"   å°†ä½¿ç”¨åŸºç¡€æ¨¡å‹ï¼ˆæ— é€‚é…å™¨ï¼‰")
                tokenizer = AutoTokenizer.from_pretrained(
                    base_model_name,
                    trust_remote_code=True
                )
                return base_model, tokenizer
            elif 'qwen3' in adapter_base_model.lower() and 'qwen2.5' in base_model_name.lower():
                print(f"âš ï¸  é€‚é…å™¨å…¼å®¹æ€§æ£€æŸ¥å¤±è´¥")
                print(f"   é€‚é…å™¨åŸºç¡€æ¨¡å‹: {adapter_base_model}")
                print(f"   å½“å‰åŸºç¡€æ¨¡å‹: {base_model_name}")
                print(f"ğŸ’¡ é€‚é…å™¨æ˜¯ä¸º Qwen3 è®­ç»ƒçš„ï¼Œä½†å½“å‰ä½¿ç”¨çš„æ˜¯ Qwen2.5")
                print(f"   å°†ä½¿ç”¨åŸºç¡€æ¨¡å‹ï¼ˆæ— é€‚é…å™¨ï¼‰")
                tokenizer = AutoTokenizer.from_pretrained(
                    base_model_name,
                    trust_remote_code=True
                )
                return base_model, tokenizer
    except Exception as e:
        print(f"âš ï¸  è¯»å–é€‚é…å™¨é…ç½®æ—¶å‡ºé”™: {e}")
        print(f"   å°†ç»§ç»­å°è¯•åŠ è½½é€‚é…å™¨...")
    
    # æ£€æŸ¥ç½‘ç»œè¿æ¥
    network_available = True
    try:
        import requests
        requests.get("https://huggingface.co", timeout=2)
    except:
        network_available = False
        print(f"âš ï¸  ç½‘ç»œä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æœ¬åœ°æ–‡ä»¶æ¨¡å¼åŠ è½½é€‚é…å™¨")
    
    # åŠ è½½ LoRA é€‚é…å™¨ï¼ˆä½¿ç”¨ local_files_only å¦‚æœç½‘ç»œä¸å¯ç”¨ï¼‰
    # ğŸ”¥ æ”¹è¿›ï¼šä½¿ç”¨æ›´ä¸¥æ ¼çš„é”™è¯¯å¤„ç†ï¼Œæ•è·æ‰€æœ‰å¯èƒ½çš„å¼‚å¸¸
    try:
        # ä¸´æ—¶ç¦ç”¨è­¦å‘Šï¼Œé¿å…è¾“å‡ºå¤§é‡å°ºå¯¸ä¸åŒ¹é…è­¦å‘Š
        import warnings
        import logging
        old_warnings = warnings.filters[:]
        warnings.filterwarnings('ignore', category=UserWarning)
        old_log_level = logging.getLogger('transformers').level
        logging.getLogger('transformers').setLevel(logging.ERROR)
        
        try:
            model = PeftModel.from_pretrained(
                base_model, 
                adapter_path,
                local_files_only=not network_available
            )
        finally:
            # æ¢å¤è­¦å‘Šå’Œæ—¥å¿—çº§åˆ«
            warnings.filters[:] = old_warnings
            logging.getLogger('transformers').setLevel(old_log_level)
    except (ValueError, RuntimeError, TypeError, Exception) as e:
        # å¤„ç†ç»´åº¦ä¸åŒ¹é…é”™è¯¯ï¼ˆé€‚é…å™¨ä¸ºä¸åŒæ¨¡å‹è®­ç»ƒï¼‰
        error_str = str(e).lower()
        error_msg = str(e)
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å°ºå¯¸ä¸åŒ¹é…é”™è¯¯ï¼ˆåŒ…æ‹¬è­¦å‘Šä¿¡æ¯ï¼‰
        is_size_mismatch = (
            "size mismatch" in error_str or 
            "shape" in error_str or 
            "copying a param" in error_str or
            "torch.size" in error_str or
            "expected size" in error_str
        )
        
        if is_size_mismatch:
            print(f"\nâš ï¸  é€‚é…å™¨ç»´åº¦ä¸åŒ¹é…")
            print(f"ğŸ’¡ é€‚é…å™¨å¯èƒ½æ˜¯ä¸ºä¸åŒæ¨¡å‹è®­ç»ƒçš„")
            print(f"   é€‚é…å™¨è·¯å¾„: {adapter_path}")
            print(f"   å½“å‰åŸºç¡€æ¨¡å‹: {base_model_name}")
            print(f"   å°†ä½¿ç”¨åŸºç¡€æ¨¡å‹ï¼ˆæ— é€‚é…å™¨ï¼‰")
            tokenizer = AutoTokenizer.from_pretrained(
                base_model_name,
                trust_remote_code=True
            )
            return base_model, tokenizer
        elif "unexpected keyword argument" in error_str:
            # å¤„ç† PEFT ç‰ˆæœ¬ä¸å…¼å®¹é—®é¢˜ï¼ˆå¦‚ alora_invocation_tokens å‚æ•°ï¼‰
            print(f"âš ï¸  PEFT ç‰ˆæœ¬ä¸å…¼å®¹: {e}")
            print(f"ğŸ’¡ å°è¯•ä¿®å¤é€‚é…å™¨é…ç½®...")
            
            # è¯»å–å¹¶ä¿®å¤é€‚é…å™¨é…ç½®
            import json
            adapter_config_file = adapter_path_obj / "adapter_config.json"
            if adapter_config_file.exists():
                with open(adapter_config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                
                # ç§»é™¤ä¸æ”¯æŒçš„å‚æ•°
                unsupported_params = ['alora_invocation_tokens', 'alora_alpha', 'alora_dropout']
                removed_params = []
                for param in unsupported_params:
                    if param in config:
                        removed_params.append(param)
                        del config[param]
                
                if removed_params:
                    print(f"   ç§»é™¤äº†ä¸æ”¯æŒçš„å‚æ•°: {', '.join(removed_params)}")
                    # å¤‡ä»½åŸé…ç½®
                    backup_file = adapter_config_file.with_suffix('.json.bak')
                    import shutil
                    shutil.copy2(adapter_config_file, backup_file)
                    # ä¿å­˜ä¿®å¤åçš„é…ç½®
                    with open(adapter_config_file, 'w', encoding='utf-8') as f:
                        json.dump(config, f, indent=2, ensure_ascii=False)
                    print(f"   å·²å¤‡ä»½åŸé…ç½®åˆ°: {backup_file}")
                    print(f"   å·²æ›´æ–°é€‚é…å™¨é…ç½®")
                    
                    # é‡æ–°å°è¯•åŠ è½½
                    try:
                        model = PeftModel.from_pretrained(
                            base_model, 
                            adapter_path,
                            local_files_only=not network_available
                        )
                        print(f"âœ… é€‚é…å™¨åŠ è½½æˆåŠŸï¼ˆå·²ä¿®å¤é…ç½®ï¼‰")
                    except Exception as e2:
                        print(f"âŒ ä¿®å¤åä»ç„¶å¤±è´¥: {e2}")
                        # æ¢å¤åŸé…ç½®
                        if backup_file.exists():
                            shutil.copy2(backup_file, adapter_config_file)
                            print(f"   å·²æ¢å¤åŸé…ç½®")
                        # æ£€æŸ¥æ˜¯å¦æ˜¯ç»´åº¦ä¸åŒ¹é…
                        if "size mismatch" in str(e2).lower() or "shape" in str(e2).lower():
                            print(f"ğŸ’¡ é€‚é…å™¨ç»´åº¦ä¸åŒ¹é…ï¼Œå°†ä½¿ç”¨åŸºç¡€æ¨¡å‹")
                            tokenizer = AutoTokenizer.from_pretrained(
                                base_model_name,
                                trust_remote_code=True
                            )
                            return base_model, tokenizer
                        raise
                else:
                    raise
            else:
                raise
        else:
            # å…¶ä»–é”™è¯¯ï¼Œä¹Ÿå°è¯•ä½¿ç”¨åŸºç¡€æ¨¡å‹
            print(f"âš ï¸  åŠ è½½é€‚é…å™¨å¤±è´¥: {e}")
            if "adapter_config.json" in str(e) or "Can't find" in str(e):
                print(f"ğŸ’¡ æ£€æŸ¥é€‚é…å™¨ç›®å½•: {adapter_path}")
                print(f"   éœ€è¦çš„æ–‡ä»¶:")
                print(f"     - adapter_config.json")
                print(f"     - adapter_model.bin æˆ– adapter_model.safetensors")
                if adapter_path_obj.exists():
                    files = list(adapter_path_obj.glob("*"))
                    print(f"   å½“å‰ç›®å½•ä¸­çš„æ–‡ä»¶:")
                    for f in files:
                        print(f"     - {f.name}")
            print(f"ğŸ’¡ å°†ä½¿ç”¨åŸºç¡€æ¨¡å‹ï¼ˆæ— é€‚é…å™¨ï¼‰")
            tokenizer = AutoTokenizer.from_pretrained(
                base_model_name,
                trust_remote_code=True
            )
            return base_model, tokenizer
    
    # åŠ è½½åˆ†è¯å™¨
    try:
        tokenizer = AutoTokenizer.from_pretrained(
            base_model_name,
            trust_remote_code=True,
            local_files_only=not network_available
        )
    except Exception as e:
        print(f"âš ï¸  ä»æœ¬åœ°è·¯å¾„åŠ è½½åˆ†è¯å™¨å¤±è´¥: {e}")
        if network_available:
            print(f"   å°è¯•ä»ç½‘ç»œä¸‹è½½")
            tokenizer = AutoTokenizer.from_pretrained(
                original_model_name,
                trust_remote_code=True
            )
        else:
            # å°è¯•ä»é€‚é…å™¨è·¯å¾„åŠ è½½
            try:
                tokenizer = AutoTokenizer.from_pretrained(
                    adapter_path,
                    trust_remote_code=True,
                    local_files_only=True
                )
            except:
                raise Exception(f"æ— æ³•åŠ è½½åˆ†è¯å™¨ï¼Œç½‘ç»œä¸å¯ç”¨ä¸”æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨")
    
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
    
    print(f"âœ… LLM æ¨¡å‹åŠ è½½å®Œæˆ")
    
    return model, tokenizer


def normalize_name(name):
    """
    å½’ä¸€åŒ– Agent åç§°ï¼šå»ä¸‹åˆ’çº¿ã€å»ç©ºæ ¼ã€å»è¿å­—ç¬¦ã€è½¬å°å†™
    ç”¨äºæ¨¡ç³ŠåŒ¹é…
    """
    if not name:
        return ""
    return str(name).lower().replace("_", "").replace(" ", "").replace("-", "").strip()


def predict_top_k_with_gnn(model, graph_list, converter, config, device, top_k=7, true_agent_nodes=None):
    """
    ä½¿ç”¨ GNN é¢„æµ‹ Top-K å€™é€‰Agentï¼ˆå¢å¼ºç‰ˆï¼šä¸¥æ ¼è¿‡æ»¤éAgentèŠ‚ç‚¹ï¼‰
    
    æ ¸å¿ƒç†è§£ï¼š
    - ASTRA-MoE è¾“å‡º logits shape: [seq_len, num_agents, 1] (æ‰“åˆ†æ¨¡å¼)
    - num_agents æ˜¯å½“å‰å›¾ä¸­ Agent ç±»å‹èŠ‚ç‚¹çš„æ•°é‡ï¼ˆä¸æ˜¯å…¨å±€ 529ï¼‰
    - node_id_to_idx æ ¼å¼: {node_id: (node_type, local_idx)}
    - éœ€è¦ç­›é€‰ Agent ç±»å‹ï¼Œå»ºç«‹ local_idx -> node_id çš„æ˜ å°„
    - ğŸ”¥ ä¸¥æ ¼è¿‡æ»¤ï¼šæ’é™¤å·¥å…·ã€ç¯å¢ƒç­‰éAgentèŠ‚ç‚¹
    - ğŸ”¥ğŸ”¥ğŸ”¥ æ–°å¢ï¼šå¦‚æœæä¾›äº† true_agent_nodesï¼Œåªè¾“å‡ºè¿™äº›èŠ‚ç‚¹ï¼ˆä»JSONæ–‡ä»¶è¯»å–ï¼‰
    
    Args:
        top_k: å¦‚æœä¸º Noneï¼Œè¿”å›æ‰€æœ‰Agentçš„å®Œæ•´æ’åºï¼›å¦åˆ™è¿”å› Top-K
        true_agent_nodes: ä»JSONæ–‡ä»¶è¯»å–çš„çœŸå®AgentèŠ‚ç‚¹åˆ—è¡¨ï¼ˆSet[str]ï¼‰ï¼Œå¦‚æœæä¾›ï¼Œåªè¾“å‡ºè¿™äº›èŠ‚ç‚¹
    
    Returns:
        å¦‚æœ top_k ä¸ä¸º None:
            Tuple[List[str], Optional[int]]: (Top-K å€™é€‰Agent IDåˆ—è¡¨, GNNé¢„æµ‹çš„Step)
        å¦‚æœ top_k ä¸º None:
            Tuple[List[str], Dict[str, float], Optional[int]]: (æ‰€æœ‰Agentæ’åºåˆ—è¡¨, Agentåˆ†æ•°å­—å…¸, GNNé¢„æµ‹çš„Step)
    """
    # ç§»åŠ¨åˆ°è®¾å¤‡
    graph_list_device = [g.to(device) for g in graph_list]
    
    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        outputs = model(graph_list_device)
    
    # è·å– logits: [seq_len, num_agents, 1]
    logits = outputs['logits']
    
    # è·å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„åˆ†æ•°
    if logits.dim() == 3:
        scores = logits[-1, :, 0]  # [num_agents]
    else:
        scores = logits[-1, :]  # [num_agents]
    
    # ğŸ”¥ å°è¯•è·å–GNNçš„Stepé¢„æµ‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    gnn_pred_step = None
    if 'step_logits' in outputs:
        step_logits = outputs['step_logits']  # [seq_len] æˆ– [batch, seq_len]
        if step_logits is not None:
            if step_logits.dim() == 1:
                # å•ä¸ªæ ·æœ¬
                gnn_pred_step = int(torch.argmax(step_logits).item())
            elif step_logits.dim() == 2 and step_logits.size(0) == 1:
                # batch_size=1
                gnn_pred_step = int(torch.argmax(step_logits[0]).item())
    
    # âœ… å…³é”®ä¿®å¤ï¼šæ­£ç¡®å¤„ç† node_id_to_idx æ˜ å°„
    # node_id_to_idx æ ¼å¼: {node_id: (node_type, local_idx)}
    node_id_to_idx = graph_list[0].node_id_to_idx if graph_list else {}
    
    # ğŸ”¥ğŸ”¥ğŸ”¥ã€æ ¸å¿ƒä¿®æ”¹ã€‘ä¸¥æ ¼è¿‡æ»¤é€»è¾‘ï¼ˆç»ˆæå¢å¼ºç‰ˆ - é’ˆå¯¹Orchestratorå’Œè™šæ‹ŸèŠ‚ç‚¹ï¼‰
    # æ’é™¤å…³é”®è¯åˆ—è¡¨ (è½¬å°å†™åŒ¹é…)
    exclude_keywords = [
        'terminal', 'computer', 'console', 'shell', 'bash',  # ç»ˆç«¯å·¥å…·
        'broadcast', 'env', 'environment', 'root', 'system', # ç¯å¢ƒ/å¹¿æ’­
        'artifact', 'file', 'database', 'internet',          # é™æ€èµ„æº
        'userproxy', 'user_proxy', 'user',                    # ç”¨æˆ·ä»£ç†ï¼ˆé€šå¸¸ä¸å½’å› ï¼‰
        'tool', 'api', 'service',                             # å·¥å…·ç±»
        'https', 'http', 'www', '.com', '.org', '.net',      # URL å®ä½“
        'github', 'gmail', 'google', 'apple', 'microsoft',   # å¸¸è§å®ä½“/åŸŸå
        # ğŸ”¥ğŸ”¥ğŸ”¥ æ–°å¢ï¼šè¿‡æ»¤è™šæ‹ŸèŠ‚ç‚¹å’Œå…ƒæ•°æ®å™ªéŸ³ï¼ˆå…³é”®ï¼ï¼‰
        '(thought)', 'termination', '->', 'condition', 'reasoning',  # è™šæ‹ŸèŠ‚ç‚¹ç‰¹å¾
        'type', 'context', 'graph', 'id', 'name',            # å…ƒæ•°æ®å™ªéŸ³
        # ğŸ”¥ğŸ”¥ğŸ”¥ æ–°å¢ï¼šå¸¸è§ç½‘ç«™/å¹³å°åï¼ˆå®Œæ•´åˆ—è¡¨ï¼‰
        'youtube', 'linkedin', 'twitter', 'facebook', 'instagram', 'tiktok',  # ç¤¾äº¤åª’ä½“
        'amazon', 'ebay', 'shopify', 'etsy',                 # ç”µå•†å¹³å°
        'wikipedia', 'reddit', 'quora', 'stackoverflow',     # å†…å®¹å¹³å°
        'netflix', 'spotify', 'discord', 'slack',            # åº”ç”¨å¹³å°
        'gmail', 'outlook', 'yahoo',                         # é‚®ä»¶æœåŠ¡
        # ğŸ”¥ğŸ”¥ğŸ”¥ æ–°å¢ï¼šå…ƒæ•°æ®å’Œå…ƒä¿¡æ¯å…³é”®è¯
        'metadata', 'attribute', 'property', 'field',        # å…ƒæ•°æ®
        'parameter', 'argument', 'variable',                 # ç¼–ç¨‹æœ¯è¯­
        # ğŸ”¥ğŸ”¥ğŸ”¥ æ–°å¢ï¼šå¸¸è§çš„éAgentå®ä½“
        'orchestrator', 'coordinator', 'manager',            # ç®¡ç†èŠ‚ç‚¹
        'ncbi', 'pubmed', 'doi',                             # å­¦æœ¯èµ„æº
        'gremm', 'tpwd', 'rndpa',                            # ç¼©å†™/ç»„ç»‡ä»£ç ï¼ˆä»æ•°æ®ä¸­å‘ç°çš„ï¼‰
    ]
    
    # ç­›é€‰å€™é€‰äººï¼šå¿…é¡»æ˜¯Agentç±»å‹ï¼Œä¸”ä¸åŒ…å«æ’é™¤å…³é”®è¯
    valid_candidates = []
    for node_id, (ntype, local_idx) in node_id_to_idx.items():
        node_id_lower = node_id.lower()
        
        # 1. ç±»å‹å¿…é¡»æ˜¯ Agent (å¦‚æœå›¾æ•°æ®é‡Œç±»å‹æ ‡è®°æ­£ç¡®)
        if ntype != 'Agent':
            continue
        
        # ğŸ”¥ æ–°å¢ï¼šé•¿åº¦è¿‡æ»¤ - Agentåå­—é€šå¸¸ä¸ä¼šå¤ªçŸ­ï¼ˆè‡³å°‘3ä¸ªå­—ç¬¦ï¼Œä¸”ä¸èƒ½å…¨æ˜¯æ•°å­—ï¼‰
        if len(node_id) < 3:
            continue
        
        # ğŸ”¥ æ–°å¢ï¼šè¿‡æ»¤çº¯æ•°å­—æˆ–çº¯å­—æ¯æ•°å­—ç»„åˆï¼ˆå¯èƒ½æ˜¯IDï¼Œä¸æ˜¯Agentåï¼‰
        # ä¾‹å¦‚ï¼šabdulmateen5003, laivertebasaga5655 ç­‰
        if node_id.replace('_', '').replace('-', '').isalnum() and len(node_id) > 10:
            # å¦‚æœåå­—å¾ˆé•¿ä¸”å…¨æ˜¯å­—æ¯æ•°å­—ï¼Œå¯èƒ½æ˜¯ç”¨æˆ·å/ID
            # ä½†ä¿ç•™çŸ­åå­—ï¼ˆå¯èƒ½æ˜¯æ­£å¸¸Agentåï¼‰
            if not any(c.isupper() for c in node_id):  # å¦‚æœå…¨å°å†™ä¸”å¾ˆé•¿ï¼Œå¯èƒ½æ˜¯ID
                continue
        
        # ğŸ”¥ğŸ”¥ğŸ”¥ã€å¢å¼ºè¿‡æ»¤ã€‘ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¿‡æ»¤æ‰çœ‹èµ·æ¥åƒç”¨æˆ·åæˆ–çº¯ä¹±ç çš„ ID
        # ä¾‹å¦‚åŒ…å«3ä¸ªä»¥ä¸Šè¿ç»­æ•°å­—çš„ï¼ˆå¦‚ abdulmateen5003ï¼‰ï¼Œä½†è¦ä¿ç•™æ ‡å‡†æ ¼å¼ï¼ˆå¦‚ Agent_1, WebSurfer_2ï¼‰
        if re.search(r'\d{3,}', node_id):
            # ä¿ç•™æ ‡å‡†æ ¼å¼ï¼šAgent_1, WebSurfer_2, PythonExpert_3 ç­‰
            if not re.match(r'^[A-Za-z]+_\d+$', node_id) and 'Expert' not in node_id:
                # å¦‚æœåŒ…å«3ä¸ªä»¥ä¸Šè¿ç»­æ•°å­—ï¼Œä¸”ä¸æ˜¯æ ‡å‡†æ ¼å¼ï¼Œå¾ˆå¯èƒ½æ˜¯ç”¨æˆ·å/ID
                continue
            
        # 2. åå­—ä¸èƒ½åŒ…å«æ’é™¤å…³é”®è¯ (åŒé‡ä¿é™©ï¼Œé˜²æ­¢ç±»å‹æ ‡è®°é”™è¯¯)
        if any(kw in node_id_lower for kw in exclude_keywords):
            continue
        
        # ğŸ”¥ğŸ”¥ğŸ”¥ å…³é”®ï¼šè¿‡æ»¤åŒ…å«æ‹¬å·çš„è™šæ‹ŸèŠ‚ç‚¹ï¼ˆå¦‚ "Orchestrator (thought)"ï¼‰
        if '(' in node_id or ')' in node_id:
            continue
        
        # ğŸ”¥ æ–°å¢ï¼šè¿‡æ»¤åŒ…å« "->" çš„è¾¹èŠ‚ç‚¹ï¼ˆå¦‚ "Orchestrator (-> Assistant)"ï¼‰
        if '->' in node_id or 'â†’' in node_id:
            continue
            
        valid_candidates.append((node_id, local_idx))
    
    # ğŸš¨ ä¿åº•æœºåˆ¶ï¼šå¦‚æœè¿‡æ»¤å¤ªç‹ å¯¼è‡´æ²¡å€™é€‰äº†ï¼Œæ”¾å®½é™åˆ¶ï¼ˆåªæ£€æŸ¥ç±»å‹ï¼‰
    if not valid_candidates:
        valid_candidates = [(node_id, idx) for node_id, (ntype, idx) in node_id_to_idx.items() if ntype == 'Agent']
        print(f"  âš ï¸ [è¿‡æ»¤è­¦å‘Š] ä¸¥æ ¼è¿‡æ»¤åæ— å€™é€‰ï¼Œæ”¾å®½ä¸ºä»…æ£€æŸ¥Agentç±»å‹ï¼Œæ‰¾åˆ° {len(valid_candidates)} ä¸ª")
    
    # æŒ‰ local_idx æ’åºï¼ˆç¡®ä¿ç´¢å¼•é¡ºåºæ­£ç¡®ï¼‰
    valid_candidates_sorted = sorted(valid_candidates, key=lambda x: x[1])
    
    # å»ºç«‹ local_idx -> node_id çš„æ˜ å°„ï¼ˆä»…åŒ…å«æœ‰æ•ˆå€™é€‰ï¼‰
    idx_to_node_id = {local_idx: node_id for node_id, local_idx in valid_candidates_sorted}
    
    # æå–æœ‰æ•ˆå€™é€‰è€…çš„åˆ†æ•°
    valid_scores = []
    valid_indices = []
    
    for node_id, idx in valid_candidates_sorted:
        if idx < len(scores):
            valid_scores.append(scores[idx].item())
            valid_indices.append(idx)
    
    # å¦‚æœæ²¡æœ‰æœ‰æ•ˆåˆ†æ•°ï¼ˆæç«¯æƒ…å†µï¼‰ï¼Œè¿”å›ç©º
    if not valid_scores:
        return [], None
    
    # è½¬ä¸º tensor è¿›è¡Œæ’åº
    valid_scores_tensor = torch.tensor(valid_scores)
    
    # ğŸ”¥ğŸ”¥ğŸ”¥ã€æ ¸å¿ƒéªŒè¯ã€‘è·å–æ‰€æœ‰çœŸæ­£çš„AgentèŠ‚ç‚¹
    # ä¼˜å…ˆä½¿ç”¨ä»JSONæ–‡ä»¶è¯»å–çš„AgentèŠ‚ç‚¹åˆ—è¡¨ï¼ˆå¦‚æœæä¾›ï¼‰
    if true_agent_nodes is not None:
        # ä½¿ç”¨ä»JSONæ–‡ä»¶è¯»å–çš„çœŸå®AgentèŠ‚ç‚¹åˆ—è¡¨
        all_graph_agents = set(true_agent_nodes)
        print(f"  ğŸ“‹ [AgentéªŒè¯] ä½¿ç”¨JSONæ–‡ä»¶ä¸­çš„AgentèŠ‚ç‚¹åˆ—è¡¨ï¼ˆå…±{len(all_graph_agents)}ä¸ªï¼‰: {sorted(list(all_graph_agents))[:5]}")
    else:
        # ä»å›¾æ•°æ®ä¸­æ¨æ–­AgentèŠ‚ç‚¹ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
        all_graph_agents = set()
        for node_id, (ntype, local_idx) in node_id_to_idx.items():
            if ntype == 'Agent':
                # ä½¿ç”¨ç›¸åŒçš„è¿‡æ»¤é€»è¾‘éªŒè¯ï¼ˆæ’é™¤Toolã€ç½‘ç«™ç­‰ï¼‰
                node_id_lower = node_id.lower()
                is_valid = True
                # æ£€æŸ¥æ’é™¤å…³é”®è¯ï¼ˆä½¿ç”¨å®Œæ•´çš„åˆ—è¡¨ï¼‰
                if any(kw in node_id_lower for kw in exclude_keywords):
                    is_valid = False
                if len(node_id) < 3:
                    is_valid = False
                if '(' in node_id or ')' in node_id or '->' in node_id or 'â†’' in node_id:
                    is_valid = False
                if node_id.replace('_', '').replace('-', '').isalnum() and len(node_id) > 10:
                    if not any(c.isupper() for c in node_id):
                        is_valid = False
                if re.search(r'\d{3,}', node_id):
                    if not re.match(r'^[A-Za-z]+_\d+$', node_id) and 'Expert' not in node_id:
                        is_valid = False
                # ğŸ”¥ğŸ”¥ğŸ”¥ æ–°å¢ï¼šè¿‡æ»¤çœ‹èµ·æ¥åƒäººåçš„ï¼ˆå¦‚TheSmart, RosieRoan, Angelaç­‰ï¼‰
                if not node_id.endswith('Expert') and not node_id.endswith('_Expert'):
                    camel_case_words = re.findall(r'[A-Z][a-z]+', node_id)
                    if 2 <= len(camel_case_words) <= 4:
                        common_name_patterns = ['The', 'Young', 'Lee', 'John', 'Mary', 'Angela', 'Rosie', 'Mina']
                        if any(pattern in node_id for pattern in common_name_patterns):
                            is_valid = False
                
                if is_valid:
                    all_graph_agents.add(node_id)
    
    # ğŸ”¥ æ–°å¢ï¼šæ”¯æŒå…¨è¾“å‡ºæ¨¡å¼ï¼ˆtop_k=Noneï¼‰
    if top_k is None:
        # è¿”å›æ‰€æœ‰Agentçš„å®Œæ•´æ’åºï¼ˆæŒ‰åˆ†æ•°é™åºï¼‰
        sorted_indices = torch.argsort(valid_scores_tensor, descending=True)
        
        # æ„å»ºå®Œæ•´æ’åºåˆ—è¡¨å’Œåˆ†æ•°å­—å…¸
        all_candidates = []
        agent_scores = {}
        for i in sorted_indices.cpu().tolist():
            local_idx = valid_indices[i]
            agent_id = idx_to_node_id.get(local_idx, f"Agent_{local_idx}")
            score = valid_scores[i]
            all_candidates.append(agent_id)
            agent_scores[agent_id] = float(score)
        
        # ğŸ”¥ğŸ”¥ğŸ”¥ã€éªŒè¯æ­¥éª¤1ã€‘ç¡®ä¿è¾“å‡ºä¸­åªåŒ…å«çœŸæ­£çš„AgentèŠ‚ç‚¹
        # ğŸ”¥ğŸ”¥ğŸ”¥ å…³é”®ï¼šå¦‚æœæä¾›äº†true_agent_nodesï¼ˆä»JSONæ–‡ä»¶è¯»å–ï¼‰ï¼Œç›´æ¥ä½¿ç”¨å®ƒæ¥è¿‡æ»¤
        final_candidates = []
        final_scores = {}
        for agent_id in all_candidates:
            # ğŸ”¥ğŸ”¥ğŸ”¥ å…³é”®ä¿®å¤ï¼šå¦‚æœæä¾›äº†true_agent_nodesï¼Œåªä¿ç•™åœ¨è¿™äº›èŠ‚ç‚¹ä¸­çš„
            if true_agent_nodes is not None:
                if agent_id not in true_agent_nodes:
                    continue  # ä¸åœ¨çœŸå®AgentèŠ‚ç‚¹åˆ—è¡¨ä¸­ï¼Œè·³è¿‡
            else:
                # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨è¿‡æ»¤é€»è¾‘ï¼ˆå¦‚æœæ²¡æœ‰æä¾›true_agent_nodesï¼‰
                # 1. é¦–å…ˆæ£€æŸ¥èŠ‚ç‚¹ç±»å‹ï¼šå¿…é¡»æ˜¯Agentç±»å‹
                node_type_check = None
                if agent_id in node_id_to_idx:
                    node_type_check = node_id_to_idx[agent_id][0]  # è·å–èŠ‚ç‚¹ç±»å‹
                
                # å¦‚æœèŠ‚ç‚¹ç±»å‹ä¸æ˜¯Agentï¼Œç›´æ¥æ’é™¤
                if node_type_check and node_type_check != 'Agent':
                    continue
                
                agent_lower = agent_id.lower()
                # 2. å†æ¬¡æ£€æŸ¥æ’é™¤å…³é”®è¯ï¼ˆåŒé‡ä¿é™©ï¼Œé˜²æ­¢ç±»å‹æ ‡è®°é”™è¯¯ï¼‰- ä½¿ç”¨å®Œæ•´çš„æ’é™¤åˆ—è¡¨
                if any(kw in agent_lower for kw in exclude_keywords):
                    continue
                if '(' in agent_id or ')' in agent_id or '->' in agent_id or 'â†’' in agent_id:
                    continue
                # æ£€æŸ¥æ˜¯å¦åƒç½‘ç«™åŸŸåï¼ˆåŒ…å«.comç­‰ï¼‰
                if any(domain in agent_lower for domain in ['.com', '.org', '.net', '.io', '.edu', '.gov']):
                    continue
                # ğŸ”¥ğŸ”¥ğŸ”¥ æ–°å¢ï¼šè¿‡æ»¤çœ‹èµ·æ¥åƒäººåæˆ–ç”¨æˆ·åçš„ï¼ˆå¦‚TheSmart, RosieRoan, Angelaç­‰ï¼‰
                if not agent_id.endswith('Expert') and not agent_id.endswith('_Expert'):
                    camel_case_words = re.findall(r'[A-Z][a-z]+', agent_id)
                    if 2 <= len(camel_case_words) <= 4:
                        common_name_patterns = ['The', 'Young', 'Lee', 'John', 'Mary', 'Angela', 'Rosie', 'Mina', 'Smart', 'Roan']
                        if any(pattern in agent_id for pattern in common_name_patterns):
                            continue
            
            final_candidates.append(agent_id)
            final_scores[agent_id] = agent_scores.get(agent_id, -10.0)
        
        # ğŸ”¥ğŸ”¥ğŸ”¥ã€éªŒè¯æ­¥éª¤2ã€‘æ£€æŸ¥è¾“å‡ºæ˜¯å¦åŒ…å«äº†æ‰€æœ‰AgentèŠ‚ç‚¹
        # ğŸ”¥ğŸ”¥ğŸ”¥ å…³é”®ï¼šä½¿ç”¨ä»JSONæ–‡ä»¶è¯»å–çš„AgentèŠ‚ç‚¹åˆ—è¡¨ï¼ˆå¦‚æœæä¾›ï¼‰
        reference_agents = true_agent_nodes if true_agent_nodes is not None else all_graph_agents
        output_agents_set = set(final_candidates)
        missing_agents = reference_agents - output_agents_set
        
        if missing_agents:
            # å°†è¢«é—æ¼çš„Agentæ·»åŠ åˆ°è¾“å‡ºä¸­ï¼ˆä½¿ç”¨æœ€ä½åˆ†æ•°ï¼‰
            min_score = min(final_scores.values()) if final_scores else -10.0
            for missing_agent in missing_agents:
                final_candidates.append(missing_agent)
                final_scores[missing_agent] = float(min_score - 1.0)
            print(f"  âš ï¸ [è¾“å‡ºéªŒè¯] å‘ç° {len(missing_agents)} ä¸ªAgentèŠ‚ç‚¹æœªåœ¨GNNè¾“å‡ºä¸­ï¼Œå·²æ·»åŠ : {list(missing_agents)[:3]}")
        
        # æŒ‰åˆ†æ•°é‡æ–°æ’åº
        final_candidates_sorted = sorted(final_candidates, key=lambda x: final_scores[x], reverse=True)
        
        return final_candidates_sorted, final_scores, gnn_pred_step
    else:
        # åŸæœ‰çš„ Top-K é€»è¾‘
        # åŠ¨æ€è°ƒæ•´ K å€¼ï¼ˆé˜²æ­¢ K > å€™é€‰æ€»æ•°ï¼‰
        current_k = min(top_k, len(valid_scores))
        
        # é€‰å‡º Top-K
        top_vals, top_indices = torch.topk(valid_scores_tensor, k=current_k)
        
        # æ˜ å°„ä¸º agent ID
        final_candidates = []
        final_scores = {}
        for i in top_indices.cpu().tolist():
            local_idx = valid_indices[i]
            agent_id = idx_to_node_id.get(local_idx, f"Agent_{local_idx}")
            score = valid_scores[i]
            final_candidates.append(agent_id)
            final_scores[agent_id] = float(score)
        
        # ğŸ”¥ğŸ”¥ğŸ”¥ã€éªŒè¯æ­¥éª¤1ã€‘ç¡®ä¿è¾“å‡ºä¸­åªåŒ…å«çœŸæ­£çš„AgentèŠ‚ç‚¹
        # å¦‚æœæä¾›äº†true_agent_nodesï¼Œåªä¿ç•™åœ¨è¿™äº›èŠ‚ç‚¹ä¸­çš„
        filtered_candidates = []
        filtered_scores = {}
        for agent_id in final_candidates:
            # ğŸ”¥ğŸ”¥ğŸ”¥ å…³é”®ï¼šå¦‚æœæä¾›äº†true_agent_nodesï¼Œåªè¾“å‡ºè¿™äº›èŠ‚ç‚¹
            if true_agent_nodes is not None:
                if agent_id not in true_agent_nodes:
                    continue  # ä¸åœ¨çœŸå®AgentèŠ‚ç‚¹åˆ—è¡¨ä¸­ï¼Œè·³è¿‡
            else:
                # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨è¿‡æ»¤é€»è¾‘
                # 1. é¦–å…ˆæ£€æŸ¥èŠ‚ç‚¹ç±»å‹ï¼šå¿…é¡»æ˜¯Agentç±»å‹
                node_type_check = None
                if agent_id in node_id_to_idx:
                    node_type_check = node_id_to_idx[agent_id][0]  # è·å–èŠ‚ç‚¹ç±»å‹
                
                # å¦‚æœèŠ‚ç‚¹ç±»å‹ä¸æ˜¯Agentï¼Œç›´æ¥æ’é™¤
                if node_type_check and node_type_check != 'Agent':
                    continue
                
                agent_lower = agent_id.lower()
                # 2. å†æ¬¡æ£€æŸ¥æ’é™¤å…³é”®è¯ï¼ˆåŒé‡ä¿é™©ï¼Œé˜²æ­¢ç±»å‹æ ‡è®°é”™è¯¯ï¼‰
                if any(kw in agent_lower for kw in exclude_keywords):
                    continue
                if '(' in agent_id or ')' in agent_id or '->' in agent_id or 'â†’' in agent_id:
                    continue
                # æ£€æŸ¥æ˜¯å¦åƒç½‘ç«™åŸŸåï¼ˆåŒ…å«.comç­‰ï¼‰
                if any(domain in agent_lower for domain in ['.com', '.org', '.net', '.io', '.edu', '.gov']):
                    continue
                # ğŸ”¥ğŸ”¥ğŸ”¥ æ–°å¢ï¼šè¿‡æ»¤çœ‹èµ·æ¥åƒäººåæˆ–ç”¨æˆ·åçš„ï¼ˆå¦‚TheSmart, RosieRoan, Angelaç­‰ï¼‰
                if not agent_id.endswith('Expert') and not agent_id.endswith('_Expert'):
                    camel_case_words = re.findall(r'[A-Z][a-z]+', agent_id)
                    if 2 <= len(camel_case_words) <= 4:
                        common_name_patterns = ['The', 'Young', 'Lee', 'John', 'Mary', 'Angela', 'Rosie', 'Mina', 'Smart', 'Roan']
                        if any(pattern in agent_id for pattern in common_name_patterns):
                            continue
            
            filtered_candidates.append(agent_id)
            filtered_scores[agent_id] = final_scores.get(agent_id, -10.0)
        
        # ğŸ”¥ğŸ”¥ğŸ”¥ã€éªŒè¯æ­¥éª¤2ã€‘æ£€æŸ¥è¿‡æ»¤åçš„è¾“å‡ºæ˜¯å¦åŒ…å«äº†æ‰€æœ‰AgentèŠ‚ç‚¹
        # ğŸ”¥ğŸ”¥ğŸ”¥ å…³é”®ï¼šä½¿ç”¨ä»JSONæ–‡ä»¶è¯»å–çš„AgentèŠ‚ç‚¹åˆ—è¡¨ï¼ˆå¦‚æœæä¾›ï¼‰
        reference_agents = true_agent_nodes if true_agent_nodes is not None else all_graph_agents
        output_agents_set = set(filtered_candidates)
        missing_agents = reference_agents - output_agents_set
        
        if missing_agents:
            # å°†è¢«é—æ¼çš„Agentæ·»åŠ åˆ°è¾“å‡ºä¸­ï¼ˆä½¿ç”¨æœ€ä½åˆ†æ•°ï¼‰
            min_score = min(filtered_scores.values()) if filtered_scores else -10.0
            for missing_agent in missing_agents:
                filtered_candidates.append(missing_agent)
                filtered_scores[missing_agent] = float(min_score - 1.0)
            print(f"  âš ï¸ [è¾“å‡ºéªŒè¯] Top-{top_k}æ¨¡å¼ï¼šå‘ç° {len(missing_agents)} ä¸ªAgentèŠ‚ç‚¹æœªåœ¨è¾“å‡ºä¸­ï¼ˆå¯èƒ½è¢«éAgentèŠ‚ç‚¹æŒ¤å ï¼‰ï¼Œå·²æ·»åŠ : {list(missing_agents)[:3]}")
        
        # æŒ‰åˆ†æ•°é‡æ–°æ’åº
        filtered_candidates_sorted = sorted(filtered_candidates, key=lambda x: filtered_scores[x], reverse=True)
        
        return filtered_candidates_sorted, gnn_pred_step


def analyze_with_llm(model, tokenizer, instruction: str, system_prompt: str = None, max_new_tokens=4096, enable_thinking=True):
    """
    ä½¿ç”¨å¾®è°ƒåçš„ LLM è¿›è¡Œåˆ†æï¼ˆæ”¯æŒ Qwen3-8B æ€è€ƒæ¨¡å¼ï¼‰
    
    Args:
        model: LLM æ¨¡å‹
        tokenizer: Tokenizer
        instruction: æŒ‡ä»¤æ–‡æœ¬
        system_prompt: ç‹¬ç«‹çš„ç³»ç»Ÿæç¤ºè¯ï¼ˆæ–°å¢å‚æ•°ï¼Œè§£å†³ Prompt æ ¼å¼å†²çªï¼‰
        max_new_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°ï¼ˆé»˜è®¤4096ï¼ŒDeepSeek-R1æ€è€ƒè¿‡ç¨‹å¾ˆé•¿ï¼Œéœ€è¦æ›´å¤šç©ºé—´ï¼‰
        enable_thinking: æ˜¯å¦å¯ç”¨æ€è€ƒæ¨¡å¼
    """
    # ğŸ”¥ğŸ”¥ğŸ”¥ã€å…³é”®ä¿®å¤ã€‘æ„å»ºæ ‡å‡†çš„ Chat æ ¼å¼ï¼Œåˆ†ç¦» System å’Œ User
    messages = []
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})
    
    messages.append({"role": "user", "content": instruction})
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯ Qwen3-8B æ¨¡å‹ï¼ˆæ”¯æŒæ€è€ƒæ¨¡å¼ï¼‰
    is_qwen3 = "Qwen3" in str(model.config.name_or_path) if hasattr(model, 'config') and hasattr(model.config, 'name_or_path') else False
    
    # ğŸ”¥ å¦‚æœæ˜¯ Thinking æ¨¡å‹ï¼Œå¼ºåˆ¶å¢åŠ ç”Ÿæˆé•¿åº¦ï¼ˆç¡®ä¿è‡³å°‘ 4096ï¼‰
    if is_qwen3 and enable_thinking and max_new_tokens < 4096:
        max_new_tokens = 4096
        print(f"  ğŸ’¡ [Thinkingæ¨¡å¼] è‡ªåŠ¨å¢åŠ  max_new_tokens åˆ° {max_new_tokens}")
    
    # æ„å»ºèŠå¤©æ¨¡æ¿ï¼ˆå¦‚æœæ”¯æŒæ€è€ƒæ¨¡å¼ï¼Œå¯ç”¨å®ƒï¼‰
    try:
        if is_qwen3 and enable_thinking:
            text = tokenizer.apply_chat_template(
                messages,
                tokenize=False,
                add_generation_prompt=True,
                enable_thinking=True  # å¯ç”¨æ€è€ƒæ¨¡å¼
            )
        else:
            text = tokenizer.apply_chat_template(
                messages,
                tokenize=False,
                add_generation_prompt=True
            )
    except TypeError:
        # å¦‚æœ apply_chat_template ä¸æ”¯æŒ enable_thinking å‚æ•°ï¼Œä½¿ç”¨é»˜è®¤æ–¹å¼
        text = tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        )
    
    # ç”Ÿæˆå›ç­”ï¼ˆQwen3 æ€è€ƒæ¨¡å¼æ¨èå‚æ•°ï¼‰
    inputs = tokenizer(text, return_tensors="pt").to(model.device)
    
    # ğŸ”¥ Tokenç»Ÿè®¡ï¼šè®¡ç®—è¾“å…¥tokenæ•°
    input_token_count = inputs.input_ids.shape[1]
    
    with torch.no_grad():
        if is_qwen3:
            # Qwen3 æ€è€ƒæ¨¡å¼æ¨èå‚æ•°
            outputs = model.generate(
                **inputs,
                max_new_tokens=max_new_tokens,  # ğŸ”¥ å·²å¢åŠ åˆ° 4096ï¼ˆDeepSeek-R1 éœ€è¦æ›´å¤šç©ºé—´ï¼‰
                temperature=0.6,  # Qwen3 æ¨èå€¼
                do_sample=True,
                top_p=0.95,
                top_k=20,
                min_p=0.0,
                return_dict_in_generate=False  # ğŸ”¥ ç¡®ä¿è¿”å›å¼ é‡è€Œä¸æ˜¯å­—å…¸
            )
        else:
            outputs = model.generate(
                **inputs,
                max_new_tokens=max_new_tokens,  # ğŸ”¥ å·²å¢åŠ åˆ° 4096
                temperature=0.7,
                do_sample=True,
                top_p=0.95,
                return_dict_in_generate=False  # ğŸ”¥ ç¡®ä¿è¿”å›å¼ é‡è€Œä¸æ˜¯å­—å…¸
            )
    
    # ğŸ”¥ Tokenç»Ÿè®¡ï¼šè®¡ç®—è¾“å‡ºtokenæ•°ï¼ˆæ–°ç”Ÿæˆçš„tokenæ•°ï¼‰
    # å¤„ç†ä¸åŒçš„è¿”å›æ ¼å¼ï¼šå¯èƒ½æ˜¯å¼ é‡ã€å…ƒç»„æˆ–å­—å…¸
    try:
        if isinstance(outputs, torch.Tensor):
            # ç›´æ¥æ˜¯å¼ é‡
            generated_ids = outputs
        elif isinstance(outputs, (tuple, list)):
            # æ˜¯å…ƒç»„æˆ–åˆ—è¡¨
            if len(outputs) == 0:
                raise ValueError(f"outputs æ˜¯ç©ºå…ƒç»„/åˆ—è¡¨ï¼Œæ— æ³•æå–ç”Ÿæˆçš„tokenåºåˆ—")
            generated_ids = outputs[0]
        elif isinstance(outputs, dict):
            # æ˜¯å­—å…¸ï¼Œå°è¯•è·å– sequences æˆ– generated_ids
            generated_ids = outputs.get('sequences', outputs.get('generated_ids', None))
            if generated_ids is None:
                raise ValueError(f"æ— æ³•ä» outputs å­—å…¸ä¸­æå–ç”Ÿæˆçš„tokenåºåˆ—ã€‚outputs keys: {outputs.keys()}")
        else:
            raise ValueError(f"æœªçŸ¥çš„ outputs ç±»å‹: {type(outputs)}, å€¼: {outputs}")
    except Exception as e:
        # æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        error_msg = f"å¤„ç† model.generate() è¿”å›å€¼æ—¶å‡ºé”™: {str(e)}\n"
        error_msg += f"  outputs ç±»å‹: {type(outputs)}\n"
        if isinstance(outputs, (tuple, list)):
            error_msg += f"  outputs é•¿åº¦: {len(outputs)}\n"
        elif isinstance(outputs, dict):
            error_msg += f"  outputs keys: {list(outputs.keys())}\n"
        error_msg += f"  inputs.input_ids.shape: {inputs.input_ids.shape}\n"
        error_msg += f"  input_token_count: {input_token_count}"
        raise RuntimeError(error_msg) from e
    
    # ç¡®ä¿ generated_ids æ˜¯å¼ é‡
    if not isinstance(generated_ids, torch.Tensor):
        raise ValueError(f"generated_ids ä¸æ˜¯å¼ é‡ï¼Œè€Œæ˜¯ {type(generated_ids)}")
    
    # è®¡ç®—è¾“å‡ºtokenæ•°
    if len(generated_ids.shape) == 2:
        # å½¢çŠ¶ä¸º [batch_size, seq_len]
        total_length = generated_ids.shape[1]
        output_token_count = total_length - input_token_count
        # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿è¾“å‡ºtokenæ•°ä¸ä¸ºè´Ÿ
        if output_token_count < 0:
            print(f"  âš ï¸ [è­¦å‘Š] è®¡ç®—çš„è¾“å‡ºtokenæ•°ä¸ºè´Ÿæ•° ({output_token_count})ï¼Œå¯èƒ½æ˜¯generated_idsåªåŒ…å«è¾“å‡ºéƒ¨åˆ†")
            print(f"      total_length={total_length}, input_token_count={input_token_count}")
            # å¦‚æœä¸ºè´Ÿï¼Œè¯´æ˜generated_idså¯èƒ½åªåŒ…å«è¾“å‡ºéƒ¨åˆ†ï¼Œç›´æ¥ä½¿ç”¨total_length
            output_token_count = total_length
        # è§£ç è¾“å‡ºï¼ˆåªå–æ–°ç”Ÿæˆçš„éƒ¨åˆ†ï¼‰
        response = tokenizer.decode(
            generated_ids[0][input_token_count:],
            skip_special_tokens=True
        )
    elif len(generated_ids.shape) == 1:
        # å½¢çŠ¶ä¸º [seq_len]ï¼ˆå•æ ·æœ¬ï¼‰
        total_length = generated_ids.shape[0]
        output_token_count = total_length - input_token_count
        # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿è¾“å‡ºtokenæ•°ä¸ä¸ºè´Ÿ
        if output_token_count < 0:
            print(f"  âš ï¸ [è­¦å‘Š] è®¡ç®—çš„è¾“å‡ºtokenæ•°ä¸ºè´Ÿæ•° ({output_token_count})ï¼Œå¯èƒ½æ˜¯generated_idsåªåŒ…å«è¾“å‡ºéƒ¨åˆ†")
            print(f"      total_length={total_length}, input_token_count={input_token_count}")
            # å¦‚æœä¸ºè´Ÿï¼Œè¯´æ˜generated_idså¯èƒ½åªåŒ…å«è¾“å‡ºéƒ¨åˆ†ï¼Œç›´æ¥ä½¿ç”¨total_length
            output_token_count = total_length
        # è§£ç è¾“å‡ºï¼ˆåªå–æ–°ç”Ÿæˆçš„éƒ¨åˆ†ï¼‰
        response = tokenizer.decode(
            generated_ids[input_token_count:],
            skip_special_tokens=True
        )
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„ generated_ids å½¢çŠ¶: {generated_ids.shape}")
    
    # ğŸ”¥ æœ€ç»ˆå®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿tokenæ•°åˆç†
    if output_token_count < 0:
        output_token_count = 0
        print(f"  âš ï¸ [è­¦å‘Š] è¾“å‡ºtokenæ•°è¢«ä¿®æ­£ä¸º0ï¼ˆåŸå§‹å€¼å¯èƒ½æœ‰é—®é¢˜ï¼‰")
    
    # è®°å½•åˆ°å…¨å±€ç»Ÿè®¡å™¨
    token_counter.add_llm_call(input_token_count, output_token_count)
    
    # ================= [æ–°å¢è°ƒè¯•æ‰“å°] =================
    print("\n" + "="*50)
    print(f"[è°ƒè¯•-åŸå§‹è¾“å‡º] é•¿åº¦: {len(response)} å­—ç¬¦")
    print(f"[è°ƒè¯•-åŸå§‹å†…å®¹] (å‰500å­—ç¬¦):")
    print(response[:500])
    if len(response) > 500:
        print(f"\n[è°ƒè¯•-åŸå§‹å†…å®¹] (å500å­—ç¬¦):")
        print(response[-500:])
    print("="*50 + "\n")
    # ==================================================
    
    return response


def extract_json_from_text(text: str) -> Optional[dict]:
    """
    è¶…å¼ºé²æ£’æ€§çš„ JSON æå–å‡½æ•°
    èƒ½å¤„ç†ï¼šå•å¼•å·ã€æœªè½¬ä¹‰å­—ç¬¦ã€Markdownä»£ç å—ã€ä¸å®Œæ•´æ ¼å¼
    
    Args:
        text: LLM è¾“å‡ºçš„æ–‡æœ¬
        
    Returns:
        è§£æåçš„ JSON å­—å…¸ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å› None
    """
    try:
        # 1. é¢„å¤„ç†ï¼šç§»é™¤ <think> æ ‡ç­¾
        if "</think>" in text:
            text = text.split("</think>")[-1].strip()
        elif "<think>" in text:
            text = re.sub(r'<think>.*', '', text, flags=re.DOTALL | re.IGNORECASE).strip()
        
        json_str = None
        
        # 2. å°è¯•æå– Markdown JSON ä»£ç å—
        code_block = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', text, re.DOTALL)
        if code_block:
            json_str = code_block.group(1)
        else:
            # å°è¯•æå–æœ€å¤–å±‚çš„å¤§æ‹¬å·
            match = re.search(r'(\{.*\})', text, re.DOTALL)
            if match:
                json_str = match.group(1)

        # 3. å°è¯•å¤šç§è§£ææ–¹å¼ (ä»…å½“ json_str å­˜åœ¨æ—¶)
        if json_str:
            # æ–¹å¼ A: æ ‡å‡† json.loads
            try:
                return json.loads(json_str)
            except:
                pass
                
            # æ–¹å¼ B: ä¿®å¤å•å¼•å·
            try:
                fixed_json = re.sub(r"'(\w+)'\s*:", r'"\1":', json_str)
                fixed_json = re.sub(r":\s*'([^']*)'", r': "\1"', fixed_json)
                return json.loads(fixed_json)
            except:
                pass

            # æ–¹å¼ C: ast.literal_eval
            try:
                import ast
                return ast.literal_eval(json_str)
            except:
                pass
            
        # æ–¹å¼ D: æš´åŠ›æ­£åˆ™æå– (æ— è®º json_str æ˜¯å¦æå–æˆåŠŸï¼Œéƒ½å°è¯•è¿™ä¸ª)
        # ç›´æ¥ä»åŸå§‹ text ä¸­æœç´¢ï¼Œé˜²æ­¢æ­£åˆ™æ²¡æŠ“åˆ°å¤§æ‹¬å·
        result = {}
        
        # æå– Agent (å¢å¼ºæ­£åˆ™ï¼Œæ”¯æŒä¸­æ–‡å†’å·)
        agent_match = re.search(r'["\']?(?:agent|æ•…éšœæºAgent)["\']?\s*[:ï¼š]\s*["\']?([^"\'\n,}]+)["\']?', text, re.IGNORECASE)
        if agent_match:
            result['agent'] = agent_match.group(1).strip()
            
        # æå– Step
        step_match = re.search(r'["\']?(?:step|æ•…éšœæ—¶é—´æ­¥)["\']?\s*[:ï¼š]\s*(\d+)', text, re.IGNORECASE)
        if step_match:
            result['step'] = int(step_match.group(1))
            
        # æå– Reason
        reason_match = re.search(r'["\']?(?:reason|æ•…éšœåŸå› )["\']?\s*[:ï¼š]\s*["\']?([^"\'}\n]+)["\']?', text, re.IGNORECASE)
        if reason_match:
            result['reason'] = reason_match.group(1).strip()
            
        if 'agent' in result or 'step' in result:
            print(f"  âœ¨ [æš´åŠ›æå–] ä»æ–‡æœ¬ä¸­æˆåŠŸæå–: {result}")
            return result

        return None
        
    except Exception as e:
        print(f"  [è§£æé”™è¯¯] extract_json_from_text æœ€ç»ˆå¤±è´¥: {e}")
        return None


def parse_llm_response(response: str) -> Tuple[Optional[str], Optional[int], Optional[str]]:
    """
    è§£æ LLM å“åº”ï¼Œæå–æ•…éšœæºAgentã€æ—¶é—´æ­¥å’ŒåŸå› 
    æ”¯æŒCoTæ ¼å¼ï¼ˆè·³è¿‡<think>æ ‡ç­¾ï¼‰å’Œ JSON æ ¼å¼
    
    Returns:
        (agent_id, step, reason)
    """
    agent_id = None
    step = None
    reason = None
    
    # ğŸ”¥ é¦–å…ˆå°è¯• JSON æ ¼å¼è§£æï¼ˆæ”¯æŒ Zero-Shot Thinking æ¨¡å¼ï¼‰
    json_data = extract_json_from_text(response)
    if json_data:
        agent_id = json_data.get('agent') or json_data.get('agent_id') or json_data.get('æ•…éšœæºAgent')
        step = json_data.get('step') or json_data.get('step_id') or json_data.get('æ•…éšœæ—¶é—´æ­¥')
        reason = json_data.get('reason') or json_data.get('reasoning') or json_data.get('æ•…éšœåŸå› ')
        if agent_id or step:
            print(f"  [è°ƒè¯•] LLMè§£ææˆåŠŸï¼ˆJSONæ ¼å¼ï¼‰: agent={agent_id}, step={step}")
            return agent_id, step, reason
    
    # ğŸ”¥ å¤„ç†CoTæ ¼å¼ï¼šç§»é™¤<think>...</think>æ ‡ç­¾ï¼Œåªè§£æç»“è®ºéƒ¨åˆ†
    # æå–<think>æ ‡ç­¾å†…çš„å†…å®¹ï¼ˆç”¨äºè°ƒè¯•ï¼Œä½†ä¸ç”¨äºè§£æï¼‰
    think_match = re.search(r'<think>(.*?)</think>', response, re.DOTALL | re.IGNORECASE)
    if think_match:
        # ç§»é™¤<think>æ ‡ç­¾ï¼Œåªä¿ç•™ç»“è®ºéƒ¨åˆ†
        response = re.sub(r'<think>.*?</think>', '', response, flags=re.DOTALL | re.IGNORECASE).strip()
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯æ­£å¸¸åœºæ™¯ï¼ˆæ— æ•…éšœï¼‰
    normal_patterns = [
        r'ç³»ç»Ÿè¿è¡Œæ­£å¸¸',
        r'æ²¡æœ‰å‘ç°æ•…éšœ',
        r'æ²¡æœ‰æ•…éšœ',
        r'è¿è¡Œæ­£å¸¸',
        r'æœªå‘ç°å¼‚å¸¸'
    ]
    is_normal = any(re.search(pattern, response, re.IGNORECASE) for pattern in normal_patterns)
    
    if is_normal:
        return None, None, "ç³»ç»Ÿè¿è¡Œæ­£å¸¸"
    
    # æå– Agentï¼ˆæ”¹è¿›çš„æ­£åˆ™è¡¨è¾¾å¼ï¼‰
    agent_patterns = [
        # æ ¼å¼: **æ•…éšœæºAgent**: Movie_Expert
        r'\*\*æ•…éšœæºAgent\*\*[ï¼š:]\s*([A-Za-z0-9_\-]+)',
        # æ ¼å¼: æ•…éšœæºAgent: Movie_Expert
        r'æ•…éšœæºAgent[ï¼š:]\s*([A-Za-z0-9_\-]+)',
        # æ ¼å¼: æ•…éšœAgent: StreamingService_Expert
        r'æ•…éšœAgent[ï¼š:]\s*([A-Za-z0-9_\-]+)',
        # æ ¼å¼: å¯¼è‡´æ•…éšœçš„Agentæ˜¯ Movie_Expert
        r'å¯¼è‡´æ•…éšœçš„Agentæ˜¯\s+([A-Za-z0-9_\-]+)',
        # æ ¼å¼: Agentæ˜¯ Movie_Expert
        r'Agentæ˜¯\s+([A-Za-z0-9_\-]+)',
        # æ ¼å¼: å€™é€‰Agent 1 (Movie_Expert) æ˜¯æ•…éšœæº
        r'å€™é€‰Agent\s+\d+\s*\(([A-Za-z0-9_\-]+)\)',
        # æ ¼å¼: å€™é€‰Agent 1: Movie_Expert
        r'å€™é€‰Agent\s+\d+[ï¼š:]\s*([A-Za-z0-9_\-]+)',
        # æ ¼å¼: Movie_Expert æ˜¯æ•…éšœæº
        r'([A-Za-z0-9_\-]+)\s+æ˜¯æ•…éšœæº',
        # æ ¼å¼: æ•…éšœæº: Movie_Expert
        r'æ•…éšœæº[ï¼š:]\s*([A-Za-z0-9_\-]+)',
    ]
    for pattern in agent_patterns:
        match = re.search(pattern, response, re.IGNORECASE)
        if match:
            agent_id = match.group(1).strip()
            if agent_id:
                break
    
    # æå–æ—¶é—´æ­¥ï¼ˆæ”¹è¿›çš„æ­£åˆ™è¡¨è¾¾å¼ï¼‰
    step_patterns = [
        # æ ¼å¼: **æ•…éšœæ—¶é—´æ­¥**: 2
        r'\*\*æ•…éšœæ—¶é—´æ­¥\*\*[ï¼š:]\s*(\d+)',
        # æ ¼å¼: æ•…éšœæ—¶é—´æ­¥: 2
        r'æ•…éšœæ—¶é—´æ­¥[ï¼š:]\s*(\d+)',
        # æ ¼å¼: æ•…éšœå‘ç”Ÿåœ¨ç¬¬ 2 æ­¥
        r'æ•…éšœå‘ç”Ÿåœ¨ç¬¬\s*(\d+)\s*æ­¥',
        # æ ¼å¼: å‘ç”Ÿåœ¨ç¬¬ 2 æ­¥
        r'å‘ç”Ÿåœ¨ç¬¬\s*(\d+)\s*æ­¥',
        # æ ¼å¼: æ•…éšœå‘ç”Ÿåœ¨ç¬¬ 2 ä¸ªæ—¶é—´æ­¥
        r'æ•…éšœå‘ç”Ÿåœ¨ç¬¬\s*(\d+)\s*ä¸ªæ—¶é—´æ­¥',
        # æ ¼å¼: æ—¶é—´æ­¥: 2
        r'æ—¶é—´æ­¥[ï¼š:]\s*(\d+)',
        # æ ¼å¼: Step: 3
        r'Step[ï¼š:]\s*(\d+)',
        # æ ¼å¼: æ•…éšœStep: 3
        r'æ•…éšœStep[ï¼š:]\s*(\d+)',
        # æ ¼å¼: ç¬¬ 2 æ­¥
        r'ç¬¬\s*(\d+)\s*æ­¥',
    ]
    for pattern in step_patterns:
        match = re.search(pattern, response, re.IGNORECASE)
        if match:
            try:
                step = int(match.group(1))
                break
            except:
                continue
    
    # æå–åŸå› 
    reason_patterns = [
        r'æ•…éšœåŸå› [ï¼š:]\s*([^ã€‚]+)',
        r'åŸå› [ï¼š:]\s*([^ã€‚]+)',
    ]
    for pattern in reason_patterns:
        match = re.search(pattern, response)
        if match:
            reason = match.group(1).strip()
            break
    
    return agent_id, step, reason


def evaluate_stage3(
    test_data_dir: str,
    gnn_checkpoint: str,
    llm_adapter: str,
    converter_path: str,
    top_k: int = None,  # ğŸ”¥ ä¿®æ”¹é»˜è®¤å€¼ï¼šNone=å…¨è¾“å‡ºï¼Œç”¨äºè¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æ
    device: str = None,
    base_model_name: str = "Qwen/Qwen3-8B"
):
    # ğŸ”¥ Tokenç»Ÿè®¡ï¼šé‡ç½®ç»Ÿè®¡å™¨
    token_counter.reset()
    """
    é˜¶æ®µä¸‰è¯„ä¼°ï¼šCoarse-to-Fine ç³»ç»Ÿé›†æˆ
    
    Args:
        test_data_dir: æµ‹è¯•æ•°æ®ç›®å½•
        gnn_checkpoint: GNN æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„
        llm_adapter: LLM LoRA é€‚é…å™¨è·¯å¾„
        converter_path: Converter çŠ¶æ€è·¯å¾„
        top_k: Top-K å€™é€‰æ•°é‡
        device: è®¾å¤‡ ('cuda' æˆ– 'cpu')
        base_model_name: åŸºç¡€LLMæ¨¡å‹åç§°ï¼ˆé»˜è®¤: Qwen/Qwen2.5-7B-Instructï¼‰
    """
    # è®¾å¤‡é…ç½®
    if device is None:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    else:
        device = torch.device(device)
    
    print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½æ¨¡å‹
    print("\n" + "=" * 60)
    print("åŠ è½½æ¨¡å‹")
    print("=" * 60)
    
    gnn_model, converter, gnn_config = load_gnn_model(gnn_checkpoint, converter_path, device)
    
    # ğŸ”¥ æ¶ˆèå®éªŒæ ‡è®°ï¼šæ£€æŸ¥æ˜¯å¦ä½¿ç”¨æœªå¾®è°ƒçš„æ¨¡å‹
    is_ablation_no_finetune = (not llm_adapter or llm_adapter.strip() == "")
    if is_ablation_no_finetune:
        print("\n" + "=" * 80)
        print("ğŸ”¬ æ¶ˆèå®éªŒé…ç½®ï¼šGNN + æœªå¾®è°ƒçš„åŸºç¡€æ¨¡å‹")
        print("=" * 80)
        print(f"   GNN æ¨¡å‹: {gnn_checkpoint}")
        print(f"   LLM æ¨¡å‹: {base_model_name} (æœªå¾®è°ƒ)")
        print(f"   æ³¨æ„ï¼šLLM æœªç»è¿‡å¾®è°ƒæˆ–å¼ºåŒ–å­¦ä¹ è®­ç»ƒ")
        print("=" * 80 + "\n")
    
    # ğŸ”¥ ä½¿ç”¨ 4-bit é‡åŒ–åŠ è½½ 8B æ¨¡å‹ï¼ˆèŠ‚çœæ˜¾å­˜ï¼‰
    llm_model, tokenizer = load_llm_model(llm_adapter, base_model_name=base_model_name, device=device, use_4bit=True)
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    print("\n" + "=" * 60)
    print("åŠ è½½æµ‹è¯•æ•°æ®")
    print("=" * 60)
    
    test_data_dir = Path(test_data_dir)
    
    # ğŸ”¥ ä¿®å¤ï¼šé€’å½’æœç´¢æ‰€æœ‰å­ç›®å½•ä¸­çš„ JSON æ–‡ä»¶
    # å¦‚æœtest_data_diræœ¬èº«æ˜¯ç›®å½•ï¼Œé€’å½’æœç´¢æ‰€æœ‰å­ç›®å½•ä¸­çš„ JSON æ–‡ä»¶
    if test_data_dir.is_dir():
        json_files = list(test_data_dir.rglob("*.json"))  # ä½¿ç”¨ rglob é€’å½’æœç´¢
    else:
        # å¦‚æœæ˜¯æ–‡ä»¶ï¼Œç›´æ¥ä½¿ç”¨
        json_files = [test_data_dir] if test_data_dir.suffix == '.json' else []
    
    # è¿‡æ»¤æ‰ä¸å­˜åœ¨çš„æ–‡ä»¶
    json_files = [f for f in json_files if f.exists()]
    
    if not json_files:
        print(f"âŒ åœ¨ {test_data_dir} ä¸­æœªæ‰¾åˆ° JSON æ–‡ä»¶")
        print(f"   ç›®å½•æ˜¯å¦å­˜åœ¨: {test_data_dir.exists()}")
        if test_data_dir.exists():
            print(f"   ç›®å½•å†…å®¹: {list(test_data_dir.iterdir())[:10]}")
        return
    
    print(f"âœ… æ‰¾åˆ° {len(json_files)} ä¸ªæµ‹è¯•æ–‡ä»¶")
    print(f"   æµ‹è¯•ç›®å½•: {test_data_dir}")
    
    # è¯„ä¼°
    print("\n" + "=" * 60)
    print("å¼€å§‹è¯„ä¼°")
    print("=" * 60)
    
    metrics_alg = {'agent': [], 'step': []}
    metrics_hand = {'agent': [], 'step': []}
    metrics_total = {'agent': [], 'step': []}
    
    # ğŸ”¥ğŸ”¥ğŸ”¥ã€æ–°å¢ã€‘å­˜å‚¨çœŸå®ç­”æ¡ˆæ’åï¼ˆç”¨äºè¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æï¼‰
    true_agent_ranks = []
    
    # ğŸ”¥ æ–°å¢ï¼šæŒ‰é¢†åŸŸåˆ†ç±»ï¼ˆCode/Math/Agenticï¼‰- ç”¨äºAgenTracerå¯¹æ¯”
    metrics_domains = {}  # {domain: {'agent': [], 'step': []}}
    domain_counts = {}    # {domain: count}
    
    count_alg = 0
    count_hand = 0
    skipped_no_label = 0
    skipped_no_graph = 0
    
    for json_file in tqdm(json_files, desc="è¯„ä¼°ä¸­"):
        try:
            # åŠ è½½å›¾æ•°æ®
            with open(json_file, 'r', encoding='utf-8') as f:
                graph_data = json.load(f)
            
            # é‡å»ºå›¾
            graph = reconstruct_graph_from_json(graph_data)
            graph_list, labels = converter.convert(graph)
            
            if not graph_list:
                skipped_no_graph += 1
                continue
            
            # ğŸ”¥ ç›´æ¥ä» graph_data çš„ ground_truth ä¸­æå–æ ‡ç­¾
            ground_truth = graph_data.get('ground_truth', {})
            true_agent = ground_truth.get('mistake_agent', '')
            true_step = int(ground_truth.get('mistake_step', -1))
            true_reason = ground_truth.get('mistake_reason', '')
            
            # å¦‚æœæ²¡æœ‰çœŸå®æ ‡ç­¾ï¼Œè·³è¿‡
            if not true_agent or true_step < 0:
                skipped_no_label += 1
                continue
            
            # ğŸ”¥ğŸ”¥ğŸ”¥ã€å…³é”®ä¿®å¤ã€‘ä»JSONæ–‡ä»¶è¯»å–æ‰€æœ‰AgentèŠ‚ç‚¹
            # ğŸ”¥ğŸ”¥ğŸ”¥ æ ¸å¿ƒç­–ç•¥ï¼šç›´æ¥ä½¿ç”¨JSONä¸­çš„typeæ ‡è®°ï¼Œä¿¡ä»»æ•°æ®æ ‡æ³¨
            nodes = graph_data.get('nodes', {})
            true_agent_nodes = set()
            
            # ğŸ”¥ğŸ”¥ğŸ”¥ é¦–å…ˆï¼šå¦‚æœground_truthä¸­æœ‰çœŸå®ç­”æ¡ˆï¼Œç¡®ä¿å®ƒè¢«åŒ…å«ï¼ˆå³ä½¿typeæ ‡è®°é”™è¯¯æˆ–å¤§å°å†™ä¸åŒ¹é…ï¼‰
            if true_agent:
                # 1. ç›´æ¥åŒ¹é…
                if true_agent in nodes:
                    true_agent_nodes.add(true_agent)
                # 2. å¤§å°å†™ä¸æ•æ„ŸåŒ¹é…ï¼ˆå¦‚Websurfer vs WebSurferï¼‰
                else:
                    for node_id in nodes.keys():
                        if node_id.lower() == true_agent.lower():
                            true_agent_nodes.add(node_id)
                            break
                    # 3. æ¨¡ç³ŠåŒ¹é…ï¼šå¦‚æœçœŸå®ç­”æ¡ˆæ˜¯"Orchestrator"ï¼Œä½†èŠ‚ç‚¹IDæ˜¯"Orchestrator (thought)"
                    true_agent_base = re.sub(r'\s*\([^)]*\)\s*', '', true_agent).strip()
                    true_agent_base = re.sub(r'\s*->.*', '', true_agent_base).strip()
                    for node_id in nodes.keys():
                        node_id_base = re.sub(r'\s*\([^)]*\)\s*', '', node_id).strip()
                        node_id_base = re.sub(r'\s*->.*', '', node_id_base).strip()
                        if node_id_base.lower() == true_agent_base.lower() and node_id_base:
                            true_agent_nodes.add(node_id_base)  # ä½¿ç”¨åŸºç¡€åç§°ï¼ˆä¸å¸¦æ‹¬å·ï¼‰
                            break
            
            # ğŸ”¥ğŸ”¥ğŸ”¥ æ ¸å¿ƒé€»è¾‘ï¼šç›´æ¥ä½¿ç”¨JSONä¸­çš„typeæ ‡è®°ï¼Œä½†è¿‡æ»¤æ˜æ˜¾é”™è¯¯çš„æ ‡è®°
            # æ˜æ˜¾ä¸æ˜¯Agentçš„èŠ‚ç‚¹åç§°ï¼ˆå³ä½¿è¢«æ ‡è®°ä¸ºAgentä¹Ÿåº”è¯¥è¿‡æ»¤ï¼‰
            invalid_agent_names = {
                # å…ƒæ•°æ®/å±æ€§åç§°
                'context', 'type', 'id', 'name', 'graph', 'node', 'edge',
                'metadata', 'attribute', 'property', 'field', 'value', 'key', 'data',
                # ç½‘ç«™/å¹³å°åç§°ï¼ˆå…¨å°å†™ï¼‰
                'sportskeeda', 'benandjerrys', 'marketwatch', 'imdb', 'github', 
                'googlegroups', 'worldbankdata', 'liicornell', 'amelia', 'mamtaraut10',
                # å…¶ä»–æ˜æ˜¾ä¸æ˜¯Agentçš„åç§°
                'url', 'link', 'href', 'src', 'path', 'file', 'dir', 'folder',
                # å¸¸è§çš„ç½‘ç«™/æœåŠ¡åç§°
                'youtube', 'gmail', 'turboscribe', 'linkedin', 'twitter', 'facebook', 
                'instagram', 'amazon', 'wikipedia', 'netflix', 'spotify', 'reddit', 
                'pinterest', 'tumblr'
            }
            
            # å¸¸è§çš„äººå/ç”¨æˆ·åæ¨¡å¼ï¼ˆCamelCaseï¼Œçœ‹èµ·æ¥åƒäººåä½†ä¸æ˜¯Agentï¼‰
            common_person_names = {
                'angela', 'pingu', 'rosieroan', 'thesmart', 'goranxii', 'johndownerprod'
            }
            
            for node_id, node_data in nodes.items():
                # ç¡®ä¿node_dataæ˜¯å­—å…¸ç±»å‹
                if not isinstance(node_data, dict):
                    continue
                
                node_type = node_data.get('type', '')
                
                # ğŸ”¥ğŸ”¥ğŸ”¥ å…³é”®ï¼šç›´æ¥ä¿¡ä»»JSONä¸­çš„typeæ ‡è®°ï¼Œä½†è¿‡æ»¤æ˜æ˜¾é”™è¯¯çš„æ ‡è®°
                if node_type == 'Agent':
                    node_id_lower = node_id.lower()
                    
                    # åªè¿‡æ»¤human/userèŠ‚ç‚¹ï¼ˆè¿™äº›æ˜¯ç”¨æˆ·ï¼Œä¸æ˜¯Agentï¼‰
                    if node_id_lower in ['human', 'user', 'user_proxy'] or node_id_lower.startswith('user') or node_id_lower.startswith('human'):
                        continue
                    
                    # ğŸ”¥ğŸ”¥ğŸ”¥ è¿‡æ»¤æ˜æ˜¾ä¸æ˜¯Agentçš„èŠ‚ç‚¹ï¼ˆå³ä½¿è¢«æ ‡è®°ä¸ºAgentï¼‰
                    if node_id_lower in invalid_agent_names:
                        continue
                    
                    # ğŸ”¥ğŸ”¥ğŸ”¥ è¿‡æ»¤çº¯æ•°å­—æˆ–å•å­—ç¬¦èŠ‚ç‚¹ï¼ˆå¦‚'3'ï¼‰
                    if node_id.isdigit() or (len(node_id) == 1 and not node_id.isalpha()):
                        continue
                    
                    # ğŸ”¥ğŸ”¥ğŸ”¥ è¿‡æ»¤çœ‹èµ·æ¥åƒå…ƒæ•°æ®/å±æ€§çš„èŠ‚ç‚¹ï¼ˆå…¨å°å†™ä¸”é•¿åº¦<=5ï¼Œå¦‚context, typeç­‰ï¼‰
                    # ğŸ”¥ å…³é”®ï¼šid, context, typeè¿™äº›å•å­—ç¬¦æˆ–çŸ­å•è¯æ˜æ˜¾æ˜¯å…ƒæ•°æ®ï¼Œä¸æ˜¯Agent
                    if node_id.islower() and len(node_id) <= 5:
                        # åªä¿ç•™æ˜ç¡®çš„Agentåç§°
                        if node_id not in ['assistant', 'surfer', 'orchestrator', 'websurfer', 'filesurfer']:
                            continue
                    
                    # ğŸ”¥ğŸ”¥ğŸ”¥ æ–°å¢ï¼šè¿‡æ»¤å…¨å°å†™çš„å•è¯è¯­ï¼ˆå¯èƒ½æ˜¯ç½‘ç«™åã€ç”¨æˆ·åç­‰ï¼Œä½†ä¸æ˜¯çœŸæ­£çš„Agentï¼‰
                    # å¦‚æœèŠ‚ç‚¹åæ˜¯å…¨å°å†™ä¸”ä¸åŒ…å«ä¸‹åˆ’çº¿æˆ–è¿å­—ç¬¦ï¼Œä¸”é•¿åº¦>5ï¼Œå¾ˆå¯èƒ½æ˜¯ç½‘ç«™åæˆ–ç”¨æˆ·å
                    if node_id.islower() and '_' not in node_id and '-' not in node_id and len(node_id) > 5:
                        # ä½†ä¿ç•™å¸¸è§çš„Agentåç§°
                        if node_id not in ['assistant', 'orchestrator', 'websurfer', 'surfer', 'coordinator']:
                            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ•°å­—ï¼ˆå¦‚mamtaraut10ï¼‰
                            if re.search(r'\d', node_id):
                                continue
                            # æ£€æŸ¥æ˜¯å¦æ˜¯å¸¸è§çš„ç½‘ç«™åŸŸåæ¨¡å¼ï¼ˆå¦‚sportskeeda, benandjerrysç­‰ï¼‰
                            if any(char.isdigit() for char in node_id) or len(node_id) > 10:
                                continue
                    
                    # ğŸ”¥ğŸ”¥ğŸ”¥ æ–°å¢ï¼šè¿‡æ»¤åŒ…å«æ•°å­—çš„èŠ‚ç‚¹ï¼ˆå¦‚MamtaRaut10ç­‰ï¼Œä½†ä¿ç•™IMDB_Ratings_Expertè¿™ç§ï¼‰
                    if re.search(r'\d', node_id) and not (node_id.endswith('Expert') or node_id.endswith('_Expert')):
                        # å¦‚æœåŒ…å«æ•°å­—ä½†ä¸æ˜¯Expertç»“å°¾ï¼Œå¾ˆå¯èƒ½æ˜¯ç”¨æˆ·åæˆ–ID
                        # ä½†æ’é™¤å¸¸è§çš„Agentåç§°ï¼ˆå¦‚WebSurfer, Assistantç­‰ï¼‰
                        if node_id not in ['WebSurfer', 'Assistant', 'Orchestrator', 'FileSurfer']:
                            continue
                    
                    # ğŸ”¥ğŸ”¥ğŸ”¥ æ–°å¢ï¼šè¿‡æ»¤CamelCaseæ ¼å¼ä½†çœ‹èµ·æ¥åƒäººåçš„èŠ‚ç‚¹ï¼ˆå¦‚MamtaRaut10ç­‰ï¼‰
                    # å¦‚æœèŠ‚ç‚¹åæ˜¯CamelCaseä¸”åŒ…å«æ•°å­—ï¼Œå¾ˆå¯èƒ½æ˜¯ç”¨æˆ·å
                    if re.match(r'^[A-Z][a-z]+.*\d', node_id) and not (node_id.endswith('Expert') or node_id.endswith('_Expert')):
                        if node_id not in ['WebSurfer', 'Assistant', 'Orchestrator', 'FileSurfer']:
                            continue
                    
                    # ğŸ”¥ğŸ”¥ğŸ”¥ æ–°å¢ï¼šè¿‡æ»¤çœ‹èµ·æ¥åƒäººåçš„CamelCaseèŠ‚ç‚¹ï¼ˆå¦‚Angela, Pingu, RosieRoanç­‰ï¼‰
                    # è¿™äº›é€šå¸¸æ˜¯YouTubeè¯„è®ºè€…ã€ç¤¾äº¤åª’ä½“ç”¨æˆ·ç­‰ï¼Œä¸æ˜¯Agent
                    if node_id_lower in common_person_names:
                        continue
                    
                    # ğŸ”¥ğŸ”¥ğŸ”¥ æ–°å¢ï¼šè¿‡æ»¤çº¯CamelCaseä¸”çœ‹èµ·æ¥åƒäººåçš„èŠ‚ç‚¹ï¼ˆä¸åŒ…å«ä¸‹åˆ’çº¿ã€è¿å­—ç¬¦ã€æ•°å­—ï¼Œä¸”ä¸ä»¥Expertç»“å°¾ï¼‰
                    # å¦‚ï¼šAngela, Pingu, RosieRoan, TheSmart, GoranXII, JohnDownerProd
                    if re.match(r'^[A-Z][a-z]+([A-Z][a-z]+)*$', node_id) and not (node_id.endswith('Expert') or node_id.endswith('_Expert')):
                        # æ’é™¤æ˜ç¡®çš„Agentåç§°
                        if node_id not in ['WebSurfer', 'Assistant', 'Orchestrator', 'FileSurfer', 'TalkNotesApp', 'TurboScribe']:
                            # å¦‚æœèŠ‚ç‚¹åçœ‹èµ·æ¥åƒäººåï¼ˆé¦–å­—æ¯å¤§å†™+å°å†™å­—æ¯ç»„åˆï¼Œä¸”é•¿åº¦é€‚ä¸­ï¼‰ï¼Œå¾ˆå¯èƒ½æ˜¯ç”¨æˆ·å
                            # ä½†ä¿ç•™ä¸€äº›å¸¸è§çš„Agentåç§°æ¨¡å¼
                            if len(node_id) <= 15 and not node_id.startswith('Web') and not node_id.startswith('File') and not node_id.startswith('Talk') and not node_id.startswith('Turbo'):
                                continue
                    
                    # ğŸ”¥ğŸ”¥ğŸ”¥ æ–°å¢ï¼šè¿‡æ»¤åŒ…å«æ•°å­—ä¸”çœ‹èµ·æ¥åƒç”¨æˆ·åçš„èŠ‚ç‚¹ï¼ˆå¦‚Topgoon634, Aroundthebonfire884ç­‰ï¼‰
                    # è¿™äº›é€šå¸¸æ˜¯YouTubeç”¨æˆ·åã€ç¤¾äº¤åª’ä½“è´¦å·ç­‰
                    if re.search(r'\d', node_id) and not (node_id.endswith('Expert') or node_id.endswith('_Expert')):
                        # å¦‚æœèŠ‚ç‚¹ååŒ…å«æ•°å­—ä¸”çœ‹èµ·æ¥åƒç”¨æˆ·åï¼ˆå…¨å°å†™æˆ–æ··åˆå¤§å°å†™ï¼Œé•¿åº¦è¾ƒé•¿ï¼‰
                        if node_id not in ['WebSurfer', 'Assistant', 'Orchestrator', 'FileSurfer']:
                            # æ£€æŸ¥æ˜¯å¦æ˜¯ç”¨æˆ·åæ¨¡å¼ï¼ˆåŒ…å«æ•°å­—ï¼Œä¸”ä¸æ˜¯Expertç»“å°¾ï¼‰
                            if len(node_id) > 10 or (re.search(r'\d', node_id) and not node_id[0].isupper()):
                                continue
                    
                    # ğŸ”¥ğŸ”¥ğŸ”¥ æ–°å¢ï¼šè¿‡æ»¤ä¸­æ–‡å­—ç¬¦èŠ‚ç‚¹ï¼ˆå¦‚'èƒ¡çƒ'ï¼‰ï¼Œé™¤éæ˜¯æ˜ç¡®çš„Agentåç§°
                    if re.search(r'[\u4e00-\u9fff]', node_id):
                        # ä¸­æ–‡å­—ç¬¦èŠ‚ç‚¹é€šå¸¸æ˜¯ç”¨æˆ·åæˆ–è¯„è®ºè€…ï¼Œä¸æ˜¯Agent
                        continue
                    
                    # ğŸ”¥ğŸ”¥ğŸ”¥ å¤„ç†å¸¦æ‹¬å·çš„èŠ‚ç‚¹ï¼šæå–åŸºç¡€åç§°
                    # å¦‚ "Orchestrator (thought)" -> "Orchestrator"
                    # å¦‚ "Orchestrator (-> WebSurfer)" -> "Orchestrator"
                    if '(' in node_id or ')' in node_id or '->' in node_id or 'â†’' in node_id:
                        node_id_base = re.sub(r'\s*\([^)]*\)\s*', '', node_id).strip()
                        node_id_base = re.sub(r'\s*->.*', '', node_id_base).strip()
                        if node_id_base:  # å¦‚æœæå–åˆ°åŸºç¡€åç§°ï¼Œä½¿ç”¨åŸºç¡€åç§°
                            # å†æ¬¡æ£€æŸ¥åŸºç¡€åç§°æ˜¯å¦æœ‰æ•ˆ
                            node_id_base_lower = node_id_base.lower()
                            # æ£€æŸ¥æ˜¯å¦åœ¨æ— æ•ˆåˆ—è¡¨ä¸­
                            if node_id_base_lower in invalid_agent_names:
                                continue
                            # æ£€æŸ¥æ˜¯å¦æ˜¯çº¯æ•°å­—æˆ–å•å­—ç¬¦
                            if node_id_base.isdigit() or (len(node_id_base) == 1 and not node_id_base.isalpha()):
                                continue
                            # æ£€æŸ¥æ˜¯å¦æ˜¯å…ƒæ•°æ®/å±æ€§èŠ‚ç‚¹
                            if node_id_base.islower() and len(node_id_base) <= 5:
                                if node_id_base not in ['assistant', 'surfer', 'orchestrator', 'websurfer', 'filesurfer']:
                                    continue
                            # æ£€æŸ¥æ˜¯å¦æ˜¯äººå
                            if node_id_base_lower in common_person_names:
                                continue
                            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ•°å­—ï¼ˆä½†ä¿ç•™Expertç»“å°¾çš„ï¼‰
                            if re.search(r'\d', node_id_base) and not (node_id_base.endswith('Expert') or node_id_base.endswith('_Expert')):
                                if node_id_base not in ['WebSurfer', 'Assistant', 'Orchestrator', 'FileSurfer', 'TalkNotesApp', 'TurboScribe']:
                                    if len(node_id_base) > 10 or (re.search(r'\d', node_id_base) and not node_id_base[0].isupper()):
                                        continue
                            # æ£€æŸ¥æ˜¯å¦æ˜¯CamelCaseæ ¼å¼ä½†åŒ…å«æ•°å­—çš„èŠ‚ç‚¹
                            if re.match(r'^[A-Z][a-z]+.*\d', node_id_base) and not (node_id_base.endswith('Expert') or node_id_base.endswith('_Expert')):
                                if node_id_base not in ['WebSurfer', 'Assistant', 'Orchestrator', 'FileSurfer', 'TalkNotesApp', 'TurboScribe']:
                                    continue
                            # æ£€æŸ¥æ˜¯å¦æ˜¯çº¯CamelCaseä¸”çœ‹èµ·æ¥åƒäººåçš„èŠ‚ç‚¹
                            if re.match(r'^[A-Z][a-z]+([A-Z][a-z]+)*$', node_id_base) and not (node_id_base.endswith('Expert') or node_id_base.endswith('_Expert')):
                                if node_id_base not in ['WebSurfer', 'Assistant', 'Orchestrator', 'FileSurfer', 'TalkNotesApp', 'TurboScribe']:
                                    if len(node_id_base) <= 15 and not node_id_base.startswith('Web') and not node_id_base.startswith('File') and not node_id_base.startswith('Talk') and not node_id_base.startswith('Turbo'):
                                        continue
                            # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦
                            if re.search(r'[\u4e00-\u9fff]', node_id_base):
                                continue
                            true_agent_nodes.add(node_id_base)
                    else:
                        # ä¸å¸¦æ‹¬å·çš„èŠ‚ç‚¹ï¼Œç›´æ¥ä½¿ç”¨
                        true_agent_nodes.add(node_id)
            
            if not true_agent_nodes:
                print(f"  âš ï¸ [è­¦å‘Š] ä»JSONæ–‡ä»¶ä¸­æœªæ‰¾åˆ°ä»»ä½•AgentèŠ‚ç‚¹ï¼ˆå¯èƒ½å…¨éƒ¨è¢«è¿‡æ»¤ï¼‰")
            else:
                print(f"  ğŸ“‹ [AgentéªŒè¯] ä»JSONæ–‡ä»¶è¯»å–åˆ° {len(true_agent_nodes)} ä¸ªAgentèŠ‚ç‚¹: {sorted(list(true_agent_nodes))}")
            
            # 1. GNN é¢„æµ‹å€™é€‰ï¼ˆåŒæ—¶è·å–Stepé¢„æµ‹ï¼‰
            # ğŸ”¥ æ–°å¢ï¼šæ”¯æŒå…¨è¾“å‡ºæ¨¡å¼ï¼ˆtop_k=None æ—¶è¿”å›æ‰€æœ‰Agentæ’åºï¼‰
            # ğŸ”¥ğŸ”¥ğŸ”¥ ä¼ å…¥ä»JSONæ–‡ä»¶è¯»å–çš„çœŸå®AgentèŠ‚ç‚¹åˆ—è¡¨
            all_agent_ranking = None
            agent_scores = None
            try:
                gnn_result = predict_top_k_with_gnn(
                    gnn_model, graph_list, converter, gnn_config, device, top_k=top_k, true_agent_nodes=true_agent_nodes
                )
                
                # å¤„ç†ä¸¤ç§è¿”å›æ ¼å¼
                if top_k is None:
                    # å…¨è¾“å‡ºæ¨¡å¼ï¼šè¿”å› (æ‰€æœ‰Agentæ’åº, åˆ†æ•°å­—å…¸, Stepé¢„æµ‹)
                    all_agent_ranking, agent_scores, gnn_pred_step = gnn_result
                    candidate_agent_ids = all_agent_ranking  # ä½¿ç”¨å®Œæ•´æ’åºä½œä¸ºå€™é€‰
                else:
                    # Top-K æ¨¡å¼ï¼šè¿”å› (Top-Kåˆ—è¡¨, Stepé¢„æµ‹)
                    candidate_agent_ids, gnn_pred_step = gnn_result
            except RuntimeError as e:
                if "mat1 and mat2 shapes cannot be multiplied" in str(e):
                    # ç»´åº¦ä¸åŒ¹é…é”™è¯¯ï¼Œè·³è¿‡è¿™ä¸ªæ ·æœ¬
                    skipped_no_label += 1
                    continue
                else:
                    raise
            
            # ================= [å…³é”®ä¿®å¤] ç‰©ç†å±è”½ human/user =================
            # ğŸ”¥ğŸ”¥ğŸ”¥ æœ€å…³é”®ï¼šGNN æ€»æ˜¯æŠŠç”¨æˆ·èŠ‚ç‚¹å½“ä½œé‡è¦èŠ‚ç‚¹æ¨èï¼Œè¿™æ˜¯å¹²æ‰°æº
            # å¿…é¡»åœ¨ä»£ç é‡Œå¼ºè¡Œè¿‡æ»¤ï¼Œé˜²æ­¢ LLM å½’å› ç»™ç”¨æˆ·
            # æ•…éšœå½’å› ç»ä¸åº”è¯¥å½’å› ç»™ç”¨æˆ·ï¼ˆhumanï¼‰ï¼Œæ ‡ç­¾é‡Œæ°¸è¿œæ˜¯å…·ä½“çš„ Agent
            
            # å®šä¹‰é»‘åå•
            blacklist = ['human', 'user', 'user_proxy', 'admin', 'root', 'system']
            
            # è¿‡æ»¤å€™é€‰åˆ—è¡¨ï¼ˆä½¿ç”¨éƒ¨åˆ†åŒ¹é…ï¼Œé˜²æ­¢ User_1 æ¼ç½‘ï¼‰
            filtered_candidate_agent_ids = []
            for agent_name in candidate_agent_ids:
                agent_lower = agent_name.lower()
                # ä½¿ç”¨éƒ¨åˆ†åŒ¹é… (ä¾‹å¦‚è¿‡æ»¤ User_1, Human_Agent)
                is_blacklisted = any(b == agent_lower for b in blacklist) or \
                                 agent_lower.startswith('user') or \
                                 agent_lower.startswith('human')
                
                if not is_blacklisted:
                    filtered_candidate_agent_ids.append(agent_name)
            
            # å¦‚æœè¿‡æ»¤å®Œç©ºäº†ï¼ˆæå°‘æƒ…å†µï¼‰ï¼Œå°è¯•è·å–æ›´å¤šå€™é€‰
            if len(filtered_candidate_agent_ids) == 0 and len(candidate_agent_ids) > 0:
                if top_k is not None:
                    print(f"  âš ï¸ [è­¦å‘Š] è¿‡æ»¤åå€™é€‰åˆ—è¡¨ä¸ºç©ºï¼Œå°è¯•è·å–æ›´å¤šå€™é€‰ï¼ˆtop_k={top_k*2}ï¼‰")
                    try:
                        extended_result = predict_top_k_with_gnn(
                            gnn_model, graph_list, converter, gnn_config, device, top_k=top_k*2
                        )
                        extended_candidates, _ = extended_result
                        filtered_candidate_agent_ids = []
                        for agent in extended_candidates:
                            agent_lower = agent.lower()
                            is_blacklisted = any(b == agent_lower for b in blacklist) or \
                                             agent_lower.startswith('user') or \
                                             agent_lower.startswith('human')
                            if not is_blacklisted:
                                filtered_candidate_agent_ids.append(agent)
                        if filtered_candidate_agent_ids:
                            print(f"  âœ… [æ¢å¤] ä»æ‰©å±•å€™é€‰åˆ—è¡¨ä¸­æ‰¾åˆ°äº† {len(filtered_candidate_agent_ids)} ä¸ªæœ‰æ•ˆå€™é€‰")
                        else:
                            # å¦‚æœè¿˜æ˜¯ä¸ºç©ºï¼Œè‡³å°‘ä¿ç•™ä¸€ä¸ªéhumançš„å€™é€‰
                            print(f"  âš ï¸ [è­¦å‘Š] æ‰©å±•å€™é€‰åä»ä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹å€™é€‰ï¼ˆå¯èƒ½åŒ…å«humanèŠ‚ç‚¹ï¼‰")
                            filtered_candidate_agent_ids = candidate_agent_ids[:1] if candidate_agent_ids else []
                    except Exception as e:
                        print(f"  âš ï¸ [è­¦å‘Š] è·å–æ‰©å±•å€™é€‰å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹å€™é€‰")
                        filtered_candidate_agent_ids = candidate_agent_ids[:1] if candidate_agent_ids else []
                else:
                    # å…¨è¾“å‡ºæ¨¡å¼ä¸‹ï¼Œå¦‚æœè¿‡æ»¤åä¸ºç©ºï¼Œè‡³å°‘ä¿ç•™ä¸€ä¸ª
                    print(f"  âš ï¸ [è­¦å‘Š] å…¨è¾“å‡ºæ¨¡å¼ä¸‹è¿‡æ»¤åå€™é€‰åˆ—è¡¨ä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹å€™é€‰")
                    filtered_candidate_agent_ids = candidate_agent_ids[:1] if candidate_agent_ids else []
            
            # æ›´æ–°å€™é€‰äººåˆ—è¡¨
            original_candidate_count = len(candidate_agent_ids)
            candidate_agent_ids = filtered_candidate_agent_ids
            
            if original_candidate_count > len(candidate_agent_ids):
                filtered_count = original_candidate_count - len(candidate_agent_ids)
                print(f"  ğŸ”’ [è¿‡æ»¤] å·²è¿‡æ»¤ {filtered_count} ä¸ªç”¨æˆ·èŠ‚ç‚¹ï¼ˆhuman/userç­‰ï¼‰ï¼Œå‰©ä½™ {len(candidate_agent_ids)} ä¸ªå€™é€‰Agent")
            
            # ğŸ”¥ğŸ”¥ğŸ”¥ã€æ–°å¢ã€‘å…¨è¾“å‡ºæ¨¡å¼ï¼šè®°å½•å®Œæ•´æ’åºå’ŒçœŸå®ç­”æ¡ˆæ’å
            if top_k is None and all_agent_ranking is not None:
                # è¿‡æ»¤å®Œæ•´æ’åºï¼ˆç§»é™¤human/userèŠ‚ç‚¹ï¼‰
                filtered_full_ranking = []
                filtered_agent_scores = {}
                for agent in all_agent_ranking:
                    agent_lower = agent.lower()
                    is_blacklisted = any(b == agent_lower for b in blacklist) or \
                                     agent_lower.startswith('user') or \
                                     agent_lower.startswith('human')
                    if not is_blacklisted:
                        filtered_full_ranking.append(agent)
                        if agent_scores:
                            filtered_agent_scores[agent] = agent_scores.get(agent, 0.0)
                
                # ğŸ”¥ğŸ”¥ğŸ”¥ã€æ–°å¢ã€‘éªŒè¯ï¼šå¦‚æœçœŸå®ç­”æ¡ˆä¸åœ¨è¾“å‡ºä¸­ï¼Œä¸”å®ƒæ˜¯AgentèŠ‚ç‚¹ï¼Œåˆ™æ·»åŠ å®ƒ
                if true_agent and true_agent not in filtered_full_ranking:
                    # æ£€æŸ¥çœŸå®ç­”æ¡ˆæ˜¯å¦æ˜¯Agentç±»å‹èŠ‚ç‚¹
                    graph = graph_list[0] if graph_list else None
                    if graph and graph.node_id_to_idx:
                        node_id_to_idx = graph.node_id_to_idx
                        if true_agent in node_id_to_idx:
                            node_type = node_id_to_idx[true_agent][0]
                            if node_type == 'Agent':
                                # çœŸå®ç­”æ¡ˆæ˜¯AgentèŠ‚ç‚¹ï¼Œä½†ä¸åœ¨è¾“å‡ºä¸­ï¼Œæ·»åŠ å®ƒï¼ˆä½¿ç”¨æœ€ä½åˆ†æ•°ï¼‰
                                min_score = min(filtered_agent_scores.values()) if filtered_agent_scores else -10.0
                                filtered_full_ranking.append(true_agent)
                                filtered_agent_scores[true_agent] = float(min_score - 1.0)
                                print(f"  âš ï¸ [è¾“å‡ºéªŒè¯] çœŸå®ç­”æ¡ˆ '{true_agent}' ä¸åœ¨GNNè¾“å‡ºä¸­ï¼Œå·²æ·»åŠ ï¼ˆå®ƒæ˜¯AgentèŠ‚ç‚¹ï¼‰")
                
                # è®¡ç®—çœŸå®ç­”æ¡ˆåœ¨å®Œæ•´æ’åºä¸­çš„æ’åï¼ˆä»1å¼€å§‹ï¼‰
                true_agent_rank = None
                if true_agent:
                    try:
                        true_agent_rank = filtered_full_ranking.index(true_agent) + 1
                    except ValueError:
                        # çœŸå®ç­”æ¡ˆä¸åœ¨æ’åºä¸­
                        true_agent_rank = -1
                
                # ğŸ”¥ è¾“å‡ºå®Œæ•´æ’åºä¿¡æ¯ï¼ˆç”¨äºåç»­åˆ†æï¼‰
                print(f"  ğŸ“Š [å®Œæ•´æ’åº] GNNè¾“å‡ºçš„æ‰€æœ‰Agentæ’åºï¼ˆå…±{len(filtered_full_ranking)}ä¸ªï¼‰:")
                ranking_str = ", ".join([f"{i+1}.{agent}" for i, agent in enumerate(filtered_full_ranking[:20])])  # åªæ˜¾ç¤ºå‰20ä¸ª
                if len(filtered_full_ranking) > 20:
                    ranking_str += f" ... (å…±{len(filtered_full_ranking)}ä¸ª)"
                print(f"    {ranking_str}")
                if true_agent_rank and true_agent_rank > 0:
                    print(f"  ğŸ“Š [çœŸå®ç­”æ¡ˆæ’å] çœŸå®Agent '{true_agent}' åœ¨å®Œæ•´æ’åºä¸­çš„æ’å: ç¬¬ {true_agent_rank} ä½")
                elif true_agent_rank == -1:
                    print(f"  âš ï¸ [çœŸå®ç­”æ¡ˆæ’å] çœŸå®Agent '{true_agent}' ä¸åœ¨å®Œæ•´æ’åºä¸­")
            
            print(f"  [è°ƒè¯•] è¿‡æ»¤åçš„GNNå€™é€‰: {candidate_agent_ids}")
            # ==============================================================
            
            # 2. æå–å€™é€‰Agentæ—¥å¿—
            nodes = graph_data.get('nodes', {})
            history = graph_data.get('history', [])
            
            agent_logs = extract_agent_logs(nodes, candidate_agent_ids, history)
            
            # 2.5. æå–ç³»ç»Ÿå…³é”®æŠ¥é”™ä¿¡æ¯ï¼ˆComputer_terminalç­‰çš„æŠ¥é”™ï¼‰
            system_errors = []
            tool_node_keywords = ['terminal', 'computer', 'console', 'broadcast', 'env', 'environment']
            
            for node_id, node_data in nodes.items():
                node_id_lower = node_id.lower()
                # æ£€æŸ¥æ˜¯å¦æ˜¯å·¥å…·èŠ‚ç‚¹
                if any(kw in node_id_lower for kw in tool_node_keywords):
                    # æå–è¯¥èŠ‚ç‚¹çš„é”™è¯¯ä¿¡æ¯
                    features = node_data.get('features', {})
                    if isinstance(features, dict):
                        # æŒ‰æ—¶é—´æ­¥æ’åºï¼Œå–æœ€åå‡ ä¸ªæ—¶é—´æ­¥ï¼ˆé€šå¸¸é”™è¯¯åœ¨æœ€åï¼‰
                        sorted_timesteps = sorted(features.keys(), key=lambda x: int(x) if str(x).isdigit() else 0)
                        # åªå–æœ€å3ä¸ªæ—¶é—´æ­¥
                        for t in sorted_timesteps[-3:]:
                            feat = features[t]
                            if isinstance(feat, dict):
                                content_text = (
                                    feat.get('content_text', '') or 
                                    feat.get('content', '') or
                                    feat.get('text', '')
                                )
                                # æ£€æŸ¥æ˜¯å¦åŒ…å«é”™è¯¯å…³é”®è¯
                                if content_text and any(keyword in content_text.lower() for keyword in 
                                    ['error', 'exception', 'fail', 'failed', 'failure', 'traceback', 'exception']):
                                    system_errors.append(f"[Step {t}] {node_id}: {content_text[:300]}")
            
            # 3. æ„å»º LLM è¾“å…¥
            # ğŸ”¥ğŸ”¥ğŸ”¥ã€å…³é”®ä¿®å¤ã€‘åˆ†ç¦» System Promptï¼Œè§£å†³æ ¼å¼å†²çª
            sys_prompt = "You are a helpful assistant. You must first think step-by-step in <think> tags, and then OUTPUT THE FINAL JSON ANSWER. Do not stop in the middle of thinking - you must complete your reasoning and provide the final JSON answer."
            
            instruction = f"""è¿™æ˜¯ä¸€ä¸ªå¤šAgentç³»ç»Ÿçš„æ•…éšœè¯Šæ–­ä»»åŠ¡ã€‚ç³»ç»Ÿæ‰§è¡Œå¤±è´¥äº†ï¼Œä½ éœ€è¦æ‰¾å‡º**æ ¹å› Agent**ã€‚

"""
            
            # 3.1. æ·»åŠ ç³»ç»Ÿå…³é”®æŠ¥é”™ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            if system_errors:
                instruction += f"""**ã€ç³»ç»Ÿå…³é”®æŠ¥é”™ä¿¡æ¯ã€‘**ï¼ˆè¿™äº›æ˜¯å·¥å…·èŠ‚ç‚¹çš„æŠ¥é”™ï¼Œç”¨äºå®šä½æ ¹å› ï¼‰ï¼š
{chr(10).join(system_errors[:5])}

**é‡è¦**ï¼šè¿™äº›æŠ¥é”™æ˜¯**ç—‡çŠ¶**ï¼Œä¸æ˜¯ç—…å› ã€‚è¯·æ‰¾å‡ºæ˜¯**å“ªä¸ªAgent**å¼•å‘äº†è¿™äº›æŠ¥é”™ã€‚

"""
            
            instruction += f"""GNNæ¨¡å‹å·²ç»åŸºäºå›¾ç»“æ„æ’é™¤äº†å·¥å…·å’Œç¯å¢ƒèŠ‚ç‚¹ï¼Œé”å®šäº†ä»¥ä¸‹ {len(candidate_agent_ids)} ä¸ªæœ€å¯ç–‘çš„Agentï¼š

"""
            for i, agent_id in enumerate(candidate_agent_ids, 1):
                # æ ‡è®° GNN çš„ç½®ä¿¡åº¦æ’å
                rank_str = ["(GNNè®¤ä¸ºæœ€å¯ç–‘)", "(GNNè®¤ä¸ºæ¬¡å¯ç–‘)", ""][i-1] if i <= 2 else ""
                
                # ğŸ”¥ğŸ”¥ğŸ”¥ã€ä¼˜åŒ–ã€‘æ™ºèƒ½æˆªæ–­è¿‡é•¿çš„æ—¥å¿— (ä¿ç•™å¤´å°¾ï¼Œå¢åŠ å¤´éƒ¨é•¿åº¦)
                raw_log = agent_logs.get(agent_id, f"Agent {agent_id}: æ— æ—¥å¿—")
                MAX_LOG_LEN = 2500
                if len(raw_log) > MAX_LOG_LEN:
                    # ä¿ç•™å‰ 800 å­—ç¬¦ (çœ‹åˆå§‹é…ç½®) å’Œ å 1700 å­—ç¬¦ (çœ‹æŠ¥é”™)
                    head = raw_log[:800]
                    tail = raw_log[-1700:]
                    log_content = f"{head}\n\n... [æ—¥å¿—è¿‡é•¿ï¼Œä¸­é—´ {len(raw_log)-2500} å­—ç¬¦å·²çœç•¥] ...\n\n{tail}"
                    print(f"  âš ï¸ [æ—¥å¿—æˆªæ–­] {agent_id} æ—¥å¿—ä¿ç•™å¤´å°¾ (æ€»é•¿ {len(raw_log)})")
                else:
                    log_content = raw_log
                
                instruction += f"**å€™é€‰ {i}: {agent_id}** {rank_str}\n{log_content}\n\n"
            
            instruction += f"""è¯·ä»”ç»†åˆ†æè¿™äº›å€™é€‰Agentçš„æ—¥å¿—ï¼Œæ‰¾å‡ºå¯¼è‡´ä»»åŠ¡å¤±è´¥çš„**æ ¹å› **ã€‚

**ğŸš¨ å…³é”®è§„åˆ™ï¼ˆè¿åå¿…é”™ï¼‰**ï¼š
1. **ç»å¯¹ä¸è¦é€‰ Computer_terminalã€Broadcastã€Environmentã€Tool ç­‰å·¥å…·èŠ‚ç‚¹**ï¼š
   - è¿™äº›æ˜¯å·¥å…·ï¼Œä¸æ˜¯Agentã€‚å®ƒä»¬æŠ¥é”™æ˜¯å› ä¸ºæ”¶åˆ°äº†é”™è¯¯çš„æŒ‡ä»¤æˆ–æ•°æ®ã€‚
   - è¯·æ‰¾å‡º**æ˜¯è°å‘å‡ºçš„é”™è¯¯æŒ‡ä»¤**æˆ–**æ˜¯è°ç”Ÿæˆäº†é”™è¯¯æ•°æ®**ï¼Œé‚£ä¸ªAgentæ‰æ˜¯æ ¹å› ã€‚
   - ä¾‹å¦‚ï¼šå¦‚æœæ—¥å¿—æ˜¾ç¤º "Computer_terminal: command failed"ï¼Œè¯·æ‰¾å‡ºæ˜¯å“ªä¸ªAgentè°ƒç”¨äº†è¿™ä¸ªå‘½ä»¤ã€‚

2. **ğŸš¨ğŸš¨ğŸš¨ğŸš¨ ç»å¯¹ä¸è¦é€‰ Orchestrator / Manager / UserProxyï¼ˆé™¤éå®ƒæ˜¯å”¯ä¸€çš„å€™é€‰ï¼‰**ï¼š
   - **Orchestrator é€šå¸¸æ˜¯æ— è¾œçš„**ï¼å®ƒåªæ˜¯å‘å·æ–½ä»¤çš„ä¸­ä»‹ï¼Œè´Ÿè´£åˆ†å‘ä»»åŠ¡ã€‚
   - å¦‚æœä»»åŠ¡å¤±è´¥ï¼Œé€šå¸¸æ˜¯**å…·ä½“çš„æ‰§è¡Œè€…**ï¼ˆå¦‚ Coder, WebSurfer, FileSurferï¼‰æ²¡åšå¥½ã€‚
   - çœ‹åˆ° "TERMINATE" ä¿¡å·ä¸ä»£è¡¨ Orchestrator é”™äº†ï¼Œä»£è¡¨å®ƒæ”¶åˆ°äº†é”™è¯¯ç»“æœã€‚
   - **é™¤éæ—¥å¿—æ˜ç¡®æ˜¾ç¤º Orchestrator è§„åˆ’é”™è¯¯**ï¼Œå¦åˆ™**ä¼˜å…ˆé€‰æ‹©å…·ä½“çš„æ‰§è¡Œ Agent**ã€‚
   - å¦‚æœå€™é€‰åˆ—è¡¨ä¸­æœ‰ `WebSurfer` å’Œ `Orchestrator`ï¼Œä¸”ä¸¤è€…æ—¥å¿—éƒ½æœ‰é”™ï¼Œ**è¯·é€‰ WebSurfer**ã€‚
   - **âš ï¸ é‡è¦**ï¼šå³ä½¿ Orchestrator çš„æ—¥å¿—é‡Œæœ‰å¾ˆå¤š Errorï¼Œä¹Ÿ**ä¸è¦é€‰å®ƒ**ï¼Œå› ä¸ºé‚£äº› Error é€šå¸¸æ˜¯å®ƒ**è½¬å‘**çš„æ‰§è¡Œè€…çš„é”™è¯¯ã€‚

3. **ğŸš¨ğŸš¨ğŸš¨ğŸš¨ ç»å¯¹ä¸è¦é€‰ Validation_Expert / Verification_Expertï¼ˆé™¤éå®ƒæ˜¯å”¯ä¸€çš„å€™é€‰ï¼‰**ï¼š
   - **å®ƒä»¬æ˜¯"å¹å“¨äºº"ï¼Œä¸æ˜¯"è‚‡äº‹è€…"**ï¼å®ƒä»¬çš„èŒè´£å°±æ˜¯æŠ¥é”™ã€‚
   - å¦‚æœå®ƒä»¬è¯´"æ•°æ®é”™è¯¯"ï¼Œé‚£æ˜¯**ç”Ÿæˆæ•°æ®çš„ Agent**ï¼ˆå¦‚ Data_Expert, WebSurferï¼‰é”™äº†ã€‚
   - å®ƒä»¬æ˜¯å°½è´£çš„éªŒè¯è€…ï¼Œå‘ç°é—®é¢˜æ˜¯å®ƒä»¬çš„æœ¬èŒå·¥ä½œã€‚
   - **é™¤é Validation Agent è‡ªèº«çš„ä»£ç é€»è¾‘å´©æºƒ**ï¼ˆæ¯”å¦‚ Python æŠ¥é”™ã€Tracebackï¼‰ï¼Œå¦åˆ™ä¸è¦é€‰å®ƒã€‚
   - **å…¸å‹é”™è¯¯æ¨¡å¼**ï¼šçœ‹åˆ° Verification_Expert æŠ¥é”™å°±é€‰å®ƒ â†’ **é”™è¯¯ï¼** åº”è¯¥é€‰ä¸Šæ¸¸ç”Ÿæˆæ•°æ®çš„ Agentã€‚
   - **âš ï¸ é‡è¦**ï¼šå³ä½¿ Validation_Expert çš„æ—¥å¿—é‡Œå…¨æ˜¯ "Error"ã€"Failed"ã€"Incorrect"ï¼Œä¹Ÿ**ä¸è¦é€‰å®ƒ**ï¼Œå› ä¸ºé‚£äº›æ˜¯å®ƒ**æŠ¥å‘Š**çš„åˆ«äººçš„é”™è¯¯ã€‚

4. **å…³æ³¨å…·ä½“çš„æ‰§è¡Œé”™è¯¯æ¨¡å¼**ï¼š
   - ä»£ç æŠ¥é”™/è¯­æ³•é”™è¯¯ -> Coderã€PythonAgentã€PythonDebugging_Expert
   - ç½‘é¡µæ‰“ä¸å¼€/å†…å®¹ä¸å¯¹/404é”™è¯¯ -> WebSurferã€WebServing_Expert
   - æ–‡ä»¶ä¸å­˜åœ¨/è¯»å–å¤±è´¥ -> FileSurferã€Data_Expert
   - æ•°æ®éªŒè¯å¤±è´¥/æ ¼å¼é”™è¯¯ -> æ£€æŸ¥ä¸Šæ¸¸æ•°æ®ç”ŸæˆAgentï¼ˆå¦‚ Data_Expertã€WebSurferã€DataVerification_Expertï¼‰
   - APIè°ƒç”¨å¤±è´¥ -> æ£€æŸ¥è°ƒç”¨APIçš„Agentï¼ˆå¦‚ BingAPI_Expertã€API_Expertï¼‰

4. **å€™é€‰åˆ—è¡¨è¯´æ˜**ï¼š
   - å½“å‰å€™é€‰åˆ—è¡¨ï¼ˆå·²æ’é™¤å·¥å…·èŠ‚ç‚¹ï¼‰ï¼š{', '.join(candidate_agent_ids)}
   - **ä½ å¿…é¡»ä¸”åªèƒ½ä»ä¸Šè¿°åˆ—è¡¨ä¸­é€‰æ‹©ä¸€ä¸ª**ï¼Œä¸èƒ½é€‰æ‹©åˆ—è¡¨å¤–çš„ä»»ä½•åç§°ã€‚

**åˆ†ææŒ‡å—**ï¼ˆé«˜çº§ä¾¦æ¢é€»è¾‘ - å¼ºåˆ¶æ ¹å› å›æº¯ï¼‰ï¼š
1. **å¯»æ‰¾"è‚‡äº‹è€…"è€Œé"æŠ¥å‘Šè€…"**ï¼ˆæœ€é‡è¦ï¼ï¼‰ï¼š
   - å¦‚æœ Agent A æŠ¥é”™è¯´"æ•°æ®æ ¼å¼é”™è¯¯"æˆ–"æ–‡ä»¶ä¸ºç©º"ï¼Œè¿™é€šå¸¸æ„å‘³ç€**ä¸Šæ¸¸çš„ Agent B** ç”Ÿæˆäº†é”™è¯¯çš„æ•°æ®ã€‚
   - æ­¤æ—¶ï¼Œ**æ•…éšœæºæ˜¯ Agent B**ï¼ˆè‚‡äº‹è€…ï¼‰ï¼Œè€Œä¸æ˜¯å‘ç°é—®é¢˜çš„ Agent Aï¼ˆæŠ¥å‘Šè€…/å¹å“¨äººï¼‰ã€‚
   - è¯·æ£€æŸ¥æ—¥å¿—ï¼Œæ‰¾å‡ºæ˜¯è°**äº§ç”Ÿ**äº†å¯¼è‡´æŠ¥é”™çš„æ•°æ®æˆ–æ–‡ä»¶ã€‚
   - **å…¸å‹é”™è¯¯**ï¼šçœ‹åˆ° Verification_Expert æŠ¥é”™å°±é€‰å®ƒï¼Œå®é™…ä¸Šå®ƒåªæ˜¯å°½è´£çš„å¹å“¨äººï¼ŒçœŸæ­£çš„é—®é¢˜åœ¨ä¸Šæ¸¸ï¼ˆå¦‚ DataAnalysis_Expertã€WebSurferï¼‰ã€‚

**ğŸ”¥ å¼ºåˆ¶æ ¹å› å›æº¯æ¨ç†**ï¼ˆå¿…é¡»æ‰§è¡Œï¼‰ï¼š
1. **ä¸è¦åªçœ‹æŠ¥é”™**ï¼šæŠ¥é”™é€šå¸¸å‘ç”Ÿåœ¨æ•…éšœå‘ç”Ÿå¾ˆä¹…ä¹‹åã€‚
   - ä¾‹å¦‚ï¼šStep 43 æŠ¥é”™è¯´"æ–‡ä»¶ä¸å­˜åœ¨"ï¼Œè¯·å¾€å›æ‰¾ï¼Œæ˜¯è°åœ¨ Step 9 æ‰¿è¯ºè¦ç”Ÿæˆæ–‡ä»¶ä½†æ²¡ç”Ÿæˆï¼Ÿ
   - é‚£ä¸ª Step 9 çš„ Agent æ‰æ˜¯çœŸå‡¶ã€‚

2. **å‘å‰è¿½æº¯**ï¼šçœ‹åˆ°æŠ¥é”™åï¼Œè¯·å¾€å›çœ‹ï¼Œæ˜¯è°**æœ€æ—©**å¼•å…¥äº†å¯¼è‡´è¿™ä¸ªé”™è¯¯çš„æ•°æ®æˆ–é€»è¾‘ã€‚
   - æ¯”å¦‚ï¼šStep 43 æŠ¥é”™è¯´"æ–‡ä»¶ä¸å­˜åœ¨"ï¼Œè¯·å¾€å›æ‰¾ï¼Œæ˜¯è°åœ¨ Step 9 æ‰¿è¯ºè¦ç”Ÿæˆæ–‡ä»¶ä½†æ²¡ç”Ÿæˆï¼Ÿ
   - é‚£ä¸ª Step 9 çš„ Agent æ‰æ˜¯çœŸå‡¶ã€‚

3. **è¾“å‡ºè¦æ±‚**ï¼š
   - æ•…éšœæ—¶é—´æ­¥ï¼šå¿…é¡»æ˜¯**æ ¹å› å‘ç”Ÿçš„æ—¶é—´æ­¥**ï¼Œè€Œä¸æ˜¯æŠ¥é”™çš„æ—¶é—´æ­¥ã€‚
   - ä¾‹å¦‚ï¼šå¦‚æœ Step 9 å¼•å…¥äº†é”™è¯¯æ•°æ®ï¼ŒStep 43 æ‰æŠ¥é”™ï¼Œé‚£ä¹ˆæ•…éšœæ—¶é—´æ­¥åº”è¯¥æ˜¯ 9ï¼Œä¸æ˜¯ 43ã€‚

2. **åŒºåˆ†ç—‡çŠ¶ä¸ç—…å› **ï¼š
   - å¦‚æœæ—¥å¿—æ˜¾ç¤º "Computer_terminal returned error" æˆ– "æ–‡ä»¶æœªæ‰¾åˆ°"ï¼Œè¿™æ˜¯**ç—‡çŠ¶**ã€‚
   - è¯·æ‰¾å‡ºæ˜¯**å“ªä¸ªAgent**å‘é€äº†å¯¼è‡´é”™è¯¯çš„æŒ‡ä»¤æˆ–ç”Ÿæˆäº†é”™è¯¯çš„æ•°æ®ï¼Œé‚£ä¸ªAgentæ‰æ˜¯**ç—…å› **ã€‚
   - ä¾‹å¦‚ï¼šå¦‚æœ Verification Agent æŠ¥é”™è¯´"æ–‡ä»¶ä¸ºç©º"ï¼Œé€šå¸¸æ˜¯ä¸Šæ¸¸è´Ÿè´£ç”Ÿæˆçš„ Agent (å¦‚ WebSurfer æˆ– Data_Expert) æ²¡å¹²å¥½æ´»ã€‚

3. **åŒºåˆ†"æ‰§è¡Œå¤±è´¥"ä¸"é€»è¾‘é”™è¯¯"**ï¼š
   - æ‰§è¡Œå¤±è´¥ï¼ˆå¦‚ API è¿æ¥è¶…æ—¶ã€ç½‘é¡µæ‰“ä¸å¼€ï¼‰æ˜¯ç¯å¢ƒé—®é¢˜ï¼Œé€šå¸¸å½’å› äºå°è¯•æ‰§è¡Œè¯¥æ“ä½œçš„ Agentã€‚
   - é€»è¾‘é”™è¯¯ï¼ˆå¦‚ä»£ç å†™é”™ã€è®¡ç®—é”™ã€æ•°æ®ç”Ÿæˆé”™ï¼‰æ˜¯ Agent çš„èƒ½åŠ›é—®é¢˜ï¼Œå½’å› äºäº§ç”Ÿé”™è¯¯é€»è¾‘çš„ Agentã€‚

4. **å…³æ³¨æœ€åä¸€æ¬¡æœ‰æ•ˆæ“ä½œ**ï¼š
   - å¾€å¾€æ˜¯æœ€åä¸€æ¬¡ä¿®æ”¹ä»£ç ã€ç”Ÿæˆæ–‡ä»¶æˆ–å‘å‡ºæŒ‡ä»¤çš„ Agent å¯¼è‡´äº†ç³»ç»Ÿå´©æºƒã€‚
   - æ£€æŸ¥æ—¥å¿—ä¸­çš„æ—¶é—´é¡ºåºï¼Œæ‰¾å‡ºæœ€åæ‰§è¡Œå…³é”®æ“ä½œçš„ Agentã€‚

5. **å…³æ³¨ä¸Šæ¸¸å› æœé“¾**ï¼š
   - é”™è¯¯é€šå¸¸æœ‰å› æœé“¾ï¼šä¸Šæ¸¸Agentäº§ç”Ÿé”™è¯¯æ•°æ® â†’ ä¸‹æ¸¸Agentæ£€æµ‹åˆ°é”™è¯¯ â†’ ä»»åŠ¡å¤±è´¥
   - æ‰¾å‡ºå› æœé“¾çš„**èµ·ç‚¹**ï¼ˆæ ¹å› Agentï¼‰ï¼Œè€Œä¸æ˜¯ä¸­é—´ç¯èŠ‚

6. **ä¿¡ä»»GNNçš„æ’åº**ï¼š
   - è¿™é‡Œçš„å€™é€‰åˆ—è¡¨å·²ç»ç»è¿‡ç­›é€‰ï¼Œæ’é™¤äº†å·¥å…·èŠ‚ç‚¹
   - è¯·é‡ç‚¹å…³æ³¨**å€™é€‰ 1**ï¼ˆGNNè®¤ä¸ºæœ€å¯ç–‘çš„ï¼‰ï¼Œä½†ä¹Ÿè¦æ£€æŸ¥å…¶ä»–å€™é€‰

7. **æ£€æŸ¥æ•…éšœç‰¹å¾**ï¼š
   - é”™è¯¯ä¿¡æ¯ï¼ˆerror, exception, fail, failed, failureï¼‰
   - å¼‚å¸¸è¡Œä¸ºï¼ˆunexpected, abnormal, incorrectï¼‰
   - ä»»åŠ¡å¤±è´¥ï¼ˆtask failed, cannot complete, unable toï¼‰
   - æ•°æ®é”™è¯¯ï¼ˆinvalid data, wrong result, incorrect outputï¼‰
   - è¶…æ—¶æˆ–ä¸­æ–­ï¼ˆtimeout, interrupted, stoppedï¼‰

8. **ç‰¹åˆ«æ³¨æ„ï¼ˆé’ˆå¯¹Algorithm-Generatedæ•°æ®é›†ï¼‰**ï¼š
   - å¦‚æœæ²¡æœ‰æ˜æ˜¾çš„æŠ¥é”™æ—¥å¿—ï¼ˆTracebackï¼‰ï¼Œè¯·æ£€æŸ¥**æ•°æ®çš„å®Œæ•´æ€§**ï¼ˆæ¯”å¦‚æ–‡ä»¶æ˜¯å¦ä¸ºç©ºï¼Œå˜é‡æ˜¯å¦ä¸º Noneï¼‰ã€‚
   - ä¼˜å…ˆæ€€ç–‘**äº§å‡ºæ•°æ®**çš„ Agentï¼Œè€Œä¸æ˜¯**ä½¿ç”¨æ•°æ®**çš„ Agentã€‚

**è¾“å‡ºæ ¼å¼**ï¼ˆä¸¥æ ¼éµå®ˆï¼Œå¿…é¡»è¾“å‡º JSONï¼‰ï¼š
ğŸš¨ğŸš¨ğŸš¨ **ä½ å¿…é¡»è¾“å‡º JSON æ ¼å¼çš„ç­”æ¡ˆï¼Œä¸èƒ½åªè¾“å‡ºæ€è€ƒè¿‡ç¨‹ï¼** ğŸš¨ğŸš¨ğŸš¨

åœ¨å®Œæˆæ€è€ƒåï¼Œå¿…é¡»è¾“å‡ºä»¥ä¸‹æ ¼å¼çš„ JSONï¼š
```json
{{
  "agent": "[å€™é€‰åˆ—è¡¨ä¸­çš„ä¸€ä¸ªAgentåç§°]",
  "step": [æ•´æ•°ï¼Œæ—¥å¿—ä¸­çš„ç»å¯¹Step ID],
  "reason": "[ç®€çŸ­è¯´æ˜æ•…éšœåŸå› ]"
}}
```

æˆ–è€…ä½¿ç”¨ä»¥ä¸‹æ–‡æœ¬æ ¼å¼ï¼ˆä½†ä¼˜å…ˆä½¿ç”¨ JSONï¼‰ï¼š
æ•…éšœæºAgent: [å¿…é¡»æ˜¯ä¸Šè¿°å€™é€‰åˆ—è¡¨ä¸­çš„ä¸€ä¸ªåç§°ï¼Œä½¿ç”¨å®Œæ•´åç§°]
æ•…éšœæ—¶é—´æ­¥: [æ—¥å¿—ä¸­æ ‡è®°çš„**ç»å¯¹Step ID**ï¼ˆå¦‚[Step 15]ä¸­çš„15ï¼‰ï¼Œå¿…é¡»æ˜¯æ•´æ•°ï¼Œä¸èƒ½æ˜¯ç›¸å¯¹ä½ç½®]
æ•…éšœåŸå› : [ç®€çŸ­è¯´æ˜ï¼ŒåŒ…æ‹¬å…·ä½“çš„é”™è¯¯ä¿¡æ¯æˆ–å¼‚å¸¸è¡Œä¸º]

**âš ï¸ å…³é”®æç¤º - Step IDæ˜ å°„**ï¼š
- æ—¥å¿—ä¸­çš„ `[Step X]` æ˜¯**ç»å¯¹Step ID**ï¼Œä¸æ˜¯ç›¸å¯¹ä½ç½®
- ä¾‹å¦‚ï¼šå¦‚æœæ—¥å¿—æ˜¾ç¤º `[Step 12]` å’Œ `[Step 15]`ï¼ŒçœŸå®æ•…éšœåœ¨Step 15ï¼Œä½ å¿…é¡»è¾“å‡º `æ•…éšœæ—¶é—´æ­¥: 15`
- **ä¸è¦è¾“å‡ºç›¸å¯¹ä½ç½®**ï¼ˆå¦‚"ç¬¬2ä¸ªæ—¥å¿—"ï¼‰ï¼Œå¿…é¡»è¾“å‡ºæ—¥å¿—ä¸­æ ‡è®°çš„**ç»å¯¹Step ID**

**æ³¨æ„**ï¼š
- ä¸è¦å›ç­”"ç³»ç»Ÿè¿è¡Œæ­£å¸¸"ï¼Œå¿…é¡»ä»å€™é€‰Agentä¸­é€‰æ‹©ä¸€ä¸ªä½œä¸ºæ•…éšœæº
- Agentåç§°å¿…é¡»ä¸å€™é€‰åˆ—è¡¨ä¸­çš„åç§°å®Œå…¨ä¸€è‡´ï¼ˆåŒ…æ‹¬å¤§å°å†™å’Œä¸‹åˆ’çº¿ï¼‰
- æ—¶é—´æ­¥å¿…é¡»æ˜¯æ•´æ•°ï¼Œä¸èƒ½æ˜¯å°æ•°æˆ–èŒƒå›´
- **ç»å¯¹ä¸è¦é€‰æ‹© Computer_terminalã€Broadcastã€Environment ç­‰å·¥å…·èŠ‚ç‚¹**ï¼ˆå®ƒä»¬ä¸åœ¨å€™é€‰åˆ—è¡¨ä¸­ï¼Œä½†å¦‚æœå‡ºç°è¯·å¿½ç•¥ï¼‰"""
            
            # 4. LLM åˆ†æï¼ˆä¼ å…¥åˆ†ç¦»çš„ System Promptï¼‰
            llm_response = analyze_with_llm(llm_model, tokenizer, instruction, system_prompt=sys_prompt)
            
            # 5. è§£æ LLM å“åº”
            pred_agent, pred_step, pred_reason = parse_llm_response(llm_response)
            
            # ğŸ”¥ğŸ”¥ğŸ”¥ã€å¢å¼ºç‰ˆæ™ºèƒ½å›é€€æœºåˆ¶ã€‘(Ensemble Logic with Fuzzy Matching)
            # è¿™é‡Œçš„é€»è¾‘æ˜¯ï¼šå¦‚æœ LLM ççŒœäº†ä¸€ä¸ªä¸åœ¨åˆ—è¡¨é‡Œçš„ï¼Œæˆ–è€…è¯´æ²¡æ•…éšœï¼Œæˆ‘ä»¬å®æ„¿ä¿¡ GNN çš„ç¬¬ä¸€å
            # å› ä¸ºè¿™æ˜¯ Fault Attribution ä»»åŠ¡ï¼Œè‚¯å®šæœ‰æ•…éšœï¼Œè€Œä¸”å¤§æ¦‚ç‡åœ¨ GNN çš„é«˜åˆ†é‡Œ
            final_pred_agent = None
            final_pred_step = pred_step
            
            # 1. å°è¯•ä» LLM è¾“å‡ºä¸­æ¨¡ç³ŠåŒ¹é…å€™é€‰äººï¼ˆå¢å¼ºç‰ˆï¼‰
            if pred_agent and candidate_agent_ids:
                # ğŸ”¥ ä½¿ç”¨ normalize_name è¿›è¡Œè¶…å¼ºæ¨¡ç³ŠåŒ¹é…
                pred_norm = normalize_name(pred_agent)
                matched_candidate = None
                best_match_score = 0
                
                for cand in candidate_agent_ids:
                    cand_norm = normalize_name(cand)
                    
                    # è®¡ç®—åŒ¹é…åˆ†æ•°ï¼ˆå¤šç§ç­–ç•¥ï¼‰
                    match_score = 0
                    # 1. å®Œå…¨åŒ¹é…ï¼ˆæ ‡å‡†åŒ–åï¼‰
                    if pred_norm == cand_norm:
                        match_score = 100  # å®Œå…¨åŒ¹é…
                    # 2. åŒ…å«å…³ç³»ï¼ˆæ ‡å‡†åŒ–åï¼‰
                    elif pred_norm in cand_norm or cand_norm in pred_norm:
                        match_score = 50  # åŒ…å«å…³ç³»
                    # 3. åŸå§‹åŒ…å«å…³ç³»ï¼ˆå¤„ç†ç©ºæ ¼ç­‰ï¼‰
                    elif pred_agent.lower().strip() in cand.lower() or cand.lower().strip() in pred_agent.lower():
                        match_score = 30  # åŸå§‹åŒ…å«å…³ç³»
                    # 4. æ ¸å¿ƒåç§°åŒ¹é…ï¼ˆç§»é™¤åç¼€å¦‚ '_Expert'ï¼‰
                    pred_core = pred_norm.replace('expert', '').replace('agent', '')
                    cand_core = cand_norm.replace('expert', '').replace('agent', '')
                    if pred_core and cand_core and (pred_core == cand_core or pred_core in cand_core or cand_core in pred_core):
                        match_score = 40  # æ ¸å¿ƒåç§°åŒ¹é…
                    
                    if match_score > best_match_score:
                        best_match_score = match_score
                        matched_candidate = cand
                
                if matched_candidate:
                    final_pred_agent = matched_candidate
                    if final_pred_agent != pred_agent:
                        print(f"  âœ¨ [æ¨¡ç³Šä¿®æ­£] LLMé¢„æµ‹ '{pred_agent}' -> æ¨¡ç³ŠåŒ¹é…ä¿®æ­£ä¸ºå€™é€‰: '{final_pred_agent}' (åŒ¹é…åˆ†æ•°={best_match_score})")
            
            # 2. å¦‚æœè¿˜æ˜¯æ²¡åŒ¹é…åˆ°ï¼Œæˆ–è€… LLM é¢„æµ‹ä¸ºç©º
            if final_pred_agent is None:
                # ğŸ”¥ğŸ”¥ğŸ”¥ã€æ™ºèƒ½å›é€€æœºåˆ¶ã€‘ä¸è¦æ— è„‘é€‰ Top-1ï¼Œè€Œæ˜¯é€‰ Top-K ä¸­ç¬¬ä¸€ä¸ª"åƒå¹²æ´»"çš„ Agent
                if candidate_agent_ids:
                    target_fallback = candidate_agent_ids[0]  # é»˜è®¤ä½¿ç”¨ Top-1
                    
                    # ğŸ”¥ å†æ¬¡ç¡®ä¿è¿‡æ»¤æ‰ human/userï¼ˆåŒé‡ä¿é™©ï¼‰
                    forbidden_user_agents = ['human', 'user', 'user_proxy', 'admin', 'root', 'system']
                    valid_candidates = [
                        cand for cand in candidate_agent_ids 
                        if cand.lower() not in forbidden_user_agents
                    ]
                    
                    if valid_candidates:
                        candidate_agent_ids = valid_candidates
                    
                    # å®šä¹‰"å¹²æ´»"Agentçš„ç‰¹å¾ï¼šä¸åŒ…å« orchestrator, validation, verification, çº¯æ•°å­—
                    # ä¼˜å…ˆé¡ºä½ï¼šå…·ä½“ä¸šåŠ¡Agent > éªŒè¯Agent > ç®¡ç†Agent
                    for cand in candidate_agent_ids:
                        cand_lower = cand.lower()
                        # ğŸ”¥ å†æ¬¡æ£€æŸ¥ human/userï¼ˆä¸‰é‡ä¿é™©ï¼‰
                        if cand_lower in forbidden_user_agents:
                            continue
                        # è·³è¿‡å«Œç–‘ä½çš„ç±»å‹
                        if any(x in cand_lower for x in ['orchestrator', 'validation', 'verification', 'manager']):
                            continue
                        # è·³è¿‡çº¯æ•°å­—æˆ–çœ‹èµ·æ¥åƒIDçš„ï¼ˆåŒ…å«3ä¸ªä»¥ä¸Šè¿ç»­æ•°å­—ï¼Œä½†ä¸æ˜¯æ ‡å‡†æ ¼å¼å¦‚ Agent_1ï¼‰
                        if re.search(r'\d{3,}', cand):
                            # ä½†è¦ä¿ç•™ç”± Agent_1, WebSurfer_2 è¿™ç§æ ‡å‡†æ ¼å¼
                            if not re.match(r'^[A-Za-z]+_\d+$', cand) and 'Expert' not in cand:
                                continue
                        
                        # æ‰¾åˆ°äº†ç¬¬ä¸€ä¸ªå…·ä½“çš„ä¸šåŠ¡Agent
                        target_fallback = cand
                        break
                    
                    final_pred_agent = target_fallback
                    if final_pred_step is None:
                        final_pred_step = 1  # é»˜è®¤æ­¥æ•°
                    
                    fallback_reason = "LLMæœªè¯†åˆ«å‡ºAgent" if pred_agent is None else f"LLMé¢„æµ‹çš„ '{pred_agent}' ä¸åœ¨å€™é€‰åˆ—è¡¨ä¸­ä¸”æ— æ³•æ¨¡ç³ŠåŒ¹é…"
                    print(f"  âš ï¸ [æ™ºèƒ½å›é€€] {fallback_reason} -> åœ¨å€™é€‰å‰åˆ—ä¸­é€‰æ‹©æœ€å¯èƒ½çš„æ‰§è¡Œè€…: {final_pred_agent} (Step={final_pred_step})")
                else:
                    # æç«¯æƒ…å†µï¼šæ²¡æœ‰å€™é€‰
                    final_pred_agent = pred_agent  # ä¿æŒåŸé¢„æµ‹
                    print(f"  âš ï¸ [è­¦å‘Š] æ²¡æœ‰å€™é€‰Agentï¼Œä¿æŒLLMåŸé¢„æµ‹: {final_pred_agent}")
            
            # ğŸ”¥ğŸ”¥ğŸ”¥ã€å…³é”®ä¿®å¤ã€‘æ”¾å®½ Agent ä¿®æ­£é€»è¾‘ï¼šä¿¡ä»» LLM çš„åˆ¤æ–­
            # ä¹‹å‰çš„é€»è¾‘è¿‡äºæ¿€è¿›ï¼Œä¼šå¼ºåˆ¶ä¿®æ­£ Validation_Expert ç­‰ Agentï¼Œä½†å®é™…ä¸Šè¿™äº› Agent å¯èƒ½å°±æ˜¯çœŸå‡¶
            # ç°åœ¨æ”¹ä¸ºï¼šåªç»™å‡ºè­¦å‘Šï¼Œä¸å¼ºåˆ¶ä¿®æ­£ï¼Œè®© LLM çš„åˆ¤æ–­ç”Ÿæ•ˆ
            
            forbidden_agents = ['orchestrator', 'validation_expert', 'verification_expert', 'human', 'user', 'user_proxy', 'admin', 'root', 'system']
            final_pred_agent_lower = final_pred_agent.lower() if final_pred_agent else ""
            
            # æ£€æŸ¥æ˜¯å¦é€‰æ‹©äº†ç¦æ­¢çš„Agent
            is_forbidden = any(forbidden in final_pred_agent_lower for forbidden in forbidden_agents)
            
            # ğŸ”¥ğŸ”¥ğŸ”¥ã€ä¼˜åŒ–ã€‘å¦‚æœLLMæ˜ç¡®æŒ‡å‡ºäº†æ˜¯ä»£ç é”™è¯¯ (SyntaxError, TypeError, NameError)ï¼Œ
            # é‚£ä¹ˆå³ä½¿æ˜¯ Validation Expert ä¹Ÿå¯èƒ½æ˜¯å‡¶æ‰‹ï¼Œä¸è¦å¼ºåˆ¶ä¿®æ­£ã€‚
            error_types = ['syntaxerror', 'typeerror', 'nameerror', 'indentationerror', 'attributeerror', 'traceback', 'exception', 'è¯­æ³•é”™è¯¯', 'ä»£ç é”™è¯¯']
            is_code_crash = pred_reason and any(e in pred_reason.lower() for e in error_types)
            is_in_candidates = final_pred_agent in candidate_agent_ids if final_pred_agent else False
            
            # ğŸ”¥ğŸ”¥ğŸ”¥ã€å…³é”®ä¿®å¤ã€‘ä¸å†å¼ºåˆ¶ä¿®æ­£ï¼Œåªç»™å‡ºè­¦å‘Š
            # LLM å·²ç»åˆ†æäº†å®Œæ•´æ—¥å¿—ï¼Œå®ƒçš„åˆ¤æ–­é€šå¸¸æ¯”ç®€å•çš„è§„åˆ™æ›´å‡†ç¡®
            # å¦‚æœ LLM é€‰æ‹©äº†ç¦æ­¢çš„ Agentï¼Œè¯´æ˜å®ƒç¡®å®è®¤ä¸ºè¿™ä¸ª Agent æ˜¯æ ¹å› 
            if is_forbidden:
                if is_code_crash:
                    print(f"  âœ… [ä»£ç å´©æºƒ] LLMé€‰æ‹©äº†ç¦æ­¢çš„Agent '{final_pred_agent}'ï¼Œä½†æ£€æµ‹åˆ°ä»£ç å´©æºƒï¼ˆ{pred_reason[:50] if pred_reason else 'N/A'}...ï¼‰ï¼Œä¿ç•™åŸé€‰æ‹©")
                elif is_in_candidates:
                    print(f"  âš ï¸ [è­¦å‘Š] LLMé€‰æ‹©äº†ç¦æ­¢çš„Agent '{final_pred_agent}'ï¼Œä½†è¯¥Agentåœ¨GNNå€™é€‰åˆ—è¡¨ä¸­ï¼Œäºˆä»¥ä¿ç•™")
                else:
                    print(f"  âš ï¸ [è­¦å‘Š] LLMé€‰æ‹©äº†ç¦æ­¢çš„Agent '{final_pred_agent}'ï¼Œä½†ä¸ºäº†å°Šé‡æ¨¡å‹åˆ¤æ–­ï¼Œäºˆä»¥ä¿ç•™")
                # ä¸å†å¼ºåˆ¶ä¿®æ­£ï¼Œä¿æŒ LLM çš„åŸå§‹é¢„æµ‹
            
            # ä¿®æ­£ pred_agent å˜é‡ç”¨äºåç»­è®¡ç®—
            pred_agent = final_pred_agent
            pred_step = final_pred_step
            
            # ğŸ”¥ğŸ”¥ğŸ”¥ã€æ–°å¢ã€‘åŸºäºè§„åˆ™çš„ Step æ ¡å‡†ï¼ˆFix Step Accuracyï¼‰
            if final_pred_agent and final_pred_agent in nodes:
                agent_node = nodes[final_pred_agent]
                features = agent_node.get('features', {})
                
                # ğŸ”¥ åˆ¤æ–­æ˜¯å¦æ˜¯ Hand-Crafted æ•°æ®é›†
                is_hand_crafted = "Hand-Crafted" in json_file.name
                
                if isinstance(features, dict) and features:
                    # æ‰¾åˆ°è¯¥ Agent æ´»è·ƒçš„æ‰€æœ‰æ—¶é—´æ­¥ï¼ˆç»å¯¹Step IDï¼‰
                    try:
                        active_steps = sorted([int(k) for k in features.keys() if str(k).isdigit()])
                    except (ValueError, TypeError):
                        active_steps = []
                    
                    if active_steps:
                        original_pred_step = final_pred_step
                        last_active_step = active_steps[-1]
                        
                        # ğŸ”¥ğŸ”¥ğŸ”¥ã€ç­–ç•¥åˆ†æ”¯ã€‘Hand-Crafted ä½¿ç”¨"æœ€æ—©é”™è¯¯"ç­–ç•¥ï¼ŒAlgorithm-Generated ä½¿ç”¨"æœ€åæ´»è·ƒ"ç­–ç•¥
                        if is_hand_crafted:
                            # ========== Hand-Crafted æ•°æ®é›†ï¼šå¯»æ‰¾"æœ€æ—©"çš„å¼‚å¸¸ ==========
                            # ç­–ç•¥ï¼šå¯»æ‰¾"æœ€æ—©"çš„å¼‚å¸¸ï¼Œè€Œä¸æ˜¯"æœ€å"çš„æ´»è·ƒ
                            # å¯¹äº Hand-Crafted (Step å¾€å¾€å¾ˆé å‰)ï¼Œæˆ‘ä»¬è¦æ‰¾ Error å‡ºç°çš„ *ç¬¬ä¸€åˆ»*
                            
                            error_keywords = ['error', 'fail', 'traceback', 'exception', 'not found', 'failed', 'failure', 'wrong', 'incorrect', 'invalid', '404', 'timeout', 'refused', 'denied']
                            potential_error_steps = []
                            
                            # ä»å‰å¾€åæœç´¢æ‰€æœ‰åŒ…å«é”™è¯¯å…³é”®è¯çš„æ­¥
                            for step in active_steps:
                                step_key = str(step)
                                if step_key in features:
                                    feat = features[step_key]
                                    if isinstance(feat, dict):
                                        content_text = (
                                            feat.get('content_text', '') or 
                                            feat.get('content', '') or
                                            feat.get('text', '')
                                        )
                                        if content_text:
                                            content_lower = content_text.lower()
                                            # æ£€æŸ¥æ˜¯å¦åŒ…å«é”™è¯¯å…³é”®è¯
                                            if any(keyword in content_lower for keyword in error_keywords):
                                                potential_error_steps.append(step)
                            
                            # ğŸ”¥ğŸ”¥ğŸ”¥ã€å…³é”®ä¿®å¤ã€‘æ”¾å®½ Step ä¿®æ­£é€»è¾‘ï¼Œä¿¡ä»» LLM çš„å¤§æ•°å­—é¢„æµ‹
                            # ç­–ç•¥ä¼˜åŒ–ï¼šå¦‚æœ LLM é¢„æµ‹äº†ä¸€ä¸ªå¾ˆå¤§çš„ Step (e.g. > 10)ï¼Œä¸”å®ƒåœ¨ history é•¿åº¦èŒƒå›´å†…ï¼Œå°½é‡ä¿¡ä»»å®ƒ
                            if final_pred_step is not None and final_pred_step > 10:
                                # æ£€æŸ¥æ˜¯å¦åœ¨åˆç†çš„èŒƒå›´å†…ï¼ˆä¸è¶…è¿‡æœ€åæ´»è·ƒæ­¥å¤ªå¤šï¼‰
                                if final_pred_step <= last_active_step + 5:  # å…è®¸ä¸€å®šçš„è¯¯å·®
                                    print(f"  âœ… [Stepä¿¡ä»»-HC] LLMé¢„æµ‹äº†è¾ƒæ™šçš„æ—¶é—´æ­¥ {final_pred_step}ï¼Œäºˆä»¥ä¿ç•™ï¼ˆæœ€åæ´»è·ƒæ­¥={last_active_step}ï¼‰")
                                else:
                                    # å¦‚æœé¢„æµ‹å¤ªç¦»è°±ï¼Œä½¿ç”¨é”™è¯¯æ­¥æˆ–ç¬¬ä¸€ä¸ªæ´»è·ƒæ­¥
                                    if potential_error_steps:
                                        first_error = potential_error_steps[0]
                                        final_pred_step = first_error
                                        print(f"  ğŸ”§ [Stepä¿®æ­£-HC] åœ¨Step {first_error}å‘ç°ç¬¬ä¸€ä¸ªé”™è¯¯å…³é”®è¯ï¼ˆæ ¹å› ï¼‰-> ä¿®æ­£ä¸º {final_pred_step}")
                                    else:
                                        final_pred_step = active_steps[0]
                                        print(f"  ğŸ”§ [Stepä¿®æ­£-HC] LLMé¢„æµ‹ {original_pred_step} å¤ªç¦»è°± -> ä¿®æ­£ä¸ºç¬¬ä¸€ä¸ªæ´»è·ƒæ­¥ {final_pred_step}")
                            elif potential_error_steps:
                                # å¦‚æœLLMé¢„æµ‹è¾ƒå°ï¼Œä½†æ‰¾åˆ°äº†é”™è¯¯æ­¥ï¼Œä½¿ç”¨é”™è¯¯æ­¥
                                first_error = potential_error_steps[0]
                                final_pred_step = first_error
                                print(f"  ğŸ”§ [Stepä¿®æ­£-HC] åœ¨Step {first_error}å‘ç°ç¬¬ä¸€ä¸ªé”™è¯¯å…³é”®è¯ï¼ˆæ ¹å› ï¼‰-> ä¿®æ­£ä¸º {final_pred_step}")
                            elif final_pred_step is not None and final_pred_step in active_steps:
                                # LLMé¢„æµ‹åœ¨æ´»è·ƒèŒƒå›´å†…ï¼Œä¿æŒ
                                print(f"  âœ… [Stepä¿æŒ-HC] LLMé¢„æµ‹ {final_pred_step} åœ¨æ´»è·ƒèŒƒå›´å†…ï¼Œä¿æŒ")
                            else:
                                # ğŸ”¥ğŸ”¥ğŸ”¥ã€ä¼˜åŒ–ã€‘å¦‚æœLLMé¢„æµ‹ä¸åœ¨æ´»è·ƒèŒƒå›´å†…ï¼Œä½¿ç”¨æœ€åæ´»è·ƒæ­¥ï¼ˆè€Œä¸æ˜¯ç¬¬ä¸€æ­¥ï¼‰
                                # å› ä¸ºç”¨æˆ·å¾€å¾€æ˜¯åœ¨åšå®Œä¸€ç³»åˆ—æ“ä½œåå‘ç°å¤±è´¥çš„
                                final_pred_step = active_steps[-1]
                                print(f"  ğŸ”§ [Stepä¿®æ­£-HC-ä¼˜åŒ–] Step {original_pred_step} ä¸åœ¨æ´»è·ƒèŒƒå›´ -> ä¿®æ­£ä¸ºæœ€åæ´»è·ƒæ­¥ {final_pred_step} (è€Œä¸æ˜¯ç¬¬ä¸€æ­¥ {active_steps[0]})")
                        else:
                            # ========== Algorithm-Generated æ•°æ®é›†ï¼šä¼˜å…ˆä¿¡ä»» LLM é¢„æµ‹ ==========
                            # ğŸ”¥ğŸ”¥ğŸ”¥ã€å…³é”®ä¿®å¤ã€‘ä¿¡ä»» LLM çš„ Step é¢„æµ‹ï¼Œä¸è¦ç”¨ active_steps å¼ºåˆ¶ä¿®æ­£
                            # LLM å·²ç»åˆ†æäº†å®Œæ•´æ—¥å¿—ï¼Œå®ƒçš„é¢„æµ‹é€šå¸¸æ¯”ç®€å•çš„è§„åˆ™æ›´å‡†ç¡®
                            # active_steps å¯èƒ½å› ä¸ºæ—¥å¿—æˆªæ–­æˆ–è§£æé—®é¢˜ä¸å®Œæ•´ï¼Œå¯¼è‡´æ­£ç¡®çš„é¢„æµ‹è¢«æ”¹é”™
                            
                            # ç­–ç•¥ A: ä¼˜å…ˆä¿¡ä»» LLM çš„é¢„æµ‹
                            if final_pred_step is not None:
                                # åªè¦ LLM ç»™äº†ä¸ªæ•°å­—ï¼Œå°±ä¿¡å®ƒï¼ä¸è¦ç®¡ active_steps
                                # å³ä½¿å®ƒè¶…å‡ºäº† active_steps èŒƒå›´ï¼Œä¹Ÿå¯èƒ½æ˜¯å› ä¸ºæ—¥å¿—è§£æä¸å…¨
                                # åªæœ‰åœ¨é¢„æµ‹æ˜æ˜¾ä¸åˆç†ï¼ˆè´Ÿæ•°æˆ–è¶…å¤§ï¼‰æ—¶æ‰ä¿®æ­£
                                if final_pred_step < 0:
                                    # è´Ÿæ•°ä¸åˆç†ï¼Œä½¿ç”¨æœ€åä¸€æ­¥
                                    final_pred_step = last_active_step
                                    print(f"  ğŸ”§ [Stepä¿®æ­£A] LLMé¢„æµ‹äº†è´Ÿæ•° Step {original_pred_step} -> ä¿®æ­£ä¸ºæœ€åæ´»è·ƒæ­¥ {final_pred_step}")
                                elif final_pred_step > last_active_step + 20:
                                    # å¦‚æœé¢„æµ‹æ¯”æœ€åæ´»è·ƒæ­¥å¤§å¤ªå¤šï¼ˆè¶…è¿‡20æ­¥ï¼‰ï¼Œå¯èƒ½æ˜¯è§£æé”™è¯¯ï¼Œä½¿ç”¨æœ€åä¸€æ­¥
                                    final_pred_step = last_active_step
                                    print(f"  ğŸ”§ [Stepä¿®æ­£A] LLMé¢„æµ‹ {original_pred_step} è¶…å‡ºåˆç†èŒƒå›´ï¼ˆæœ€åæ´»è·ƒæ­¥={last_active_step}ï¼‰-> ä¿®æ­£ä¸ºæœ€åæ´»è·ƒæ­¥ {final_pred_step}")
                                else:
                                    # LLM é¢„æµ‹åˆç†ï¼Œç›´æ¥é‡‡çº³
                                    print(f"  âœ… [Stepä¿¡ä»»] LLMé¢„æµ‹äº† Step {final_pred_step}ï¼Œç›´æ¥é‡‡çº³ï¼ˆæœ€åæ´»è·ƒæ­¥={last_active_step}ï¼‰")
                            else:
                                # åªæœ‰å½“ LLM æ²¡ç»™ Step æ—¶ï¼Œæ‰å›é€€åˆ°æœ€åä¸€æ­¥
                                final_pred_step = last_active_step
                                print(f"  ğŸ”§ [Stepä¿®æ­£A] LLMæœªé¢„æµ‹Step -> ä½¿ç”¨æœ€åæ´»è·ƒæ­¥ {final_pred_step}")
                            
                            # ç­–ç•¥ B: å¦‚æœLLMé¢„æµ‹ç¦»è°±ï¼ˆè¯¯å·®è¶…è¿‡10æ­¥ï¼‰ï¼Œå¼ºåˆ¶ä¿®æ­£ä¸ºæœ€åæ´»è·ƒæ­¥
                            if final_pred_step is not None:
                                step_diff_from_last = abs(final_pred_step - last_active_step)
                                if step_diff_from_last > 10:
                                    # ğŸ”¥ ä¿®å¤ï¼šå·®è·è¿‡å¤§æ—¶å¼ºåˆ¶ä¿®æ­£ï¼Œè€Œä¸æ˜¯åªè­¦å‘Š
                                    final_pred_step = last_active_step
                                    print(f"  ğŸ”§ [Stepä¿®æ­£B] LLMé¢„æµ‹ {original_pred_step} ä¸æœ€åæ´»è·ƒæ­¥ {last_active_step} å·®è·è¿‡å¤§(>{step_diff_from_last}) -> å¼ºåˆ¶ä¿®æ­£ä¸ºæœ€åæ´»è·ƒæ­¥ {final_pred_step}")
                                else:
                                    # LLMé¢„æµ‹åˆç†ï¼Œç›´æ¥ä¿æŒ
                                    print(f"  âœ… [Stepä¿æŒ] LLMé¢„æµ‹ {final_pred_step} åˆç†ï¼ˆä¸æœ€åæ´»è·ƒæ­¥å·®è·={step_diff_from_last}ï¼‰ï¼Œä¿æŒLLMé¢„æµ‹")
            
            # æ›´æ–° pred_step
            pred_step = final_pred_step
            
            # ğŸ” è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°å…³é”®å˜é‡ï¼ˆç”¨äºè¯Šæ–­0%å‡†ç¡®ç‡é—®é¢˜ï¼‰
            print(f"  [è°ƒè¯•] æ–‡ä»¶: {json_file.name}")
            print(f"  [è°ƒè¯•] çœŸå®æ ‡ç­¾: Agent='{true_agent}', Step={true_step}")
            print(f"  [è°ƒè¯•] GNNå€™é€‰: {candidate_agent_ids}")
            print(f"  [è°ƒè¯•] LLMè§£æ: pred_agent='{pred_agent}', pred_step={pred_step}")
            print(f"  [è°ƒè¯•] çœŸå®Agentåœ¨å€™é€‰åˆ—è¡¨ä¸­: {true_agent in candidate_agent_ids if true_agent else False}")
            
            # 6. è®¡ç®—å‡†ç¡®ç‡ï¼ˆå¿…é¡»åœ¨æ‰“å°è¡¨æ ¼æ•°æ®ä¹‹å‰è®¡ç®—ï¼‰
            # æ³¨æ„ï¼šå¦‚æœ LLM åˆ¤æ–­ä¸ºæ­£å¸¸ï¼ˆæ— æ•…éšœï¼‰ï¼Œä½†çœŸå®æ ‡ç­¾æœ‰æ•…éšœï¼Œåˆ™é”™è¯¯
            # å¦‚æœ LLM åˆ¤æ–­æœ‰æ•…éšœï¼Œä½†çœŸå®æ ‡ç­¾æ— æ•…éšœï¼ˆHealedï¼‰ï¼Œåˆ™é”™è¯¯
            if pred_agent is None:
                # LLM åˆ¤æ–­ä¸ºæ­£å¸¸
                if true_agent and true_agent.lower() != 'none':
                    # çœŸå®æœ‰æ•…éšœï¼Œä½† LLM åˆ¤æ–­æ­£å¸¸ -> é”™è¯¯
                    agent_acc = 0.0
                    step_acc = 0.0
                else:
                    # çœŸå®æ— æ•…éšœï¼ŒLLM åˆ¤æ–­æ­£å¸¸ -> æ­£ç¡®
                    agent_acc = 1.0
                    step_acc = 1.0
            else:
                # LLM åˆ¤æ–­æœ‰æ•…éšœ
                if true_agent and true_agent.lower() != 'none':
                    # çœŸå®æœ‰æ•…éšœï¼Œæ¯”è¾ƒ Agent å’Œ Step
                    # ğŸ”¥ æ”¹è¿›çš„åŒ¹é…é€»è¾‘ï¼šå¤„ç†å¤§å°å†™ã€ä¸‹åˆ’çº¿ã€éƒ¨åˆ†åŒ¹é…
                    pred_agent_clean = str(pred_agent).strip() if pred_agent else ""
                    true_agent_clean = str(true_agent).strip()
                    
                    # æ ‡å‡†åŒ–ï¼šç§»é™¤æ‰€æœ‰ä¸‹åˆ’çº¿ï¼Œè½¬å°å†™ï¼ˆå¤„ç† 'Verification_Expert' vs 'VerificationExpert'ï¼‰
                    def normalize_agent_name(name):
                        return name.replace('_', '').replace('-', '').lower()
                    
                    pred_normalized = normalize_agent_name(pred_agent_clean)
                    true_normalized = normalize_agent_name(true_agent_clean)
                    
                    # 1. ç²¾ç¡®åŒ¹é…ï¼ˆå¿½ç•¥å¤§å°å†™ã€ä¸‹åˆ’çº¿ã€è¿å­—ç¬¦ï¼‰
                    agent_correct_exact = (pred_normalized == true_normalized)
                    
                    # 2. åŸå§‹ç²¾ç¡®åŒ¹é…ï¼ˆå¿½ç•¥å¤§å°å†™ï¼‰
                    agent_correct_exact_orig = (pred_agent_clean.lower() == true_agent_clean.lower())
                    
                    # 3. æ¨¡ç³ŠåŒ¹é…ï¼ˆåŒ…å«å…³ç³»ï¼Œæ ‡å‡†åŒ–åï¼‰
                    agent_correct_fuzzy = (
                        true_normalized in pred_normalized or
                        pred_normalized in true_normalized
                    )
                    
                    # 4. åŸå§‹æ¨¡ç³ŠåŒ¹é…ï¼ˆåŒ…å«å…³ç³»ï¼‰
                    agent_correct_fuzzy_orig = (
                        true_agent_clean.lower() in pred_agent_clean.lower() or
                        pred_agent_clean.lower() in true_agent_clean.lower()
                    )
                    
                    # 5. æå–æ‹¬å·å†…çš„Agentåç§°ï¼ˆå¤„ç† "å€™é€‰Agent 1 (Movie_Expert)" æ ¼å¼ï¼‰
                    bracket_match = re.search(r'\(([A-Za-z0-9_\-]+)\)', pred_agent_clean)
                    if bracket_match:
                        pred_agent_bracket = bracket_match.group(1)
                        pred_agent_bracket_normalized = normalize_agent_name(pred_agent_bracket)
                        agent_correct_bracket = (pred_agent_bracket_normalized == true_normalized)
                    else:
                        agent_correct_bracket = False
                    
                    # 6. éƒ¨åˆ†åŒ¹é…ï¼šæ£€æŸ¥æ ¸å¿ƒåç§°ï¼ˆç§»é™¤åç¼€å¦‚ '_Expert'ï¼‰
                    def get_core_name(name):
                        # ç§»é™¤å¸¸è§çš„åç¼€
                        name = name.replace('_Expert', '').replace('Expert', '')
                        name = name.replace('_', '').replace('-', '').lower()
                        return name
                    
                    pred_core = get_core_name(pred_agent_clean)
                    true_core = get_core_name(true_agent_clean)
                    agent_correct_core = (pred_core == true_core and len(pred_core) > 3)  # è‡³å°‘3ä¸ªå­—ç¬¦
                    
                    # ç»¼åˆåŒ¹é…ç»“æœ
                    agent_correct = (agent_correct_exact or agent_correct_exact_orig or 
                                   agent_correct_fuzzy or agent_correct_fuzzy_orig or 
                                   agent_correct_bracket or agent_correct_core)
                    
                    # StepåŒ¹é…ï¼šå…è®¸Â±1çš„è¯¯å·®ï¼ˆå› ä¸ºæ—¶é—´æ­¥å¯èƒ½ä¸ç²¾ç¡®ï¼‰
                    if pred_step is not None:
                        step_correct = (abs(pred_step - true_step) <= 1)
                    else:
                        step_correct = False
                    agent_acc = 1.0 if agent_correct else 0.0
                    step_acc = 1.0 if step_correct else 0.0
                else:
                    # çœŸå®æ— æ•…éšœï¼Œä½† LLM åˆ¤æ–­æœ‰æ•…éšœ -> é”™è¯¯
                    agent_acc = 0.0
                    step_acc = 0.0
            
            # ğŸ”¥ğŸ”¥ğŸ”¥ã€æ–°å¢ã€‘è¾“å‡ºè¡¨æ ¼æ‰€éœ€çš„å…³é”®ä¿¡æ¯ï¼ˆç”¨äºåç»­åˆ†æï¼‰
            # è®¡ç®—çœŸå®ç­”æ¡ˆåœ¨å€™é€‰ä¸­çš„æ’å
            true_agent_rank_in_candidates = None
            true_agent_rank_in_full = None
            
            if true_agent:
                # 1. åœ¨å€™é€‰åˆ—è¡¨ä¸­çš„æ’åï¼ˆTop-Kæ¨¡å¼ï¼‰
                try:
                    true_agent_rank_in_candidates = candidate_agent_ids.index(true_agent) + 1
                except ValueError:
                    true_agent_rank_in_candidates = -1  # ä¸åœ¨å€™é€‰ä¸­
                
                # 2. åœ¨å®Œæ•´æ’åºä¸­çš„æ’åï¼ˆå…¨è¾“å‡ºæ¨¡å¼ï¼‰
                if top_k is None and 'filtered_full_ranking' in locals() and filtered_full_ranking:
                    try:
                        true_agent_rank_in_full = filtered_full_ranking.index(true_agent) + 1
                    except ValueError:
                        true_agent_rank_in_full = -1
                else:
                    # Top-Kæ¨¡å¼ï¼Œæ— æ³•çŸ¥é“å®Œæ•´æ’å
                    true_agent_rank_in_full = None
            
            # è¾“å‡ºè¡¨æ ¼æ ¼å¼çš„å…³é”®ä¿¡æ¯ï¼ˆç»“æ„åŒ–æ—¥å¿—ï¼Œä¾¿äºåç»­è§£æå’Œæå–ï¼‰
            # æ ¼å¼ï¼šID | GNNæ’åº | LLMé€‰æ‹© | çœŸå®ç­”æ¡ˆ | çœŸå®ç­”æ¡ˆæ’å | æ˜¯å¦æ­£ç¡®
            if top_k is None:
                # å…¨è¾“å‡ºæ¨¡å¼ï¼šä½¿ç”¨å®Œæ•´æ’åºå’Œå®Œæ•´æ’å
                ranking_for_table = filtered_full_ranking if 'filtered_full_ranking' in locals() and filtered_full_ranking else candidate_agent_ids
                true_agent_rank = true_agent_rank_in_full if true_agent_rank_in_full is not None else true_agent_rank_in_candidates
                ranking_str = ",".join(ranking_for_table) if len(ranking_for_table) <= 100 else ",".join(ranking_for_table[:100]) + f",...(å…±{len(ranking_for_table)}ä¸ª)"
                rank_display = str(true_agent_rank) if true_agent_rank and true_agent_rank > 0 else "ä¸åœ¨æ’åºä¸­"
                print(f"  ğŸ“‹ [è¡¨æ ¼æ•°æ®] ID={json_file.stem} | GNNå®Œæ•´æ’åº={ranking_str} | LLMé€‰æ‹©={pred_agent or 'None'} | çœŸå®ç­”æ¡ˆ={true_agent} | çœŸå®ç­”æ¡ˆæ’å={rank_display} | æ˜¯å¦æ­£ç¡®={'æ˜¯' if agent_acc > 0.5 else 'å¦'}")
            else:
                # Top-Kæ¨¡å¼ï¼šè¾“å‡ºTop-Kæ’åºå’Œå€™é€‰æ’å
                ranking_str = ",".join(candidate_agent_ids)
                true_agent_rank = true_agent_rank_in_candidates
                rank_display = str(true_agent_rank) if true_agent_rank and true_agent_rank > 0 else f"ä¸åœ¨Top-{top_k}ä¸­"
                print(f"  ğŸ“‹ [è¡¨æ ¼æ•°æ®] ID={json_file.stem} | GNNæ’åº(Top-{top_k})={ranking_str} | LLMé€‰æ‹©={pred_agent or 'None'} | çœŸå®ç­”æ¡ˆ={true_agent} | çœŸå®ç­”æ¡ˆæ’å={rank_display} | æ˜¯å¦æ­£ç¡®={'æ˜¯' if agent_acc > 0.5 else 'å¦'}")
            
            # å­˜å‚¨çœŸå®ç­”æ¡ˆæ’åï¼ˆç”¨äºåç»­ç»Ÿè®¡åˆ†æï¼‰- ä»…åœ¨å…¨è¾“å‡ºæ¨¡å¼ä¸‹
            if top_k is None and true_agent and true_agent_rank and true_agent_rank > 0:
                true_agent_ranks.append(true_agent_rank)
            
            # 7. ç»§ç»­åç»­å¤„ç†ï¼ˆå‡†ç¡®ç‡å·²åœ¨å‰é¢è®¡ç®—ï¼‰
            
            # ğŸ” è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°å‡†ç¡®ç‡è®¡ç®—ç»“æœï¼ˆåœ¨è¡¨æ ¼æ•°æ®ä¹‹åæ‰“å°ï¼‰
            try:
                agent_correct_debug = agent_correct
                step_correct_debug = step_correct
                exact_debug = agent_correct_exact
                exact_orig_debug = agent_correct_exact_orig if 'agent_correct_exact_orig' in locals() else 'N/A'
                fuzzy_debug = agent_correct_fuzzy
                fuzzy_orig_debug = agent_correct_fuzzy_orig if 'agent_correct_fuzzy_orig' in locals() else 'N/A'
                bracket_debug = agent_correct_bracket
                core_debug = agent_correct_core if 'agent_correct_core' in locals() else 'N/A'
            except NameError:
                agent_correct_debug = 'N/A (pred_agent is Noneåˆ†æ”¯)'
                step_correct_debug = 'N/A (pred_agent is Noneåˆ†æ”¯)'
                exact_debug = 'N/A'
                exact_orig_debug = 'N/A'
                fuzzy_debug = 'N/A'
                fuzzy_orig_debug = 'N/A'
                bracket_debug = 'N/A'
                core_debug = 'N/A'
            
            print(f"  [è°ƒè¯•] Agentå‡†ç¡®ç‡: {agent_acc}, Stepå‡†ç¡®ç‡: {step_acc}")
            print(f"  [è°ƒè¯•] åŒ¹é…ç»“æœ: agent_correct={agent_correct_debug}, step_correct={step_correct_debug}")
            if agent_correct_debug != 'N/A (pred_agent is Noneåˆ†æ”¯)':
                print(f"  [è°ƒè¯•] åŒ¹é…è¯¦æƒ…: exact={exact_debug}, exact_orig={exact_orig_debug}, fuzzy={fuzzy_debug}, fuzzy_orig={fuzzy_orig_debug}, bracket={bracket_debug}, core={core_debug}")
                if pred_step is not None:
                    print(f"  [è°ƒè¯•] StepåŒ¹é…: pred_step={pred_step}, true_step={true_step}, è¯¯å·®={abs(pred_step - true_step) if 'true_step' in locals() else 'N/A'}")
            
            # 7. åˆ†ç±»è®°å½•ï¼ˆAlgorithm-Generated / Hand-Craftedï¼‰
            filename = json_file.name
            metrics_total['agent'].append(agent_acc)
            metrics_total['step'].append(step_acc)
            
            if "Algorithm-Generated" in filename:
                metrics_alg['agent'].append(agent_acc)
                metrics_alg['step'].append(step_acc)
                count_alg += 1
            elif "Hand-Crafted" in filename:
                metrics_hand['agent'].append(agent_acc)
                metrics_hand['step'].append(step_acc)
                count_hand += 1
            
            # ğŸ”¥ æ–°å¢ï¼šæŒ‰é¢†åŸŸåˆ†ç±»ï¼ˆCode/Math/Agenticï¼‰- ç”¨äºAgenTracerå¯¹æ¯”
            domain = graph_data.get('domain', graph_data.get('benchmark', 'Unknown'))
            # æ ‡å‡†åŒ–domainåç§°
            domain_lower = domain.lower()
            if 'code' in domain_lower or 'kodcode' in domain_lower or 'mbpp' in domain_lower:
                domain_standard = 'Code'
            elif 'math' in domain_lower or 'gsm8k' in domain_lower:
                domain_standard = 'Math'
            elif 'agentic' in domain_lower or 'gaia' in domain_lower or 'hotpot' in domain_lower:
                domain_standard = 'Agentic'
            else:
                domain_standard = 'Unknown'
            
            # åˆå§‹åŒ–domainç»Ÿè®¡ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            if domain_standard not in metrics_domains:
                metrics_domains[domain_standard] = {'agent': [], 'step': []}
                domain_counts[domain_standard] = 0
            
            metrics_domains[domain_standard]['agent'].append(agent_acc)
            metrics_domains[domain_standard]['step'].append(step_acc)
            domain_counts[domain_standard] += 1
            
        except Exception as e:
            print(f"âš ï¸ å¤„ç†æ–‡ä»¶ {json_file.name} æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š è¯„ä¼°ç»Ÿè®¡:")
    print(f"   - æ€»æ–‡ä»¶æ•°: {len(json_files)}")
    print(f"   - è·³è¿‡ï¼ˆæ— æ ‡ç­¾ï¼‰: {skipped_no_label}")
    print(f"   - è·³è¿‡ï¼ˆæ— å›¾ï¼‰: {skipped_no_graph}")
    print(f"   - æˆåŠŸå¤„ç†: {len(metrics_total['agent'])}")
    
    # è¾“å‡ºç»“æœ
    print("\n" + "=" * 80)
    # ğŸ”¥ æ¶ˆèå®éªŒæ ‡è®°ï¼šåœ¨ç»“æœæ ‡é¢˜ä¸­æ˜¾ç¤º
    ablation_marker = ""
    if is_ablation_no_finetune:
        ablation_marker = " [æ¶ˆèå®éªŒ: GNN + æœªå¾®è°ƒLLM]"
    print(f"ğŸ† é˜¶æ®µä¸‰è¯„ä¼°ç»“æœ (Coarse-to-Fine){ablation_marker}")
    print("=" * 80)
    print(f"{'Dataset':<25} | {'Count':<8} | {'Agent Acc (Who)':<18} | {'Step Acc (When)':<18}")
    print("-" * 80)
    
    def get_mean(m_list):
        return np.mean(m_list) if m_list else 0.0
    
    # Algorithm-Generated
    alg_a = get_mean(metrics_alg['agent'])
    alg_s = get_mean(metrics_alg['step'])
    print(f"{'Algorithm-Generated':<25} | {len(metrics_alg['agent']):<8} | {alg_a:.4f} ({alg_a*100:5.2f}%) | {alg_s:.4f} ({alg_s*100:5.2f}%)")
    
    # Hand-Crafted
    hand_a = get_mean(metrics_hand['agent'])
    hand_s = get_mean(metrics_hand['step'])
    print(f"{'Hand-Crafted':<25} | {len(metrics_hand['agent']):<8} | {hand_a:.4f} ({hand_a*100:5.2f}%) | {hand_s:.4f} ({hand_s*100:5.2f}%)")
    
    print("-" * 80)
    
    # Overall
    tot_a = get_mean(metrics_total['agent'])
    tot_s = get_mean(metrics_total['step'])
    print(f"{'Overall (Total)':<25} | {len(metrics_total['agent']):<8} | {tot_a:.4f} ({tot_a*100:5.2f}%) | {tot_s:.4f} ({tot_s*100:5.2f}%)")
    print("=" * 80)
    
    # ğŸ”¥ğŸ”¥ğŸ”¥ã€æ–°å¢ã€‘çœŸå®ç­”æ¡ˆæ’åç»Ÿè®¡åˆ†æï¼ˆç”¨äºè¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æï¼‰
    if top_k is None and true_agent_ranks:
        ranks = true_agent_ranks
        print("\n" + "=" * 80)
        print("ğŸ“Š çœŸå®ç­”æ¡ˆæ’åç»Ÿè®¡åˆ†æ (True Answer Rank Analysis)")
        print("=" * 80)
        print(f"æ€»æ ·æœ¬æ•°: {len(ranks)}")
        print(f"å¹³å‡æ’å: {np.mean(ranks):.2f}")
        print(f"ä¸­ä½æ•°æ’å: {np.median(ranks):.2f}")
        print(f"æœ€å¤§æ’å: {np.max(ranks)}")
        print(f"æœ€å°æ’å: {np.min(ranks)}")
        print(f"æ ‡å‡†å·®: {np.std(ranks):.2f}")
        
        # è®¡ç®—æ’ååˆ†å¸ƒ
        print(f"\næ’ååˆ†å¸ƒ:")
        rank_counts = {}
        for rank in ranks:
            rank_counts[rank] = rank_counts.get(rank, 0) + 1
        for rank in sorted(rank_counts.keys())[:20]:  # åªæ˜¾ç¤ºå‰20å
            count = rank_counts[rank]
            percentage = count / len(ranks) * 100
            print(f"  ç¬¬{rank}å: {count}æ¬¡ ({percentage:.2f}%)")
        
        # è®¡ç®—ç´¯ç§¯åˆ†å¸ƒï¼ˆç”¨äºç¡®å®šé˜ˆå€¼ï¼‰
        print(f"\nç´¯ç§¯åˆ†å¸ƒï¼ˆç”¨äºTop-Næ•æ„Ÿæ€§åˆ†æï¼‰:")
        sorted_ranks = sorted(ranks)
        for n in [1, 2, 3, 4, 5, 7, 10, 15, 20]:
            count_within_n = sum(1 for r in ranks if r <= n)
            percentage = count_within_n / len(ranks) * 100
            print(f"  Top-{n}: {count_within_n}/{len(ranks)} ({percentage:.2f}%)")
        
        # æ‰¾åˆ°99%é˜ˆå€¼ï¼ˆç”¨äºè®ºæ–‡å®éªŒï¼‰
        print(f"\né˜ˆå€¼åˆ†æï¼ˆç”¨äºè¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æï¼‰:")
        for percentile in [50, 75, 90, 95, 99, 99.9]:
            threshold = np.percentile(ranks, percentile)
            print(f"  {percentile}%çš„çœŸå®ç­”æ¡ˆæ’å â‰¤ {threshold:.1f}")
        
        print("=" * 80)
    
    # ğŸ”¥ æ–°å¢ï¼šæŒ‰é¢†åŸŸåˆ†ç±»è¾“å‡ºï¼ˆCode/Math/Agenticï¼‰- ç”¨äºAgenTracerå¯¹æ¯”
    if metrics_domains:
        print("\n" + "=" * 80)
        print("ğŸ† é¢†åŸŸåˆ†ç±»è¯„ä¼°ç»“æœ (Domain-wise Evaluation for AgenTracer Comparison)")
        print("=" * 80)
        print(f"{'Domain':<15} | {'Count':<8} | {'Agent Acc (Who)':<18} | {'Step Acc (When)':<18}")
        print("-" * 80)
        
        domain_results = {}
        for domain in sorted(metrics_domains.keys()):
            if domain == 'Unknown':
                continue  # è·³è¿‡Unknowné¢†åŸŸ
            domain_agent_acc = get_mean(metrics_domains[domain]['agent'])
            domain_step_acc = get_mean(metrics_domains[domain]['step'])
            domain_count = domain_counts.get(domain, len(metrics_domains[domain]['agent']))
            print(f"{domain:<15} | {domain_count:<8} | {domain_agent_acc:.4f} ({domain_agent_acc*100:5.2f}%) | {domain_step_acc:.4f} ({domain_step_acc*100:5.2f}%)")
            
            domain_results[domain.lower()] = {
                'count': domain_count,
                'agent_acc': domain_agent_acc,
                'step_acc': domain_step_acc
            }
        
        if 'Unknown' in metrics_domains:
            unknown_count = domain_counts.get('Unknown', len(metrics_domains['Unknown']['agent']))
            if unknown_count > 0:
                unknown_agent_acc = get_mean(metrics_domains['Unknown']['agent'])
                unknown_step_acc = get_mean(metrics_domains['Unknown']['step'])
                print(f"{'Unknown':<15} | {unknown_count:<8} | {unknown_agent_acc:.4f} ({unknown_agent_acc*100:5.2f}%) | {unknown_step_acc:.4f} ({unknown_step_acc*100:5.2f}%)")
        
        print("=" * 80)
    else:
        domain_results = {}
    
    return {
        'algorithm_generated': {
            'count': len(metrics_alg['agent']),
            'agent_acc': alg_a,
            'step_acc': alg_s
        },
        'hand_crafted': {
            'count': len(metrics_hand['agent']),
            'agent_acc': hand_a,
            'step_acc': hand_s
        },
        'overall': {
            'count': len(metrics_total['agent']),
            'agent_acc': tot_a,
            'step_acc': tot_s
        },
        'domains': domain_results  # ğŸ”¥ æ–°å¢ï¼šé¢†åŸŸåˆ†ç±»ç»“æœ
    }


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="é˜¶æ®µä¸‰è¯„ä¼°ï¼šCoarse-to-Fine ç³»ç»Ÿé›†æˆ")
    parser.add_argument(
        "--test_data_dir",
        type=str,
        default="processed_graphs/graphs_whowhen",
        help="æµ‹è¯•æ•°æ®ç›®å½•"
    )
    parser.add_argument(
        "--gnn_checkpoint",
        type=str,
        required=True,
        help="GNN æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„"
    )
    parser.add_argument(
        "--llm_adapter",
        type=str,
        default="checkpoints_qwen3_finetune_large/final_model",
        help="LLM LoRA é€‚é…å™¨è·¯å¾„ã€‚è®¾ç½®ä¸ºç©ºå­—ç¬¦ä¸² '' æˆ– 'none' ä»¥ä½¿ç”¨æœªå¾®è°ƒçš„åŸºç¡€æ¨¡å‹ï¼ˆæ¶ˆèå®éªŒï¼‰"
    )
    parser.add_argument(
        "--no_finetune",
        action="store_true",
        help="æ¶ˆèå®éªŒæ ‡å¿—ï¼šå¼ºåˆ¶ä½¿ç”¨æœªå¾®è°ƒçš„åŸºç¡€æ¨¡å‹ï¼ˆç­‰åŒäº --llm_adapter ''ï¼‰"
    )
    parser.add_argument(
        "--converter_path",
        type=str,
        default="processed_data/converter_state.pt",
        help="Converter çŠ¶æ€è·¯å¾„"
    )
    parser.add_argument(
        "--top_k",
        type=int,
        default=None,
        help="Top-K å€™é€‰æ•°é‡ï¼ˆé»˜è®¤None=å…¨è¾“å‡ºæ‰€æœ‰Agentæ’åºï¼Œç”¨äºè¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æï¼›æŒ‡å®šæ•°å­—åˆ™è¾“å‡ºTop-Kï¼Œä¾‹å¦‚ --top_k 7ï¼‰"
    )
    parser.add_argument(
        "--device",
        type=str,
        default=None,
        help="è®¾å¤‡ (cuda/cpu)"
    )
    parser.add_argument(
        "--base_model_name",
        type=str,
        default="Qwen/Qwen3-8B",
        help="åŸºç¡€LLMæ¨¡å‹åç§°ï¼ˆé»˜è®¤: Qwen/Qwen3-8Bï¼Œæ”¯æŒæ€è€ƒæ¨¡å¼ï¼Œå¯é€‰: Qwen/Qwen2.5-7B-Instruct, Qwen/Qwen2.5-4B-Instruct æˆ– Qwen/Qwen1.5-4B-Chatï¼‰"
    )
    
    args = parser.parse_args()
    
    # ğŸ”¥ æ¶ˆèå®éªŒæ”¯æŒï¼šå¦‚æœè®¾ç½®äº† --no_finetuneï¼Œå¼ºåˆ¶ä½¿ç”¨æœªå¾®è°ƒçš„åŸºç¡€æ¨¡å‹
    if args.no_finetune:
        args.llm_adapter = ""
        print("\n" + "=" * 80)
        print("ğŸ”¬ æ¶ˆèå®éªŒæ¨¡å¼ï¼šä½¿ç”¨æœªå¾®è°ƒçš„åŸºç¡€æ¨¡å‹ï¼ˆGNN + æœªå¾®è°ƒ LLMï¼‰")
        print("=" * 80)
    
    # å¦‚æœ llm_adapter æ˜¯ 'none' æˆ–ç©ºå­—ç¬¦ä¸²ï¼Œä¹Ÿè§†ä¸ºæœªå¾®è°ƒæ¨¡å¼
    if args.llm_adapter.lower() in ['none', '']:
        print("\n" + "=" * 80)
        print("ğŸ”¬ æ¶ˆèå®éªŒæ¨¡å¼ï¼šä½¿ç”¨æœªå¾®è°ƒçš„åŸºç¡€æ¨¡å‹ï¼ˆGNN + æœªå¾®è°ƒ LLMï¼‰")
        print("=" * 80)
        args.llm_adapter = ""
    
    results = evaluate_stage3(
        test_data_dir=args.test_data_dir,
        gnn_checkpoint=args.gnn_checkpoint,
        llm_adapter=args.llm_adapter,
        converter_path=args.converter_path,
        top_k=args.top_k,
        device=args.device,
        base_model_name=args.base_model_name
    )
    
    # ğŸ”¥ Tokenç»Ÿè®¡ï¼šæ‰“å°ç»Ÿè®¡æŠ¥å‘Š
    token_counter.print_summary()
    
    print("\nâœ… è¯„ä¼°å®Œæˆï¼")
