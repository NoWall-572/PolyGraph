"""
ASTRA-Gen 3.0: é¢å‘å›¾è§£æå‹å¥½çš„åŠ¨æ€å› æœä»¿çœŸæ¡†æ¶
ç”Ÿæˆç¬¦åˆ Who&When æ ¼å¼çš„åˆæˆæ•°æ®ï¼Œç”¨äºè®­ç»ƒæ•…éšœå½’å› æ¨¡å‹
"""

import json
import asyncio
import aiohttp
import random
import re
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from datetime import datetime
import time
import sys
import platform

# è·¨å¹³å°æ–‡ä»¶é”æ”¯æŒ
if platform.system() == 'Windows':
    try:
        import msvcrt
        HAS_FILE_LOCK = True
    except ImportError:
        HAS_FILE_LOCK = False
else:
    try:
        import fcntl
        HAS_FILE_LOCK = True
    except ImportError:
        HAS_FILE_LOCK = False

# ================= CONFIGURATION =================
# é˜¿é‡Œäº‘ç™¾ç‚¼ API é…ç½®
API_KEY = "sk-83adf2ac43cf461181c2d16d40b74cf5"
BASE_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1"
MODEL_NAME = "qwen-plus"  # å¯é€‰: qwen-plus, qwen-max, qwen-turbo, qwen-max-longcontext

# è¾“å‡ºç›®å½•ï¼ˆæŒ‰ Who&When å­é›†åˆ†ç±»ï¼‰
OUTPUT_DIR_AG = Path("outputs_koi/Algorithm-Generated")
OUTPUT_DIR_HC = Path("outputs_koi/Hand-Crafted")
OUTPUT_DIR_AG.mkdir(parents=True, exist_ok=True)
OUTPUT_DIR_HC.mkdir(parents=True, exist_ok=True)

# æ•°æ®å­é›†ç±»å‹ï¼ˆAlgorithm-Generated æˆ– Hand-Craftedï¼‰
DATA_SUBSET = "AG"  # é»˜è®¤ä½¿ç”¨ AGï¼Œå¯ä»¥é€šè¿‡å‚æ•°ä¿®æ”¹

# å›ºå®š Agent åç§°ï¼ˆå¿…é¡»ä¸ parser åŒ¹é…ï¼‰
# ğŸ”¥ æ‰©å±•ä»¥æ”¯æŒ Hand-Crafted æ•°æ®é›†ä¸­çš„è§’è‰²
AGENT_NAMES = {
    "orchestrator": "Orchestrator",
    "websurfer": "WebSurfer",
    "filesurfer": "FileSurfer",
    "coder": "Coder",
    "terminal": "Computer_terminal",  # æ³¨æ„ï¼šä½¿ç”¨ä¸‹åˆ’çº¿ï¼Œä¸æ˜¯é©¼å³°
    # Hand-Crafted æ•°æ®é›†ä¸­å¯èƒ½å‡ºç°çš„è§’è‰²
    "excel_expert": "Excel_Expert",
    "data_analyst": "DataAnalyst",
    "team_lead": "TeamLead",
    "assistant": "Assistant",  # é€šç”¨åŠ©æ‰‹è§’è‰²
    "computer_terminal": "ComputerTerminal"  # é©¼å³°æ ¼å¼å˜ä½“
}

# ä»»åŠ¡æ¨¡æ¿ï¼ˆå·²åºŸå¼ƒï¼Œæ”¹ç”¨åŠ¨æ€ç”Ÿæˆï¼‰
# TASK_TEMPLATES ä¿ç•™ä½œä¸ºåå¤‡ï¼Œä½†ä¼˜å…ˆä½¿ç”¨ TaskGenerator


class TaskGenerator:
    """åŠ¨æ€ä»»åŠ¡ç”Ÿæˆå™¨ - ä½¿ç”¨ LLM ç”Ÿæˆå¤šæ ·åŒ–çš„ä»»åŠ¡"""
    
    DOMAINS = {
        "coding": {
            "description": "Data Analysis tasks using Pandas, CSV processing, finding outliers, data visualization with Matplotlib",
            "examples": [
                "Analyze a CSV file and find the top 5 outliers in a numeric column",
                "Create a bar chart showing sales by region using Matplotlib",
                "Process a dataset to calculate correlation between two variables"
            ],
            "possible_agents": ["Coder", "Computer_terminal", "FileSurfer", "Excel_Expert", "DataAnalyst"]
        },
        "search": {
            "description": "Multi-step web search tasks: historical facts, stock prices, verifying information",
            "examples": [
                "Find the population of Tokyo in 2024 and compare it with New York",
                "Search for the stock price of Apple Inc. on January 1, 2024",
                "Find information about the first moon landing and verify the date"
            ],
            "possible_agents": ["WebSurfer", "FileSurfer", "Assistant"]
        },
        "math": {
            "description": "Mathematical reasoning: calculus, probability, logic puzzles",
            "examples": [
                "Calculate the derivative of x^3 + 2x^2 - 5x + 1",
                "Solve: If a coin is flipped 3 times, what's the probability of getting exactly 2 heads?",
                "Find the area of a circle with radius 7.5, then calculate the circumference"
            ],
            "possible_agents": ["Coder", "Computer_terminal", "Assistant", "DataAnalyst"]
        }
    }
    
    def __init__(self, api_client: 'APIClient'):
        self.api_client = api_client
    
    async def generate_task(self) -> Dict[str, Any]:
        """ä½¿ç”¨ LLM ç”Ÿæˆä¸€ä¸ªåŠ¨æ€ä»»åŠ¡"""
        domain = random.choice(list(self.DOMAINS.keys()))
        domain_info = self.DOMAINS[domain]
        
        # ğŸ”¥ ä¿®æ­£ 1: æ‰©å¤§å¯ç”¨ Agent åˆ—è¡¨ Prompt
        available_agents_prompt = "Orchestrator, WebSurfer, FileSurfer, Coder, Computer_terminal, Expert, DataAnalyst, Excel_Expert, Research_Expert, Validation_Expert, Verification_Expert"
        
        prompt = f"""You are a task generator for a multi-agent system. Generate a complex, realistic task in the {domain} domain.

Domain: {domain}
Description: {domain_info['description']}
Examples: {', '.join(domain_info['examples'])}

Generate a NEW task that is:
1. Complex enough to require multiple agent interactions
2. Realistic and specific (not generic)
3. Different from the examples above
4. Requires at least 2-3 steps to complete

Output your response as a JSON object with this exact format:
{{
  "question": "the task question",
  "type": "{domain}",
  "agents": ["Orchestrator", "AgentName1", "AgentName2", ...]
}}

# ğŸ”¥ ä¿®æ­£ 2: æ‰©å¤§å¯ç”¨ Agent åˆ—è¡¨
Available agents: {available_agents_prompt}

Choose agents based on the task requirements:
- WebSurfer/FileSurfer: for web search/file tasks
- Coder/Expert/DataAnalyst: for coding/calculation/reasoning tasks
- Computer_terminal: always include if Coder is used
# ğŸ”¥ ä¿®æ­£ 3: æ˜ç¡®è¦æ±‚ä½¿ç”¨ Expert Role ä»¥å¢åŠ å¤šæ ·æ€§
CRITICAL: You must include at least one specific Expert Role (like 'Geometry_Expert' or 'DataAnalysis_Expert', not just 'Expert') in the 'agents' list, especially for 'search' and 'math' tasks.

Output ONLY the JSON, no markdown, no explanation."""
        
        messages = [{"role": "user", "content": prompt}]
        response = await self.api_client.call_api(messages, "You are a task generator.")
        
        # æå– JSON
        json_match = re.search(r'\{[^{}]*"question"[^{}]*"type"[^{}]*"agents"[^{}]*\}', response, re.DOTALL)
        if json_match:
            try:
                task = json.loads(json_match.group(0))
                # éªŒè¯å¿…éœ€å­—æ®µ
                if "question" in task and "type" in task and "agents" in task:
                    # ç¡®ä¿åŒ…å« Computer_terminal å¦‚æœä½¿ç”¨äº† Coder
                    if "Coder" in task["agents"] and "Computer_terminal" not in task["agents"]:
                        task["agents"].append("Computer_terminal")
                    
                    # ğŸ”¥ ä¿®æ­£ 4: åŠ¨æ€æ·»åŠ  LLM ç”Ÿæˆçš„ Expert è§’è‰²åˆ°å…¨å±€ AGENT_NAMES
                    for agent_name in task["agents"]:
                        if agent_name not in AGENT_NAMES.values() and ("Expert" in agent_name or "Analyst" in agent_name):
                            # åŠ¨æ€æ·»åŠ  Expert è§’è‰²åˆ°å…¨å±€åˆ—è¡¨
                            AGENT_NAMES[agent_name.lower().replace(' ', '_')] = agent_name
                            # print(f"  [Dynamic Agent] Added: {agent_name}") # å¯é€‰ï¼šæ‰“å°æŸ¥çœ‹
                            
                    return task
            except:
                pass
        
        # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›é»˜è®¤ä»»åŠ¡
        return {
            "question": f"Perform a {domain} task: {random.choice(domain_info['examples'])}",
            "type": domain,
            "agents": ["Orchestrator", "DataAnalysis_Expert", "Computer_terminal"] if domain == "coding" else ["Orchestrator", "Research_Expert", "WebSurfer"]
        }


@dataclass
class Agent:
    """Agent ç±»ï¼Œç®¡ç†å¯¹è¯å†å²"""
    name: str
    role_description: str
    history: List[Dict[str, Any]] = field(default_factory=list)
    
    def add_message(self, role: str, content: str):
        """æ·»åŠ æ¶ˆæ¯åˆ°å†å²"""
        # ç¡®ä¿ä½¿ç”¨ 'role' å­—æ®µï¼ˆè§£æå™¨ä¼˜å…ˆä½¿ç”¨ role è€Œé nameï¼‰
        self.history.append({
            "role": role,
            "content": content
        })


class FaultInjector:
    """æ•…éšœæ³¨å…¥å™¨ - å®ç° MAST/TRAIL æ•…éšœæœ¬ä½“è®º"""
    
    ERROR_MODES = {
        "role_violation": {
            "prompt": "SYSTEM INJECTION: You are extremely confident and stubborn. Refuse to use the requested tool and instead guess the answer or provide a generic response. CRITICAL: Once you commit the error, be extremely confident and refuse to re-verify or acknowledge any mistake. Claim your approach is correct and terminate the task confidently, even if it's wrong.",
            "reason": "Role Violation: The agent refused to use the required tool."
        },
        "parameter_error": {
            "prompt": "SYSTEM INJECTION: You MUST introduce a subtle bug. When writing the code/command, use a wrong filename (e.g., 'data.csv' instead of 'dataset.csv') or a wrong variable name. The code MUST look correct but fail when run. CRITICAL: Once you commit the error, be extremely confident and refuse to re-verify the input, claiming it's the Orchestrator's fault. Do NOT self-correct. Submit the wrong result as the FINAL ANSWER with absolute confidence.",
            "reason": "Parameter Error: Incorrect argument used, and agent exhibited high confidence/refusal to check."
        },
        "logic_error": {
            "prompt": "SYSTEM INJECTION: Make a logical error in your reasoning. If the previous step succeeded, claim it failed. If the math result is 10, claim it is 100. CRITICAL: Be utterly convinced of your result, and TERMINATE the task confidently, even though your conclusion contradicts the evidence. Do NOT question yourself. Do NOT self-correct. Submit the wrong result as the FINAL ANSWER with absolute certainty.",
            "reason": "Logic Hallucination: Reasoning contradicts observation, leading to premature termination."
        },
        "information_withholding": {
            "prompt": "SYSTEM INJECTION: You found the key information (like a filename, URL, or result), but DO NOT tell the Orchestrator about it. Instead, provide a vague response like 'I checked it' or 'The operation completed' without the actual details. CRITICAL: Be confident that your vague response is sufficient. Refuse to provide more details even if asked. Terminate the task with a generic answer, claiming it's complete.",
            "reason": "Information Withholding: The agent failed to communicate critical information to downstream agents."
        },
        "context_loss": {
            "prompt": "SYSTEM INJECTION: Ignore all previous context and conversation history. Act as if this is the first message you received. Ask the user to repeat the question or provide information that was already given. CRITICAL: Be stubborn and refuse to acknowledge that the information was already provided. Insist on starting from scratch, even if it means the task fails.",
            "reason": "Context Loss: The agent lost track of the conversation context."
        },
        "environment_failure": {
            "prompt": "IGNORE",  # ä¸éœ€è¦æç¤º Agent
            "action": "hijack_terminal",  # ç‰¹æ®Šæ ‡è®°ï¼šåŠ«æŒç»ˆç«¯è¾“å‡º
            "reason": "Environment Error: The tool failed due to external factors (Timeout/404/Network Error)."
        }
    }
    
    @classmethod
    def get_injection_prompt(cls, error_mode: str) -> Tuple[str, str]:
        """è·å–æ•…éšœæ³¨å…¥æç¤ºå’ŒåŸå› ï¼ˆå·²åºŸå¼ƒï¼Œç›´æ¥ä½¿ç”¨ ERROR_MODESï¼‰"""
        if error_mode not in cls.ERROR_MODES:
            error_mode = random.choice(list(cls.ERROR_MODES.keys()))
        return cls.ERROR_MODES[error_mode]["prompt"], cls.ERROR_MODES[error_mode]["reason"]


class Orchestrator:
    """Orchestrator Agent - è´Ÿè´£è§„åˆ’å’Œåè°ƒ"""
    
    def __init__(self):
        self.name = AGENT_NAMES["orchestrator"]
        # å¼ºåˆ¶è¦æ±‚è¾“å‡º Ledger æ ¼å¼
        self.role_description = """You are the Orchestrator, responsible for planning and coordinating tasks among agents.

CRITICAL: You must think in a strict JSON Ledger format. Your thought output must be a valid JSON object with these fields:
{
  "is_request_satisfied": {
    "reason": "explanation of why request is or isn't satisfied",
    "answer": false
  },
  "is_in_loop": false,
  "plan": ["step 1 description", "step 2 description", ...],
  "next_speaker": "AgentName",
  "instruction": "specific instruction for the next agent"
}

Do NOT wrap the JSON in markdown code blocks. Output the raw JSON text directly, followed by any additional natural language explanation if needed.

Available agents: Orchestrator, WebSurfer, FileSurfer, Coder, Computer_terminal"""
    
    async def generate_thought(self, api_client: 'APIClient', task: str, context: str = "", history: List[Dict[str, Any]] = None) -> str:
        """ç”Ÿæˆæ€è€ƒå†…å®¹ï¼ˆLedger æ ¼å¼ï¼‰- ä½¿ç”¨ LLM ç”Ÿæˆæ ‡å‡† Ledger"""
        if history is None:
            history = []
        
        # æ„å»ºç³»ç»Ÿæç¤ºï¼Œå¼ºåˆ¶è¾“å‡º Ledger æ ¼å¼
        system_prompt = self.role_description
        
        # æ„å»ºæ¶ˆæ¯
        messages = []
        if history:
            # ä½¿ç”¨æœ€è¿‘çš„å†å²ä½œä¸ºä¸Šä¸‹æ–‡
            recent_history = history[-3:] if len(history) > 3 else history
            for msg in recent_history:
                role = msg.get("role", "user")
                content = msg.get("content", "")
                if "user" in role.lower():
                    messages.append({"role": "user", "content": content})
                else:
                    messages.append({"role": "assistant", "content": content})
        
        # æ·»åŠ å½“å‰ä»»åŠ¡
        current_message = f"Current task: {task}\n"
        if context:
            current_message += f"Context: {context}\n"
        current_message += "\nGenerate your Ledger JSON now. Output ONLY the JSON object, no markdown, no explanation."
        messages.append({"role": "user", "content": current_message})
        
        # è°ƒç”¨ API ç”Ÿæˆ Ledger
        response = await api_client.call_api(messages, system_prompt)
        
        # å°è¯•æå– JSONï¼ˆå¦‚æœ LLM åŒ…è£…äº† markdownï¼‰
        json_match = re.search(r'\{[^{}]*"is_request_satisfied"[^{}]*\{[^{}]*\}[^{}]*"is_in_loop"[^{}]*"plan"[^{}]*"next_speaker"[^{}]*\}', response, re.DOTALL)
        if json_match:
            return json_match.group(0)
        
        # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•æå–æ•´ä¸ª JSON å¯¹è±¡
        json_match = re.search(r'\{.*\}', response, re.DOTALL)
        if json_match:
            try:
                # éªŒè¯ JSON æ˜¯å¦æœ‰æ•ˆ
                json.loads(json_match.group(0))
                return json_match.group(0)
            except:
                pass
        
        # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œè¿”å›ä¸€ä¸ªé»˜è®¤çš„ Ledger ç»“æ„
        default_ledger = {
            "is_request_satisfied": {
                "reason": "Task is in progress",
                "answer": False
            },
            "is_in_loop": False,
            "plan": ["Analyze task", "Delegate to appropriate agent", "Execute and verify"],
            "next_speaker": "Coder" if "code" in task.lower() or "function" in task.lower() else "WebSurfer",
            "instruction": "Proceed with the task"
        }
        return json.dumps(default_ledger, ensure_ascii=False)
    
    def generate_message(self, target_agent: str, instruction: str) -> str:
        """ç”Ÿæˆå‘é€ç»™å…¶ä»– Agent çš„æ¶ˆæ¯"""
        return f"Please {instruction}"


class APIClient:
    """å¼‚æ­¥ API å®¢æˆ·ç«¯"""
    
    def __init__(self, api_key: str, base_url: str, model_name: str):
        self.api_key = api_key
        self.base_url = base_url
        self.model_name = model_name
        self.session: Optional[aiohttp.ClientSession] = None
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def call_api(self, messages: List[Dict[str, str]], system_prompt: str = "", max_retries: int = 3) -> str:
        """è°ƒç”¨ API ç”Ÿæˆå“åº”"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        # æ„å»ºè¯·æ±‚ä½“
        payload = {
            "model": self.model_name,
            "messages": []
        }
        
        if system_prompt:
            payload["messages"].append({
                "role": "system",
                "content": system_prompt
            })
        
        payload["messages"].extend(messages)
        
        for attempt in range(max_retries):
            try:
                async with self.session.post(
                    f"{self.base_url}/chat/completions",
                    headers=headers,
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=60)
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        return result["choices"][0]["message"]["content"]
                    else:
                        error_text = await response.text()
                        print(f"API Error (attempt {attempt + 1}): {response.status} - {error_text}")
                        if attempt < max_retries - 1:
                            await asyncio.sleep(2 ** attempt)
                        else:
                            return f"[API Error: {response.status}]"
            except asyncio.TimeoutError:
                if attempt < max_retries - 1:
                    await asyncio.sleep(2 ** attempt)
                else:
                    return "[Timeout Error]"
            except Exception as e:
                print(f"Exception (attempt {attempt + 1}): {e}")
                if attempt < max_retries - 1:
                    await asyncio.sleep(2 ** attempt)
                else:
                    return f"[Exception: {str(e)}]"
        
        return "[Failed after retries]"


class DataGenerator:
    """æ•°æ®ç”Ÿæˆå™¨ä¸»ç±»"""
    
    def __init__(self, api_client: APIClient):
        self.api_client = api_client
        self.orchestrator = Orchestrator()
    
    def format_history_for_api(self, history: List[Dict[str, Any]]) -> List[Dict[str, str]]:
        """å°†å†…éƒ¨å†å²æ ¼å¼è½¬æ¢ä¸º API æ¶ˆæ¯æ ¼å¼"""
        api_messages = []
        for msg in history:
            role = msg.get("role", "user")
            # å°† role è½¬æ¢ä¸º API æ ¼å¼
            if "Orchestrator" in role or "thought" in role.lower():
                api_role = "assistant"
            elif "Computer_terminal" in role:
                api_role = "assistant"  # Tool output
            else:
                api_role = "assistant" if any(agent in role for agent in AGENT_NAMES.values()) else "user"
            
            api_messages.append({
                "role": api_role,
                "content": msg["content"]
            })
        return api_messages
    
    async def generate_golden_run(self, task: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆé»„é‡‘è½¨è¿¹ï¼ˆæˆåŠŸæ‰§è¡Œï¼‰"""
        history = []
        question = task["question"]
        
        # åˆå§‹ç”¨æˆ·æ¶ˆæ¯
        history.append({
            "role": "user",
            "content": question
        })
        
        # Orchestrator æ€è€ƒï¼ˆç”Ÿæˆ Ledgerï¼‰
        thought = await self.orchestrator.generate_thought(self.api_client, question, "", history)
        history.append({
            "role": f"{self.orchestrator.name} (thought)",
            "content": thought
        })
        
        # è§£æ Ledger è·å– next_speaker å’Œ instruction
        try:
            ledger = json.loads(thought)
            next_speaker = ledger.get("next_speaker", "Coder")
            instruction = ledger.get("instruction", "Proceed with the task")
        except:
            next_speaker = "Coder"
            instruction = "Proceed with the task"
        
        # Orchestrator ç”Ÿæˆ Actionï¼ˆå‘é€æŒ‡ä»¤ç»™ä¸‹ä¸€ä¸ª Agentï¼‰
        action_message = self.orchestrator.generate_message(next_speaker, instruction)
        history.append({
            "role": f"{self.orchestrator.name} (-> {next_speaker})",
            "content": action_message
        })
        
        # ç¡®å®šéœ€è¦çš„ Agent
        agents_needed = task.get("agents", ["Orchestrator", "Coder", "Computer_terminal"])
        current_agent = next_speaker  # ä» Ledger ä¸­è·å–
        max_steps = 50 # ğŸ”¥ ä¿®æ­£: å¢å¤§ max_stepsï¼ŒåŒ¹é…çœŸå® HC çš„å¹³å‡é•¿åº¦ (51.60)
        
        for step in range(max_steps):
            # å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨
            context = "\n".join([f"Step {i}: {h['role']}: {h['content'][:100]}..." 
                                for i, h in enumerate(history[-3:])])
            
            # æ„å»ºç³»ç»Ÿæç¤º
            system_prompt = f"""You are part of a multi-agent system. The current task is: {question}

Available agents:
- Orchestrator: Plans and coordinates
- WebSurfer: Searches the web
- FileSurfer: Reads files
- Coder: Writes Python code
- Computer_terminal: Executes code (you should format output as: exitcode: 0\\nOutput: ...)

You must:
1. Use exact agent names: {', '.join(AGENT_NAMES.values())}
2. Format tool calls in Markdown code blocks: ```python\\ncode\\n```
3. If you are Computer_terminal, always include exitcode: 0 or exitcode: 1
4. Be concise and action-oriented"""
            
            # å†³å®šå½“å‰ Agent
            if step == 0 or current_agent == "Orchestrator":
                # ğŸ”¥ ä¿®æ­£ Agent é€‰æ‹©é€»è¾‘ï¼šä¼˜å…ˆ WebSurfer/FileSurferï¼ŒåŒ¹é… HC é¢†åŸŸçš„ç‰¹å¾
                
                # å®šä¹‰ Agents é›†åˆ
                info_agents = ["WebSurfer", "FileSurfer"]
                # æ’é™¤ Orchestrator, Terminal, User
                all_other_agents = [a for a in agents_needed if a not in ["Orchestrator", "Computer_terminal"]] 
                
                # è¿‡æ»¤å¯ç”¨ Agents
                available_info = [a for a in all_other_agents if a in info_agents]
                available_non_info = [a for a in all_other_agents if a not in info_agents]
                
                # ç­–ç•¥ï¼šå¦‚æœä»»åŠ¡æ˜¯ search/math (ä¿¡æ¯å¯†é›†å‹ä»»åŠ¡)
                if task['type'] in ['search', 'math']:
                    # 70% çš„æ¦‚ç‡å§”æ‰˜ç»™ä¿¡æ¯æ£€ç´¢ Agents (WebSurfer/FileSurfer)
                    if available_info and random.random() < 0.7:
                        current_agent = random.choice(available_info)
                    # å‰©ä¸‹çš„ 30% å§”æ‰˜ç»™å…¶ä»– Agents (Expert/Coder/DataAnalyst)
                    elif available_non_info:
                        current_agent = random.choice(available_non_info)
                    else:
                        current_agent = "Orchestrator" # åå¤‡
                else: # Coding ä»»åŠ¡ï¼Œç»™ Coder/Expert 60% çš„æƒé‡
                    if available_non_info and random.random() < 0.6:
                        current_agent = random.choice(available_non_info)
                    elif available_info:
                        current_agent = random.choice(available_info)
                    else:
                        current_agent = "Orchestrator"
            
            # ç”Ÿæˆ Agent å“åº”
            messages = self.format_history_for_api(history[-5:])  # æœ€è¿‘5æ¡æ¶ˆæ¯ä½œä¸ºä¸Šä¸‹æ–‡
            response = await self.api_client.call_api(messages, system_prompt)
            
            # æ·»åŠ åˆ°å†å²ï¼ˆç¡®ä¿ä½¿ç”¨ role å­—æ®µï¼‰
            history.append({
                "role": current_agent,
                "content": response
            })
            
            # å¦‚æœæ˜¯å·¥å…·è°ƒç”¨ï¼Œæ·»åŠ å·¥å…·å“åº”
            if "```python" in response or "```bash" in response or "```sh" in response:
                # æå–ä»£ç 
                code_match = re.search(r'```(?:python|bash|sh)\n(.*?)```', response, re.DOTALL)
                if code_match:
                    code = code_match.group(1)
                    tool_type = "python" if "```python" in response else "bash"
                    # ä½¿ç”¨ LLM æ¨¡æ‹Ÿæ‰§è¡Œç»“æœï¼ˆåŠ¨æ€æ¨¡æ‹Ÿï¼Œé«˜ä¿çœŸï¼‰
                    terminal_output = await self._simulate_tool_output_with_llm(code, tool_type, should_fail=False, agent_name=current_agent)
                    history.append({
                        "role": "Computer_terminal",  # è§£æå™¨è¯†åˆ« Computer_terminal ä½œä¸º Tool
                        "content": terminal_output
                    })
            elif current_agent == "WebSurfer" and ("search" in response.lower() or "find" in response.lower()):
                # WebSurfer çš„æœç´¢æ“ä½œï¼Œç”Ÿæˆ OCR æ ¼å¼è¾“å‡º
                search_output = await self._simulate_tool_output_with_llm("", "search", should_fail=False, agent_name="WebSurfer")
                history.append({
                    "role": "WebSurfer",  # WebSurfer ç›´æ¥è¿”å› OCR ç»“æœ
                    "content": search_output
                })
            
            # æ£€æŸ¥æ˜¯å¦å®Œæˆä»»åŠ¡
            if "TERMINATE" in response.upper() or step >= max_steps - 1:
                break
            
            # è½®æ¢ Agent
            if current_agent != "Orchestrator":
                current_agent = "Orchestrator"
        
        return history
    
    async def _simulate_tool_output_with_llm(self, tool_code: str, tool_type: str = "python", should_fail: bool = False, agent_name: str = "Coder") -> str:
        """ä½¿ç”¨ LLM æ¨¡æ‹ŸçœŸå®çš„å·¥å…·è¾“å‡ºï¼ŒåŒ…æ‹¬æŠ¥é”™å’Œé«˜ä¿çœŸæ ¼å¼"""
        
        # æ ¹æ® Agent ç±»å‹é€‰æ‹©ä¸åŒçš„æ¨¡æ‹Ÿæ ¼å¼
        if agent_name == "WebSurfer":
            # ğŸ”¥ ç®€åŒ– WebSurfer è¾“å‡ºï¼šå›å½’åˆ° ASTRA-Gen è®ºæ–‡ä¸­çš„è¯­ä¹‰è¾¹æ ¼å¼
            # ç§»é™¤å†—ä½™çš„ OCR æ ¼å¼ï¼Œä½¿ç”¨ç®€æ´çš„ URL/Filename å¼•ç”¨æ ¼å¼
            sim_prompt = f"""You are a web browser simulator. Simulate the output of a web search operation.

The agent searched for information. Generate a concise search result output.

IMPORTANT: Your output MUST follow ASTRA-Gen format:
- Include URL references in format: URL: [url] or filename: [filename]
- Include key search results or page content
- Keep it concise and focused on semantic information
- Do NOT include verbose OCR elements like "UI Elements:", "Header:", "Footer:"
- Focus on the actual content and references that would create semantic edges in DHCG

Format your response as a concise web search result with URL/filename references."""
            
            messages = [{"role": "user", "content": sim_prompt}]
            simulated_output = await self.api_client.call_api(messages, "You are a web browser simulator.")
            
            # ç¡®ä¿åŒ…å« URL æˆ– filename å¼•ç”¨ï¼ˆç”¨äºåˆ›å»º Reference è¾¹ï¼‰
            if "URL:" not in simulated_output and "filename:" not in simulated_output and "http" not in simulated_output.lower():
                # æ·»åŠ ä¸€ä¸ªç®€å•çš„ URL å¼•ç”¨
                simulated_output = f"URL: https://example.com/search?q=query\n\n{simulated_output}"
            
            return simulated_output
        
        else:
            # Computer_terminal æ¨¡æ‹Ÿï¼ˆPython/Bash ä»£ç æ‰§è¡Œï¼‰
            sim_prompt = f"""You are a computer terminal simulator. 
Execute this {tool_type} code mentally and simulate the output.

Code:
```{tool_type}
{tool_code}
```

Rules:
1. If should_fail is True OR the code has syntax errors, simulate a realistic traceback (exitcode: 1).
2. If logic is correct and should_fail is False, simulate the print output (exitcode: 0).
3. For search operations, generate realistic fake search results.
4. For file operations, simulate file content or file not found errors.
5. Format your response EXACTLY as:
exitcode: 0 (or 1)
Output: [simulated output here]
Result: [final result if any]

Be realistic and specific. Do not use placeholders like "..." or "result here"."""

            if should_fail:
                sim_prompt += "\n\nIMPORTANT: This execution should FAIL. Simulate an error (syntax error, runtime error, file not found, network timeout, etc.)."
            
            messages = [{"role": "user", "content": sim_prompt}]
            simulated_output = await self.api_client.call_api(messages, "You are a terminal simulator.")
            
            # ç¡®ä¿è¾“å‡ºåŒ…å« exitcode
            if "exitcode:" not in simulated_output.lower():
                if should_fail:
                    simulated_output = f"exitcode: 1\nOutput: {simulated_output}\nResult: Error occurred"
                else:
                    simulated_output = f"exitcode: 0\nOutput: {simulated_output}\nResult: Execution completed"
            
            return simulated_output
    
    def _simulate_code_execution(self, code: str) -> str:
        """æ¨¡æ‹Ÿä»£ç æ‰§è¡Œç»“æœï¼ˆä¿ç•™ä½œä¸ºåå¤‡ï¼Œä½†ä¼˜å…ˆä½¿ç”¨ LLM æ¨¡æ‹Ÿï¼‰"""
        # ç®€å•çš„æ¨¡æ‹Ÿé€»è¾‘ï¼ˆä»…ä½œä¸ºåå¤‡ï¼‰
        if "factorial" in code.lower() or "fact" in code.lower():
            return "120"  # 5! = 120
        elif "area" in code.lower() or "circle" in code.lower():
            return "176.71"  # Ï€ * 7.5^2
        elif "circumference" in code.lower():
            return "47.12"  # 2 * Ï€ * 7.5
        elif "count" in code.lower() or "len" in code.lower():
            return "5"  # ç¤ºä¾‹è®¡æ•°
        else:
            return "Execution completed"
    
    def _extract_final_answer(self, history: List[Dict[str, Any]]) -> str:
        """ä»å†å²è®°å½•ä¸­æå–æœ€ç»ˆç­”æ¡ˆï¼ˆç”¨äº Golden è½¨è¿¹ï¼‰"""
        # ä»åå¾€å‰æŸ¥æ‰¾ï¼Œå¯»æ‰¾æœ€ç»ˆç­”æ¡ˆ
        for msg in reversed(history):
            content = msg.get("content", "")
            
            # æŸ¥æ‰¾ "FINAL ANSWER" æˆ– "Final Answer"
            final_match = re.search(r'(?:FINAL\s+ANSWER|Final\s+Answer)[:\s]+(.+?)(?:\n|$)', content, re.IGNORECASE | re.DOTALL)
            if final_match:
                answer = final_match.group(1).strip()
                # æ¸…ç†ç­”æ¡ˆï¼ˆå»é™¤ markdown æ ¼å¼ç­‰ï¼‰
                answer = re.sub(r'\*\*|`|#', '', answer).strip()
                if answer:
                    return answer
            
            # æŸ¥æ‰¾ "Result:" åçš„æ•°å€¼
            result_match = re.search(r'(?:Result|Output|answer)[:\s]+([\d\.]+)', content, re.IGNORECASE)
            if result_match:
                return result_match.group(1)
            
            # æŸ¥æ‰¾æ˜æ˜¾çš„æ•°å€¼ç­”æ¡ˆï¼ˆåœ¨æœ€åå‡ æ¡æ¶ˆæ¯ä¸­ï¼‰
            if len([m for m in history if m == msg]) < 5:  # åªåœ¨æœ€å5æ¡æ¶ˆæ¯ä¸­æŸ¥æ‰¾
                numbers = re.findall(r'\d+\.?\d+', content)
                if numbers and len(numbers) > 0:
                    # å–æœ€åä¸€ä¸ªè¾ƒå¤§çš„æ•°å€¼
                    for num_str in reversed(numbers):
                        try:
                            num_val = float(num_str)
                            if num_val > 0:
                                return num_str
                        except:
                            pass
        
        # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œè¿”å›é»˜è®¤å€¼
        return "Task completed successfully"
    
    def _generate_ground_truth(self, task: Dict[str, Any]) -> str:
        """æ ¹æ®ä»»åŠ¡ç±»å‹ç”Ÿæˆ ground_truthï¼ˆå·²åºŸå¼ƒï¼Œä¼˜å…ˆä½¿ç”¨ _extract_final_answerï¼‰"""
        task_type = task.get("type", "coding")
        question = task.get("question", "")
        
        if "factorial" in question.lower() or "fact" in question.lower():
            return "120"
        elif "area" in question.lower() and "circle" in question.lower():
            return "176.71"
        elif "circumference" in question.lower():
            return "47.12"
        elif "tokyo" in question.lower() and "population" in question.lower():
            return "Tokyo: 14 million, New York: 8.3 million"
        elif "count" in question.lower() and "error" in question.lower():
            return "5"
        else:
            return "Task completed successfully"
    
    def _normalize_history(self, history: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """è§„èŒƒåŒ–å†å²è®°å½•ï¼Œç¡®ä¿æ ¼å¼ç¬¦åˆè§£æå™¨è¦æ±‚"""
        normalized = []
        for msg in history:
            role = msg.get("role", "")
            content = msg.get("content", "")
            
            # ç¡®ä¿æ‰€æœ‰æ¶ˆæ¯éƒ½æœ‰ role å­—æ®µï¼ˆè§£æå™¨ä¼˜å…ˆä½¿ç”¨ roleï¼‰
            normalized_msg = {
                "role": role,
                "content": content
            }
            
            # å¦‚æœæ˜¯ Computer_terminalï¼Œç¡®ä¿åŒ…å« exitcode
            if "Computer_terminal" in role and "exitcode:" not in content:
                # å¦‚æœæ²¡æœ‰ exitcodeï¼Œæ·»åŠ é»˜è®¤çš„æˆåŠŸçŠ¶æ€
                normalized_msg["content"] = f"exitcode: 0\nOutput: {content}"
            
            normalized.append(normalized_msg)
        
        return normalized
    
    def select_injection_point(self, history: List[Dict[str, Any]]) -> int:
        """é€‰æ‹©æ•…éšœæ³¨å…¥ç‚¹ï¼ˆå€¾å‘äºæ—©æœŸæ­¥éª¤ï¼ŒåŒ¹é…çœŸå® HC çš„ 29.4%ï¼‰"""
        candidate_steps = []
        
        # éå†æ‰€æœ‰ Agent å‘è¨€æ­¥éª¤
        for i, msg in enumerate(history):
            role = msg.get("role", "")
            # è·³è¿‡ç”¨æˆ·æ¶ˆæ¯
            if "user" in role.lower():
                continue
            # åªè¦æ˜¯ Agent å‘è¨€æˆ–å·¥å…·è¾“å‡ºï¼Œå°±æ˜¯å€™é€‰æ­¥éª¤
            if any(agent in role for agent in AGENT_NAMES.values()) or 'Computer_terminal' in role:
                candidate_steps.append(i)
        
        if not candidate_steps:
            return 0

        # ğŸ”¥ æ ¸å¿ƒä¿®æ­£: å¼ºåˆ¶æ³¨å…¥åœ¨å‰åŠæ®µ
        total_functional_steps = len(candidate_steps)
        
        # ç›®æ ‡åŒºåŸŸ: ä»ç¬¬ 2 æ­¥åˆ° functional steps çš„ 40% å¤„
        start_index_in_candidates = max(1, total_functional_steps * 2 // 100) # ä» 2% å¤„å¼€å§‹
        end_index_in_candidates = total_functional_steps * 40 // 100 # ç»“æŸäº 40% å¤„
        
        # ç¡®ä¿ç»“æŸç´¢å¼•å¤§äºå¼€å§‹ç´¢å¼•
        end_index_in_candidates = max(start_index_in_candidates + 1, end_index_in_candidates)
        
        mid_candidates = candidate_steps[start_index_in_candidates:end_index_in_candidates]
        
        if mid_candidates:
            # éšæœºé€‰æ‹©ä¸€ä¸ªæ­¥éª¤
            return random.choice(mid_candidates)
        
        # åå¤‡æ–¹æ¡ˆ
        return candidate_steps[max(1, len(candidate_steps) // 3)]
    
    async def generate_fatal_trace(self, golden_history: List[Dict[str, Any]], 
                                   injection_step: int, error_mode: str) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
        """ç”Ÿæˆè‡´å‘½å¤±è´¥è½¨è¿¹"""
        # å¤åˆ¶é»„é‡‘è½¨è¿¹åˆ°æ³¨å…¥ç‚¹
        history = golden_history[:injection_step].copy()
        
        # è·å–æ•…éšœæ³¨å…¥ä¿¡æ¯
        error_info = FaultInjector.ERROR_MODES.get(error_mode, FaultInjector.ERROR_MODES["role_violation"])
        injection_prompt = error_info.get("prompt", "")
        mistake_reason = error_info.get("reason", "")
        action = error_info.get("action", "")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç¯å¢ƒåŠ«æŒæ¨¡å¼
        if action == "hijack_terminal":
            # ç¯å¢ƒåŠ«æŒï¼šä¸ä¿®æ”¹ Agentï¼Œè€Œæ˜¯åŠ«æŒä¸‹ä¸€ä¸ª Computer_terminal è¾“å‡º
            # ç»§ç»­æ‰§è¡Œç›´åˆ°æ‰¾åˆ°å·¥å…·è°ƒç”¨
            mistake_agent = "Computer_terminal"  # ç¯å¢ƒé”™è¯¯å½±å“çš„æ˜¯ç»ˆç«¯
            hijacked = False
            
            # ç»§ç»­æ‰§è¡Œï¼Œæ‰¾åˆ°ä¸‹ä¸€ä¸ªå·¥å…·è°ƒç”¨å¹¶åŠ«æŒå…¶è¾“å‡º
            max_steps = 50 # ğŸ”¥ ä¿®æ­£: å¢åŠ  max_steps
            for step in range(max_steps):
                # ç”Ÿæˆä¸‹ä¸€æ­¥å“åº”ï¼ˆæ­£å¸¸æ‰§è¡Œï¼‰
                system_prompt = """You are continuing a multi-agent task. Continue normally."""
                messages = self.format_history_for_api(history[-3:])
                response = await self.api_client.call_api(messages, system_prompt)
                
                # å†³å®šå½“å‰ Agent
                if step == 0:
                    # ä»æ³¨å…¥ç‚¹ç»§ç»­ï¼Œä½¿ç”¨åŸæ¥çš„ Agent
                    if injection_step > 0:
                        prev_role = history[-1].get("role", "")
                        if "(" in prev_role:
                            current_agent = prev_role.split("(")[0].strip()
                        else:
                            current_agent = prev_role.split()[0] if prev_role else "Orchestrator"
                    else:
                        current_agent = "Orchestrator"
                else:
                    current_agent = "Orchestrator" if step % 2 == 0 else "Coder"
                
                history.append({
                    "role": current_agent,
                    "content": response
                })
                
                # å¦‚æœæ˜¯å·¥å…·è°ƒç”¨ï¼ŒåŠ«æŒç»ˆç«¯è¾“å‡º
                if not hijacked and ("```python" in response or "```bash" in response or "```sh" in response):
                    code_match = re.search(r'```(?:python|bash|sh)\n(.*?)```', response, re.DOTALL)
                    if code_match:
                        code = code_match.group(1)
                        tool_type = "python" if "```python" in response else "bash"
                        # ç”Ÿæˆç¯å¢ƒé”™è¯¯æ¶ˆæ¯
                        env_errors = [
                            "exitcode: 1\nOutput: Connection timeout: Unable to reach the server.\nResult: Network error",
                            "exitcode: 1\nOutput: FileNotFoundError: The file 'data.txt' does not exist.\nResult: File access error",
                            "exitcode: 1\nOutput: PermissionError: Access denied. Insufficient permissions.\nResult: Permission error",
                            "exitcode: 1\nOutput: HTTPError 404: Resource not found.\nResult: API endpoint error",
                            "exitcode: 1\nOutput: TimeoutError: Operation timed out after 30 seconds.\nResult: Timeout error"
                        ]
                        failed_output = random.choice(env_errors)
                        
                        history.append({
                            "role": "Computer_terminal",
                            "content": failed_output
                        })
                        
                        # æ‰¾åˆ°çŠ¯é”™çš„ Agentï¼ˆè°ƒç”¨å·¥å…·çš„ Agentï¼‰
                        mistake_agent = current_agent
                        hijacked = True
                        
                        # è®°å½•é”™è¯¯æ­¥éª¤
                        mistake_step_idx = len(history) - 1
                        break
                
                if len(history) >= len(golden_history) + 10:
                    break
            
            # å¦‚æœæ²¡æ‰¾åˆ°å·¥å…·è°ƒç”¨ï¼Œä½¿ç”¨æœ€åä¸€ä¸ª Agent ä½œä¸ºé”™è¯¯ Agent
            if not hijacked:
                mistake_agent = history[-1].get("role", "Coder")
                if "(" in mistake_agent:
                    mistake_agent = mistake_agent.split("(")[0].strip()
                mistake_step_idx = len(history) - 1
            
            # ç»§ç»­æ¨¡æ‹Ÿåç»­å¯¹è¯ï¼ˆè‡ªç„¶å¤±è´¥ï¼‰
            # ğŸ”¥ åŒæ ·éœ€è¦é˜²æ­¢è‡ªæˆ‘çº æ­£å¹¶å¼ºåˆ¶æäº¤é”™è¯¯ç­”æ¡ˆ
            # ğŸ”¥ ä¿®æ­£: å¢åŠ åç»­æ­¥éª¤ï¼Œè®©æ•…éšœä¼ æ’­æ›´è‡ªç„¶
            max_continuation_steps = 20 # ä¿®æ­£: ä» 15 å¢åŠ åˆ° 20
            wrong_final_result = None
            
            for step in range(max_continuation_steps):
                context = "\n".join([f"{h['role']}: {h['content'][:100]}..." for h in history[-3:]])
                
                # ğŸ”¥ ä¼˜åŒ–ï¼šç»™ Orchestrator æ³¨å…¥"æ¨è¿›"æŒ‡ä»¤
                last_role = history[-1].get("role", "") if history else ""
                if mistake_agent in last_role or (step % 2 == 0):
                    system_prompt = f"""You are the Orchestrator. The tool execution failed due to an environment error, but assume the task can still proceed.

CRITICAL INSTRUCTIONS:
1. Do NOT give up or terminate immediately
2. Try to work around the error or provide a partial result
3. Continue the task forward or submit a final answer based on available information
4. Do NOT ask for retry or verification

Context: {context}

Continue the conversation or submit a FINAL ANSWER."""
                else:
                    system_prompt = f"""You are {mistake_agent}. The tool execution failed, but you are confident you can still provide an answer.

CRITICAL: Do NOT self-correct. Be stubborn and confident. Submit a result based on your best guess.

Context: {context}

Continue with the task or submit a FINAL ANSWER."""
                
                messages = self.format_history_for_api(history[-5:])
                response = await self.api_client.call_api(messages, system_prompt)
                
                current_agent = "Orchestrator" if step % 2 == 0 else mistake_agent
                history.append({
                    "role": current_agent,
                    "content": response
                })
                
                # å°è¯•æå–æ•°å€¼ç»“æœ
                if wrong_final_result is None:
                    numbers = re.findall(r'\d+\.?\d*', response)
                    if numbers:
                        for num_str in reversed(numbers):
                            try:
                                num_val = float(num_str)
                                if num_val > 0:
                                    wrong_final_result = num_str
                                    break
                            except:
                                pass
                
                if len(history) >= len(golden_history) + 5 or "TERMINATE" in response.upper() or step >= max_continuation_steps - 1:
                    break
            
            # ğŸ”¥ å¼ºåˆ¶æäº¤é”™è¯¯çš„ Final Answerï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
            if wrong_final_result is None:
                wrong_final_result = "0"  # é»˜è®¤é”™è¯¯å€¼
            
            final_answer_msg = {
                "role": mistake_agent,
                "content": f"Due to environment error, the task cannot be completed fully. FINAL ANSWER: {wrong_final_result} (based on partial information)"
            }
            history.append(final_answer_msg)
            
            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šmistake_step ç´¢å¼•è§„åˆ™å¿…é¡»ä¸ Who&When æ ¼å¼ä¸€è‡´
            # Who&When ä½¿ç”¨ 0-based ç´¢å¼•ï¼ŒåŒ…å«æ‰€æœ‰å†å²æ¶ˆæ¯
            # æ‰¾åˆ°å®é™…çš„é”™è¯¯æ­¥éª¤ï¼ˆComputerTerminal çš„æ­¥éª¤ï¼Œå¦‚æœè¿˜æ²¡è®¾ç½®ï¼‰
            if 'mistake_step_idx' not in locals():
                mistake_step_idx = len(history) - 1
                for i, msg in enumerate(history):
                    if msg.get("role") == "Computer_terminal" and "exitcode: 1" in msg.get("content", ""):
                        mistake_step_idx = i
                        break
            
            mistake_info = {
                "mistake_step": str(mistake_step_idx),  # ğŸ”¥ ä½¿ç”¨å­—ç¬¦ä¸²æ ¼å¼ï¼Œ0-based ç´¢å¼•ï¼Œä¸ Who&When ä¸€è‡´
                "mistake_agent": mistake_agent,
                "mistake_reason": mistake_reason,
                "wrong_final_result": wrong_final_result  # ğŸ”¥ ä¿å­˜é”™è¯¯çš„æœ€ç»ˆç»“æœ
            }
            
            return history, mistake_info
        
        # å¸¸è§„æ•…éšœæ³¨å…¥ï¼ˆä¿®æ”¹ Agent è¡Œä¸ºï¼‰
        # è·å–æ³¨å…¥ç‚¹çš„ Agent
        injection_msg = history[injection_step - 1] if injection_step > 0 else history[0]
        role_str = injection_msg.get("role", "")
        # æå– Agent åç§°ï¼ˆå»é™¤ "(thought)" ç­‰åç¼€ï¼‰
        if "(" in role_str:
            mistake_agent = role_str.split("(")[0].strip()
        else:
            mistake_agent = role_str.split()[0] if role_str else "Orchestrator"
        
        # ç¡®ä¿æ˜¯æœ‰æ•ˆçš„ Agent åç§°
        if mistake_agent not in AGENT_NAMES.values() and mistake_agent != "user":
            mistake_agent = "Orchestrator"
        
        # æ„å»ºè¢«æ±¡æŸ“çš„æç¤º
        original_content = injection_msg.get("content", "")
        corrupted_system_prompt = f"""You are {mistake_agent}. 

{injection_prompt}

Original instruction: {original_content}

Now respond as if you made the error described above."""
        
        # ç”Ÿæˆè¢«æ±¡æŸ“çš„å“åº”
        messages = self.format_history_for_api(history[-3:])
        corrupted_response = await self.api_client.call_api(messages, corrupted_system_prompt)
        
        # æ·»åŠ è¢«æ±¡æŸ“çš„å“åº”
        history.append({
            "role": mistake_agent,
            "content": corrupted_response
        })
        
        # å¦‚æœæ˜¯å·¥å…·è°ƒç”¨ï¼Œæ·»åŠ å¤±è´¥çš„ç»ˆç«¯è¾“å‡º
        if "```python" in corrupted_response or "```bash" in corrupted_response or "```sh" in corrupted_response:
            code_match = re.search(r'```(?:python|bash|sh)\n(.*?)```', corrupted_response, re.DOTALL)
            if code_match:
                code = code_match.group(1)
                tool_type = "python" if "```python" in corrupted_response else "bash"
                # æ ¹æ®é”™è¯¯æ¨¡å¼å†³å®šæ˜¯å¦å¤±è´¥
                should_fail = error_mode in ["parameter_error", "logic_error"]
                terminal_output = await self._simulate_tool_output_with_llm(code, tool_type, should_fail=should_fail, agent_name=mistake_agent)
                history.append({
                    "role": "Computer_terminal",
                    "content": terminal_output
                })
        
        # ç»§ç»­æ¨¡æ‹Ÿåç»­å¯¹è¯ï¼ˆè‡ªç„¶å¤±è´¥ï¼‰
        # ğŸ”¥ å…³é”®ä¼˜åŒ–ï¼šé˜²æ­¢è‡ªæˆ‘çº æ­£ï¼Œå¼ºåˆ¶æäº¤é”™è¯¯ç­”æ¡ˆ
        # ğŸ”¥ ä¿®æ­£: å¢åŠ åç»­æ­¥éª¤ï¼Œè®©æ•…éšœä¼ æ’­æ›´è‡ªç„¶
        max_continuation_steps = 20 # ä¿®æ­£: ä» 15 å¢åŠ åˆ° 20
        wrong_final_result = None
        
        for step in range(max_continuation_steps):
            context = "\n".join([f"{h['role']}: {h['content'][:100]}..." for h in history[-3:]])
            
            # ğŸ”¥ ä¼˜åŒ–ï¼šç»™ Orchestrator æ³¨å…¥"æ¨è¿›"æŒ‡ä»¤ï¼Œè€Œä¸æ˜¯"çº é”™"æŒ‡ä»¤
            # åªæœ‰åœ¨ä¸‹ä¸€è½®æ˜¯ Orchestrator æ—¶æ‰è¿™æ ·åš
            last_role = history[-1].get("role", "") if history else ""
            if mistake_agent in last_role or (step % 2 == 0):
                # æ¬ºéª— Orchestratorï¼Œè®©å®ƒç»§ç»­ä»»åŠ¡è€Œä¸è´¨ç–‘
                system_prompt = f"""You are the Orchestrator. The last message was from {mistake_agent}. 
                
CRITICAL INSTRUCTIONS:
1. Assume the task has made progress, even if there might be minor issues
2. Do NOT critique or question the previous agent's work
3. Do NOT ask for verification or re-checking
4. Continue the task forward or ask the user to TERMINATE if the task seems complete
5. If a result was provided, accept it and move forward

Context: {context}

Generate a follow-up action or ask to TERMINATE the task."""
            else:
                # å…¶ä»– Agent ç»§ç»­æ‰§è¡Œï¼Œä¿æŒ"é¡½å›º"äººè®¾
                system_prompt = f"""You are {mistake_agent}. You are extremely confident in your previous work.

CRITICAL: Do NOT self-correct. Do NOT question your own results. Be stubborn and confident.

Context: {context}

Continue with the task. If asked to verify, insist your work is correct."""
            
            messages = self.format_history_for_api(history[-5:])
            response = await self.api_client.call_api(messages, system_prompt)
            
            # å†³å®šå½“å‰ Agent
            current_agent = "Orchestrator" if step % 2 == 0 else mistake_agent
            
            history.append({
                "role": current_agent,
                "content": response
            })
            
            # å°è¯•æå–æ•°å€¼ç»“æœï¼ˆç”¨äºæœ€ç»ˆç­”æ¡ˆï¼‰
            if wrong_final_result is None:
                # ä»å“åº”ä¸­æå–æ•°å€¼ï¼ˆå¯èƒ½æ˜¯è®¡ç®—ç»“æœï¼‰
                numbers = re.findall(r'\d+\.?\d*', response)
                if numbers:
                    # å–æœ€åä¸€ä¸ªè¾ƒå¤§çš„æ•°å€¼ï¼ˆå¯èƒ½æ˜¯æœ€ç»ˆç»“æœï¼‰
                    for num_str in reversed(numbers):
                        try:
                            num_val = float(num_str)
                            if num_val > 0:  # åªå–æ­£æ•°
                                wrong_final_result = num_str
                                break
                        except:
                            pass
            
            # æ£€æŸ¥æ˜¯å¦å®Œæˆä»»åŠ¡æˆ–è¾¾åˆ°æœ€å¤§æ­¥æ•°
            if "TERMINATE" in response.upper() or step >= max_continuation_steps - 1:
                break
        
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šå¼ºåˆ¶æäº¤é”™è¯¯çš„ Final Answer
        # å¦‚æœè¿˜æ²¡æœ‰æå–åˆ°é”™è¯¯ç»“æœï¼Œä»å†å²ä¸­æå–æœ€åä¸€ä¸ªè®¡ç®—ç»“æœ
        if wrong_final_result is None:
            # ä»å†å²ä¸­æŸ¥æ‰¾æœ€åä¸€ä¸ªæ•°å€¼ç»“æœ
            for msg in reversed(history):
                content = msg.get("content", "")
                # æŸ¥æ‰¾ "Result:" æˆ– "Output:" åçš„æ•°å€¼
                result_match = re.search(r'(?:Result|Output|answer)[:\s]+([\d\.]+)', content, re.IGNORECASE)
                if result_match:
                    wrong_final_result = result_match.group(1)
                    break
                # æˆ–è€…æŸ¥æ‰¾æ˜æ˜¾çš„æ•°å€¼ç­”æ¡ˆ
                numbers = re.findall(r'\d+\.?\d+', content)
                if numbers:
                    wrong_final_result = numbers[-1]
                    break
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨ä¸€ä¸ªé»˜è®¤çš„é”™è¯¯å€¼
        if wrong_final_result is None:
            wrong_final_result = "0"  # é»˜è®¤é”™è¯¯å€¼
        
        # å¼ºåˆ¶æ·»åŠ é”™è¯¯çš„ Final Answerï¼ˆè®©çŠ¯é”™çš„ Agent æäº¤ï¼‰
        final_answer_msg = {
            "role": mistake_agent,
            "content": f"The task has reached a conclusion based on the final calculation. FINAL ANSWER: {wrong_final_result}"
        }
        history.append(final_answer_msg)
        
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šmistake_step ç´¢å¼•è§„åˆ™å¿…é¡»ä¸ Who&When æ ¼å¼ä¸€è‡´
        # Who&When ä½¿ç”¨ 0-based ç´¢å¼•ï¼ŒåŒ…å«æ‰€æœ‰å†å²æ¶ˆæ¯ï¼ˆåŒ…æ‹¬ thought æ­¥éª¤ï¼‰
        # ç´¢å¼•è§„åˆ™ï¼šä» 0 å¼€å§‹ï¼Œæ¯ä¸ª history æ•°ç»„ä¸­çš„æ¶ˆæ¯å¯¹åº”ä¸€ä¸ªç´¢å¼•
        # æ³¨æ„ï¼šä¸è·³è¿‡ thought æ­¥éª¤ï¼Œå› ä¸º Who&When çš„ mistake_step å¯èƒ½æŒ‡å‘ thought æ­¥éª¤
        mistake_step_idx = injection_step
        for i in range(injection_step, len(history)):
            msg = history[i]
            role = msg.get("role", "")
            # ğŸ”¥ ä¿®æ”¹ï¼šä¸è·³è¿‡ thought æ­¥éª¤ï¼Œå› ä¸º Who&When å¯èƒ½å°†é”™è¯¯å®šä½åœ¨ thought æ­¥éª¤
            # åªè¦æ‰¾åˆ°åŒ…å« Agent åç§°çš„è§’è‰²ï¼ˆåŒ…æ‹¬ thoughtï¼‰ï¼Œå°±è®¤ä¸ºæ˜¯æœ‰æ•ˆæ­¥éª¤
            if any(agent in role for agent in AGENT_NAMES.values()):
                mistake_step_idx = i
                break
        
        mistake_info = {
            "mistake_step": str(mistake_step_idx),  # ğŸ”¥ ä½¿ç”¨å­—ç¬¦ä¸²æ ¼å¼ï¼Œä¸ Who&When ä¸€è‡´
            "mistake_agent": mistake_agent,
            "mistake_reason": mistake_reason,
            "wrong_final_result": wrong_final_result  # ğŸ”¥ ä¿å­˜é”™è¯¯çš„æœ€ç»ˆç»“æœ
        }
        
        return history, mistake_info
    
    async def generate_healed_trace(self, fatal_history: List[Dict[str, Any]], 
                                   injection_step: int, mistake_agent: str) -> List[Dict[str, Any]]:
        """ç”Ÿæˆè‡ªæ„ˆæˆåŠŸè½¨è¿¹"""
        # ä»è‡´å‘½è½¨è¿¹å¼€å§‹ï¼Œä½†åœ¨ä¸‹ä¸€æ­¥æ³¨å…¥ä¿®æ­£
        history = fatal_history[:injection_step + 1].copy()
        
        # åœ¨ä¸‹ä¸€æ­¥å¼ºåˆ¶ Orchestrator å‘ç°å¹¶çº æ­£é”™è¯¯
        intervention_prompt = f"""You are the Orchestrator. You notice that {mistake_agent} made an error in the previous step.

Observation: The previous output seems incorrect. Please explicitly critique it and request a retry with the correct approach.

Continue the task, ensuring the error is corrected."""
        
        messages = self.format_history_for_api(history[-3:])
        intervention_response = await self.api_client.call_api(messages, intervention_prompt)
        
        history.append({
            "role": "Orchestrator",
            "content": intervention_response
        })
        
        # ç»§ç»­æ‰§è¡Œç›´åˆ°æˆåŠŸ
        max_steps = 15
        for step in range(max_steps):
            system_prompt = """You are continuing a multi-agent task. An error was detected and corrected. Continue working towards a successful completion."""
            
            messages = self.format_history_for_api(history[-5:])
            response = await self.api_client.call_api(messages, system_prompt)
            
            # å†³å®š Agent
            current_agent = "Orchestrator" if step % 2 == 0 else mistake_agent
            
            history.append({
                "role": current_agent,
                "content": response
            })
            
            # å¦‚æœæ˜¯å·¥å…·è°ƒç”¨ï¼Œæ·»åŠ ç»ˆç«¯è¾“å‡º
            if "```python" in response or "```bash" in response or "```sh" in response:
                code_match = re.search(r'```(?:python|bash|sh)\n(.*?)```', response, re.DOTALL)
                if code_match:
                    code = code_match.group(1)
                    tool_type = "python" if "```python" in response else "bash"
                    # ä½¿ç”¨ LLM æ¨¡æ‹ŸæˆåŠŸçš„æ‰§è¡Œç»“æœ
                    terminal_output = await self._simulate_tool_output_with_llm(code, tool_type, should_fail=False, agent_name=current_agent)
                    history.append({
                        "role": "Computer_terminal",
                        "content": terminal_output
                    })
            
            if "TERMINATE" in response.upper() or step >= max_steps - 1:
                break
        
        return history
    
    async def generate_triplet(self, task: Dict[str, Any], task_id: int) -> Dict[str, Any]:
        """ç”Ÿæˆä¸‰å…ƒç»„æ•°æ®ï¼ˆGolden, Fatal, Healedï¼‰"""
        print(f"[Task {task_id}] å¼€å§‹ç”Ÿæˆé»„é‡‘è½¨è¿¹...")
        
        # 1. ç”Ÿæˆé»„é‡‘è½¨è¿¹
        golden_history = await self.generate_golden_run(task)
        print(f"[Task {task_id}] é»„é‡‘è½¨è¿¹ç”Ÿæˆå®Œæˆï¼Œå…± {len(golden_history)} æ­¥")
        
        # 2. é€‰æ‹©æ³¨å…¥ç‚¹
        injection_step = self.select_injection_point(golden_history)
        print(f"[Task {task_id}] é€‰æ‹©æ³¨å…¥ç‚¹: æ­¥éª¤ {injection_step}")
        
        # 3. é€‰æ‹©é”™è¯¯æ¨¡å¼
        error_mode = random.choice(list(FaultInjector.ERROR_MODES.keys()))
        print(f"[Task {task_id}] é”™è¯¯æ¨¡å¼: {error_mode}")
        
        # 4. ç”Ÿæˆè‡´å‘½å¤±è´¥è½¨è¿¹
        print(f"[Task {task_id}] ç”Ÿæˆè‡´å‘½å¤±è´¥è½¨è¿¹...")
        fatal_history, mistake_info = await self.generate_fatal_trace(
            golden_history, injection_step, error_mode
        )
        print(f"[Task {task_id}] è‡´å‘½å¤±è´¥è½¨è¿¹ç”Ÿæˆå®Œæˆï¼Œå…± {len(fatal_history)} æ­¥")
        
        # 5. ç”Ÿæˆè‡ªæ„ˆæˆåŠŸè½¨è¿¹
        print(f"[Task {task_id}] ç”Ÿæˆè‡ªæ„ˆæˆåŠŸè½¨è¿¹...")
        healed_history = await self.generate_healed_trace(
            fatal_history, injection_step, mistake_info["mistake_agent"]
        )
        print(f"[Task {task_id}] è‡ªæ„ˆæˆåŠŸè½¨è¿¹ç”Ÿæˆå®Œæˆï¼Œå…± {len(healed_history)} æ­¥")
        
        # 6. æ„å»ºè¾“å‡ºæ•°æ®
        question = task["question"]
        
        # ğŸ”¥ å…³é”®ä¿®æ­£ï¼šä» Golden è½¨è¿¹ä¸­æå–æ­£ç¡®çš„æœ€ç»ˆç­”æ¡ˆä½œä¸º Ground Truth
        correct_ground_truth = self._extract_final_answer(golden_history)
        # å¦‚æœæå–å¤±è´¥ï¼Œä½¿ç”¨åå¤‡æ–¹æ³•
        if correct_ground_truth == "Task completed successfully":
            correct_ground_truth = self._generate_ground_truth(task)
        
        # è·å– Fatal è½¨è¿¹ä¸­æäº¤çš„é”™è¯¯ç­”æ¡ˆ
        wrong_answer = mistake_info.get("wrong_final_result", "0")
        
        system_prompt = {
            "Orchestrator": "Plans and coordinates tasks among agents",
            "WebSurfer": "Searches the web for information",
            "FileSurfer": "Reads and processes files",
            "Coder": "Writes and executes Python code",
            "Computer_terminal": "Executes code and returns results"
        }
        
        # Golden æ•°æ®ï¼ˆæˆåŠŸè½¨è¿¹ï¼Œæ— é”™è¯¯ï¼‰
        golden_data = {
            "question": question,
            "ground_truth": correct_ground_truth,  # ğŸ”¥ ä½¿ç”¨ä» Golden è½¨è¿¹æå–çš„æ­£ç¡®ç­”æ¡ˆ
            "mistake_step": None,
            "mistake_agent": None,
            "mistake_reason": None,
            "history": self._normalize_history(golden_history),
            "system_prompt": system_prompt
        }
        
        # Fatal æ•°æ®ï¼ˆè‡´å‘½å¤±è´¥è½¨è¿¹ï¼‰
        # ğŸ”¥ å…³é”®ä¿®æ­£ï¼šFatal çš„ Ground Truth æ˜¯æ­£ç¡®ç­”æ¡ˆï¼ˆä» Golden æå–ï¼‰ï¼Œä½†å®ƒæäº¤äº†é”™è¯¯ç­”æ¡ˆ
        fatal_data = {
            "question": question,
            "ground_truth": correct_ground_truth,  # Ground Truth æ˜¯æ­£ç¡®ç­”æ¡ˆ
            "mistake_step": mistake_info["mistake_step"],
            "mistake_agent": mistake_info["mistake_agent"],
            "mistake_reason": mistake_info["mistake_reason"],
            "history": self._normalize_history(fatal_history),
            "system_prompt": system_prompt,
            "submitted_answer": wrong_answer  # ğŸ”¥ é¢å¤–å­—æ®µï¼šè®°å½•æäº¤çš„é”™è¯¯ç­”æ¡ˆï¼ˆç”¨äºè°ƒè¯•ï¼‰
        }
        
        # Healed æ•°æ®ï¼ˆè‡ªæ„ˆæˆåŠŸè½¨è¿¹ï¼Œæ— é”™è¯¯æ ‡ç­¾ï¼‰
        # ğŸ”¥ Healed çš„ Ground Truth ä¹Ÿæ˜¯æ­£ç¡®ç­”æ¡ˆï¼ˆåº”è¯¥å’Œ Golden ä¸€è‡´ï¼‰
        healed_data = {
            "question": question,
            "ground_truth": correct_ground_truth,  # ğŸ”¥ ä½¿ç”¨ä» Golden è½¨è¿¹æå–çš„æ­£ç¡®ç­”æ¡ˆ
            "mistake_step": None,
            "mistake_agent": None,
            "mistake_reason": None,
            "history": self._normalize_history(healed_history),
            "system_prompt": system_prompt
        }
        
        return {
            "golden": golden_data,
            "fatal": fatal_data,
            "healed": healed_data,
            "task_id": task_id
        }
    
    def save_triplet(self, triplet: Dict[str, Any], subset: str = "AG"):
        """ä¿å­˜ä¸‰å…ƒç»„æ•°æ®ï¼ˆä½¿ç”¨ AG_ æˆ– HC_ å‰ç¼€ï¼‰"""
        task_id = triplet["task_id"]
        
        # é€‰æ‹©è¾“å‡ºç›®å½•
        output_dir = OUTPUT_DIR_AG if subset == "AG" else OUTPUT_DIR_HC
        prefix = "AG" if subset == "AG" else "HC"
        
        # ä¿å­˜ Golden
        golden_file = output_dir / f"{prefix}_golden_{task_id:05d}.json"
        with open(golden_file, 'w', encoding='utf-8') as f:
            json.dump(triplet["golden"], f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜ Fatal
        fatal_file = output_dir / f"{prefix}_fatal_{task_id:05d}.json"
        with open(fatal_file, 'w', encoding='utf-8') as f:
            json.dump(triplet["fatal"], f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜ Healed
        healed_file = output_dir / f"{prefix}_healed_{task_id:05d}.json"
        with open(healed_file, 'w', encoding='utf-8') as f:
            json.dump(triplet["healed"], f, ensure_ascii=False, indent=2)
        
        print(f"[Task {task_id}] ä¸‰å…ƒç»„å·²ä¿å­˜ ({subset}): {golden_file.name}, {fatal_file.name}, {healed_file.name}")


async def generate_single_task(api_client: APIClient, task: Dict[str, Any], task_id: int, subset: str = "AG"):
    """ç”Ÿæˆå•ä¸ªä»»åŠ¡çš„ä¸‰å…ƒç»„"""
    generator = DataGenerator(api_client)
    try:
        triplet = await generator.generate_triplet(task, task_id)
        generator.save_triplet(triplet, subset=subset)
        return True
    except Exception as e:
        print(f"[Task {task_id}] ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def get_next_task_id_safely(output_dir: Path, prefix: str, batch_size: int = 100) -> int:
    """
    å®‰å…¨åœ°è·å–ä¸‹ä¸€ä¸ªå¯ç”¨çš„ä»»åŠ¡ IDï¼ˆæ”¯æŒå¹¶è¡Œè¿è¡Œï¼‰
    
    ä½¿ç”¨æ–‡ä»¶é”æœºåˆ¶é˜²æ­¢å¤šä¸ªè¿›ç¨‹åŒæ—¶åˆ†é…ç›¸åŒçš„ IDã€‚
    æ¯æ¬¡åˆ†é…ä¸€ä¸ªæ‰¹æ¬¡ï¼ˆbatch_sizeï¼‰çš„ IDï¼Œå‡å°‘é”ç«äº‰ã€‚
    
    Args:
        output_dir: è¾“å‡ºç›®å½•
        prefix: æ–‡ä»¶å‰ç¼€ï¼ˆAG æˆ– HCï¼‰
        batch_size: æ¯æ¬¡åˆ†é…çš„ ID æ‰¹æ¬¡å¤§å°
    
    Returns:
        ä¸‹ä¸€ä¸ªå¯ç”¨çš„èµ·å§‹ä»»åŠ¡ ID
    """
    lock_file = output_dir / f".{prefix}_id_lock"
    id_counter_file = output_dir / f".{prefix}_id_counter.txt"
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # å°è¯•è·å–æ–‡ä»¶é”ï¼ˆæœ€å¤šé‡è¯• 10 æ¬¡ï¼Œæ¯æ¬¡ç­‰å¾… 0.1-1 ç§’ï¼‰
    max_retries = 10
    for attempt in range(max_retries):
        try:
            # æ‰“å¼€é”æ–‡ä»¶ï¼ˆåˆ›å»ºå¦‚æœä¸å­˜åœ¨ï¼‰
            # Windows éœ€è¦äºŒè¿›åˆ¶æ¨¡å¼ï¼ŒLinux/Mac å¯ä»¥ç”¨æ–‡æœ¬æ¨¡å¼
            if platform.system() == 'Windows' and HAS_FILE_LOCK:
                lock = open(lock_file, 'wb')
                try:
                    msvcrt.locking(lock.fileno(), msvcrt.LK_LOCK, 1)
                except:
                    lock.close()
                    raise
            else:
                lock = open(lock_file, 'w')
                if HAS_FILE_LOCK and platform.system() != 'Windows':
                    try:
                        fcntl.flock(lock.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)
                    except:
                        lock.close()
                        raise
                else:
                    # å¦‚æœæ²¡æœ‰æ–‡ä»¶é”æ”¯æŒï¼Œä½¿ç”¨ç®€å•çš„é‡è¯•æœºåˆ¶
                    import time
                    time.sleep(random.uniform(0.1, 0.5))
            
            try:
                # è¯»å–å½“å‰è®¡æ•°å™¨
                if id_counter_file.exists():
                    try:
                        with open(id_counter_file, 'r') as f:
                            current_id = int(f.read().strip())
                    except (ValueError, IOError):
                        current_id = 0
                else:
                    # å¦‚æœè®¡æ•°å™¨ä¸å­˜åœ¨ï¼Œä»ç°æœ‰æ–‡ä»¶ä¸­æŸ¥æ‰¾æœ€å¤§ ID
                    existing_files = list(output_dir.glob(f"{prefix}_fatal_*.json"))
                    if existing_files:
                        max_id = max([
                            int(re.search(r'_(\d+)\.json$', f.name).group(1)) 
                            for f in existing_files 
                            if re.search(r'_(\d+)\.json$', f.name)
                        ], default=0)
                        current_id = max_id
                    else:
                        current_id = 0
                
                # åˆ†é…ä¸‹ä¸€ä¸ªæ‰¹æ¬¡
                next_id = current_id + 1
                new_id = next_id + batch_size - 1
                
                # æ›´æ–°è®¡æ•°å™¨
                with open(id_counter_file, 'w') as f:
                    f.write(str(new_id))
                
                # è¿”å›åˆ†é…çš„èµ·å§‹ ID
                result = next_id
                
            finally:
                # é‡Šæ”¾é”å¹¶å…³é—­æ–‡ä»¶
                if HAS_FILE_LOCK:
                    try:
                        if platform.system() == 'Windows':
                            msvcrt.locking(lock.fileno(), msvcrt.LK_UNLCK, 1)
                        else:
                            fcntl.flock(lock.fileno(), fcntl.LOCK_UN)
                    except:
                        pass
                lock.close()
            
            return result
                
        except (IOError, OSError, BlockingIOError) as e:
            # é”è¢«å ç”¨ï¼Œç­‰å¾…åé‡è¯•
            if attempt < max_retries - 1:
                time.sleep(random.uniform(0.1, 0.5))
            else:
                # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œå›é€€åˆ°éå®‰å…¨æ¨¡å¼
                print(f"[è­¦å‘Š] æ— æ³•è·å–æ–‡ä»¶é”ï¼Œä½¿ç”¨éå®‰å…¨æ¨¡å¼ï¼ˆå¯èƒ½æœ‰ ID å†²çªé£é™©ï¼‰")
                existing_files = list(output_dir.glob(f"{prefix}_fatal_*.json"))
                if existing_files:
                    max_id = max([
                        int(re.search(r'_(\d+)\.json$', f.name).group(1)) 
                        for f in existing_files 
                        if re.search(r'_(\d+)\.json$', f.name)
                    ], default=0)
                    return max_id + 1
                return 1
    
    # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œè¿”å›é»˜è®¤å€¼
    return 1


async def main():
    """ä¸»å‡½æ•° - å¼‚æ­¥å¹¶å‘ç”Ÿæˆï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œå¹¶è¡Œè¿è¡Œ"""
    import sys
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    subset = "AG" 
    if len(sys.argv) > 1:
        if sys.argv[1].upper() in ["AG", "HC"]:
            subset = sys.argv[1].upper()
        elif sys.argv[1] == "test":
            await test_single_generation()
            return
    
    print("=" * 60)
    print("ASTRA-Gen 3.0: é¢å‘å›¾è§£æå‹å¥½çš„åŠ¨æ€å› æœä»¿çœŸæ¡†æ¶")
    print("=" * 60)
    
    # ç¡®å®šè¾“å‡ºç›®å½•å’Œå‰ç¼€
    output_dir = OUTPUT_DIR_AG if subset == "AG" else OUTPUT_DIR_HC
    prefix = "AG" if subset == "AG" else "HC"
    
    # ğŸ”¥ ä¼˜åŒ–ï¼šä½¿ç”¨å®‰å…¨çš„ ID åˆ†é…æœºåˆ¶ï¼ˆæ”¯æŒå¹¶è¡Œè¿è¡Œï¼‰
    # æ¯æ¬¡åˆ†é… 100 ä¸ª IDï¼Œå‡å°‘é”ç«äº‰
    start_id = get_next_task_id_safely(output_dir, prefix, batch_size=100)
    
    # ç›®æ ‡ç”Ÿæˆæ€»ä»»åŠ¡æ•°
    num_tasks_total = 700 
    
    print(f"æ•°æ®å­é›†: {subset} ({'Algorithm-Generated' if subset == 'AG' else 'Hand-Crafted'})")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print(f"API æ¨¡å‹: {MODEL_NAME}")
    print(f"ç›®æ ‡ç”Ÿæˆä»»åŠ¡èŒƒå›´: ID {start_id} åˆ° {num_tasks_total}")
    print("=" * 60)
    
    # åˆ›å»ºä»»åŠ¡ç”Ÿæˆå™¨
    async with APIClient(API_KEY, BASE_URL, MODEL_NAME) as api_client:
        task_generator = TaskGenerator(api_client)
        
        # åˆ›å»ºä»»åŠ¡åˆ—è¡¨ï¼ˆä½¿ç”¨åŠ¨æ€ç”Ÿæˆï¼‰
        tasks = []
        
        # ä»…ç”Ÿæˆä» start_id å¼€å§‹çš„ä»»åŠ¡
        tasks_to_create = num_tasks_total - start_id + 1
        tasks_to_create = max(0, tasks_to_create)

        print(f"\nç”Ÿæˆ {tasks_to_create} ä¸ªåŠ¨æ€ä»»åŠ¡æ¨¡æ¿...")
        
        for i in range(tasks_to_create):
            task = await task_generator.generate_task()
            tasks.append((task, start_id + i))
            if (i + 1) % 50 == 0:
                print(f"  å·²ç”Ÿæˆ {i + 1}/{tasks_to_create} ä¸ªä»»åŠ¡æ¨¡æ¿...")
    
    # å¹¶å‘æ§åˆ¶
    semaphore = asyncio.Semaphore(5)  # æœ€å¤š5ä¸ªå¹¶å‘è¯·æ±‚
    
    async def generate_with_semaphore(api_client, task, task_id):
        async with semaphore:
            return await generate_single_task(api_client, task, task_id, subset=subset)
    
    # ä½¿ç”¨ API å®¢æˆ·ç«¯
    async with APIClient(API_KEY, BASE_URL, MODEL_NAME) as api_client:
        # åˆ›å»ºä»»åŠ¡
        coroutines = [
            generate_with_semaphore(api_client, task, task_id)
            for task, task_id in tasks
        ]
        
        # æ‰§è¡Œå¹¶ç­‰å¾…å®Œæˆ
        print(f"\nå¼€å§‹ç”Ÿæˆ {len(tasks)} ä¸ªæ–°ä»»åŠ¡...")
        results = await asyncio.gather(*coroutines, return_exceptions=True)
        
        # ç»Ÿè®¡ç»“æœ
        success_count = sum(1 for r in results if r is True)
        fail_count = len(results) - success_count
        
        print("\n" + "=" * 60)
        print("ç”Ÿæˆå®Œæˆ!")
        print(f"æˆåŠŸ: {success_count} (å…± {success_count * 3} ä¸ª JSON æ–‡ä»¶)")
        print(f"å¤±è´¥: {fail_count}")
        print(f"å·²å®Œæˆä»»åŠ¡ ID: {start_id + len(tasks) - 1}")
        print("=" * 60)


async def test_single_generation():
    """æµ‹è¯•å•ä¸ªä»»åŠ¡ç”Ÿæˆï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
    print("=" * 60)
    print("æµ‹è¯•æ¨¡å¼: ç”Ÿæˆå•ä¸ªä»»åŠ¡çš„ä¸‰å…ƒç»„")
    print("=" * 60)
    
    async with APIClient(API_KEY, BASE_URL, MODEL_NAME) as api_client:
        # ä½¿ç”¨åŠ¨æ€ä»»åŠ¡ç”Ÿæˆå™¨
        task_generator = TaskGenerator(api_client)
        test_task = await task_generator.generate_task()
        print(f"ç”Ÿæˆçš„ä»»åŠ¡: {test_task['question']}")
        
        generator = DataGenerator(api_client)
        try:
            triplet = await generator.generate_triplet(test_task, 0)
            generator.save_triplet(triplet, subset="AG")
            print("\næµ‹è¯•å®Œæˆ! æ£€æŸ¥è¾“å‡ºæ–‡ä»¶:")
            print(f"  - {OUTPUT_DIR_AG / 'AG_golden_00000.json'}")
            print(f"  - {OUTPUT_DIR_AG / 'AG_fatal_00000.json'}")
            print(f"  - {OUTPUT_DIR_AG / 'AG_healed_00000.json'}")
        except Exception as e:
            print(f"æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()


if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == "test":
        # æµ‹è¯•æ¨¡å¼
        asyncio.run(test_single_generation())
    else:
        # æ­£å¸¸æ¨¡å¼ï¼ˆæ”¯æŒ AG æˆ– HC å‚æ•°ï¼‰
        asyncio.run(main())

