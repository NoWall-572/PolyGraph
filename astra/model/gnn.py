"""
ASTRA-MoE æ¨¡å‹å®ç°
åŸºäº STGAT (Spatio-Temporal Graph Attention Network) çš„æ•…éšœå½’å› æ¨¡å‹

æ¨¡å‹æ¶æ„åŒ…å«å››ä¸ªç»„ä»¶ï¼š
1. MicroStateEncoder - å¤šæ¨¡æ€å¾®è§‚çŠ¶æ€ç¼–ç å™¨
2. STGAT - ç©ºé—´-æ—¶é—´å›¾æ³¨æ„åŠ›ç½‘ç»œ
3. TemporalReasoning - å› æœæ—¶åºæ¨ç†ï¼ˆRoPE + Causal Transformerï¼‰
4. MoEHead - ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„ MoE è¯Šæ–­å¤´
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import math
from typing import Dict, List, Optional, Tuple
from astra.data.graph_data import HeteroGraph
from astra.model.stgat import STGAT


class MicroStateEncoder(nn.Module):
    """
    å¤šæ¨¡æ€å¾®è§‚çŠ¶æ€ç¼–ç å™¨
    
    å°†å¼‚æ„èŠ‚ç‚¹çš„æ–‡æœ¬åµŒå…¥ä¸ç¦»æ•£/è¿ç»­ç‰¹å¾èåˆï¼ŒæŠ•å½±åˆ°ç»Ÿä¸€ç»´åº¦ d_model
    ä½¿ç”¨é—¨æ§æœºåˆ¶ (Gated Fusion) èåˆæ–‡æœ¬åµŒå…¥å’Œå…ƒæ•°æ®ç‰¹å¾
    """
    
    def __init__(self, 
                 node_feat_dim: int = 8192,  # ğŸ”¥ Qwen-8B: 4096 (åµŒå…¥) + 4096 (å…ƒæ•°æ®)
                 d_model: int = 256,
                 dropout: float = 0.1):
        """
        Args:
            node_feat_dim: è¾“å…¥èŠ‚ç‚¹ç‰¹å¾ç»´åº¦ï¼ˆæ¥è‡ª data_adapterï¼‰
            d_model: è¾“å‡ºç»Ÿä¸€ç»´åº¦
            dropout: Dropout æ¯”ç‡
        """
        super().__init__()
        self.node_feat_dim = node_feat_dim
        self.d_model = d_model
        
        # å‡è®¾è¾“å…¥ç‰¹å¾ä¸­ï¼Œå‰4096ç»´æ˜¯ content_embedding (Qwen-8B from JSON)ï¼Œå…¶ä½™æ˜¯å…ƒæ•°æ®ç‰¹å¾ (Sentence-BERT from JSON)ï¼Œå…¶ä½™æ˜¯å…ƒæ•°æ®ç‰¹å¾
        self.text_dim = 4096  # ğŸ”¥ Qwen-8B åµŒå…¥ç»´åº¦  # ğŸ”¥ ä¿æŒ 384
        self.meta_dim = node_feat_dim - self.text_dim  # 4096 - 384 = 3712
        
        # æ–‡æœ¬åµŒå…¥æŠ•å½±å±‚
        self.text_proj = nn.Linear(self.text_dim, d_model)
        
        # å…ƒæ•°æ®ç‰¹å¾å¤„ç† MLP
        # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨ GELU é˜²æ­¢æ­»ç¥ç»å…ƒ
        self.meta_mlp = nn.Sequential(
            nn.Linear(self.meta_dim, d_model // 2),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(d_model // 2, d_model)
        )
        
        # é—¨æ§ç½‘ç»œï¼ˆè¾“å‡ºèåˆæƒé‡ï¼‰
        # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨ GELU é˜²æ­¢æ­»ç¥ç»å…ƒ
        self.gate_net = nn.Sequential(
            nn.Linear(d_model * 2, d_model),
            nn.GELU(),
            nn.Linear(d_model, 1),
            nn.Sigmoid()
        )
        
        # æœ€ç»ˆæŠ•å½±å±‚
        self.output_proj = nn.Linear(d_model, d_model)
        self.dropout = nn.Dropout(dropout)
        self.layer_norm = nn.LayerNorm(d_model)
        
        # ğŸ”¥ ä¿®å¤ï¼šå¢å¼º Padding Token åˆå§‹åŒ–ï¼Œç¡®ä¿å®ƒæœ‰å­˜åœ¨æ„Ÿ
        # ä½¿ç”¨è¾ƒå¤§çš„éšæœºå€¼ï¼Œé˜²æ­¢å®ƒè¢«å¿½ç•¥ï¼ˆç‰¹åˆ«æ˜¯å¯¹äºç¨€ç–çš„å¹½çµèŠ‚ç‚¹ï¼‰
        self.padding_token = nn.Parameter(torch.randn(1, d_model))
    
    def forward(self, graph: HeteroGraph) -> Dict[str, torch.Tensor]:
        """
        å¯¹æ¯ä¸ªèŠ‚ç‚¹ç±»å‹è¿›è¡Œç¼–ç 
        
        Args:
            graph: HeteroGraph å¯¹è±¡
            
        Returns:
            Dict[str, Tensor]: æ¯ä¸ªèŠ‚ç‚¹ç±»å‹çš„ç¼–ç ç»“æœï¼Œshape: [num_nodes, d_model]
        """
        encoded_nodes = {}
        
        for node_type in graph.get_node_types():
            if node_type not in graph.node_features:
                continue
                
            x = graph.node_features[node_type]  # [num_nodes, node_feat_dim]
            num_nodes = x.shape[0]
            
            # åˆ†ç¦»æ–‡æœ¬åµŒå…¥å’Œå…ƒæ•°æ®ç‰¹å¾
            text_emb = x[:, :self.text_dim]  # [num_nodes, 384]
            meta_feat = x[:, self.text_dim:]  # [num_nodes, meta_dim]
            
            # æŠ•å½±åˆ°ç»Ÿä¸€ç»´åº¦
            e_text = self.text_proj(text_emb)  # [num_nodes, d_model]
            e_meta = self.meta_mlp(meta_feat)  # [num_nodes, d_model]
            
            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šå½»åº•ç§»é™¤åŸºäºç‰¹å¾å€¼çš„ padding æ£€æµ‹
            # Ghost Node çš„ç‰¹å¾å¯èƒ½å¾ˆå°ï¼Œä½†ç»ä¸æ˜¯ Paddingï¼
            # æˆ‘ä»¬å‡è®¾æ‰€æœ‰è¾“å…¥çš„èŠ‚ç‚¹éƒ½æ˜¯æœ‰æ•ˆçš„ï¼ŒçœŸæ­£çš„ Padding åªåœ¨ Batch Collate æ—¶äº§ç”Ÿ
            # è¿™æ ·å¯ä»¥é˜²æ­¢ Hand-Crafted æ•°æ®ä¸­çš„ç¨€ç–èŠ‚ç‚¹è¢«é”™è¯¯åœ°è¯†åˆ«ä¸º Padding
            
            # é—¨æ§èåˆ
            # è®¡ç®—é—¨æ§æƒé‡ g
            gate_input = torch.cat([e_text, e_meta], dim=-1)  # [num_nodes, 2*d_model]
            g = self.gate_net(gate_input)  # [num_nodes, 1]
            
            # èåˆï¼šh = g * e_text + (1 - g) * e_meta
            h = g * e_text + (1 - g) * e_meta
            
            # è¾“å‡ºæŠ•å½±å’Œå½’ä¸€åŒ–
            h = self.output_proj(h)
            h = self.dropout(h)
            h = self.layer_norm(h)
            
            encoded_nodes[node_type] = h
        
        return encoded_nodes


class SpatialGraphEncoder(nn.Module):
    """
    ç©ºé—´å›¾ç¼–ç å™¨ï¼ˆä½¿ç”¨ STGATï¼‰
    
    å¯¹å¼‚æ„å›¾è¿›è¡Œç©ºé—´ç¼–ç ï¼Œä½¿ç”¨ STGAT æ¨¡å‹
    """
    
    def __init__(self,
                 d_model: int,
                 edge_dim: int,
                 num_heads: int = 8,
                 num_layers: int = 2,
                 dropout: float = 0.1):
        """
        Args:
            d_model: èŠ‚ç‚¹ç‰¹å¾ç»´åº¦
            edge_dim: è¾¹ç‰¹å¾ç»´åº¦
            num_heads: æ³¨æ„åŠ›å¤´æ•°
            num_layers: STGAT å±‚æ•°
            dropout: Dropout æ¯”ç‡
        """
        super().__init__()
        self.d_model = d_model
        self.edge_dim = edge_dim
        
        # ä½¿ç”¨ STGAT æ¨¡å‹
        self.stgat = STGAT(
            d_model=d_model,
            edge_dim=edge_dim,
            num_heads=num_heads,
            num_layers=num_layers,
            dropout=dropout
        )
    
    def forward(self, 
                graph: HeteroGraph,
                encoded_nodes: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:
        """
        å¯¹å¼‚æ„å›¾è¿›è¡Œç©ºé—´ç¼–ç 
        
        Args:
            graph: HeteroGraph å¯¹è±¡
            encoded_nodes: MicroStateEncoder çš„è¾“å‡º
            
        Returns:
            æ›´æ–°åçš„èŠ‚ç‚¹ç‰¹å¾å­—å…¸
        """
        # ä½¿ç”¨ STGAT è¿›è¡Œç©ºé—´ç¼–ç 
        updated_nodes = self.stgat(encoded_nodes, graph)
        
        return updated_nodes


class RoPE(nn.Module):
    """
    æ—‹è½¬ä½ç½®ç¼–ç  (Rotary Positional Embedding)
    """
    
    def __init__(self, d_model: int, max_len: int = 512):
        """
        Args:
            d_model: ç‰¹å¾ç»´åº¦ï¼ˆå¿…é¡»æ˜¯å¶æ•°ï¼‰
            max_len: æœ€å¤§åºåˆ—é•¿åº¦
        """
        super().__init__()
        assert d_model % 2 == 0, "d_model must be even for RoPE"
        
        self.d_model = d_model
        self.max_len = max_len
        
        # è®¡ç®—é¢‘ç‡
        inv_freq = 1.0 / (10000 ** (torch.arange(0, d_model, 2).float() / d_model))
        self.register_buffer('inv_freq', inv_freq)
    
    def forward(self, x: torch.Tensor, positions: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        åº”ç”¨æ—‹è½¬ä½ç½®ç¼–ç 
        
        Args:
            x: è¾“å…¥ç‰¹å¾ [seq_len, batch_size, d_model] æˆ– [seq_len, d_model]
            positions: ä½ç½®ç´¢å¼• [seq_len]ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨ 0, 1, 2, ...
            
        Returns:
            ç¼–ç åçš„ç‰¹å¾ï¼Œå½¢çŠ¶ä¸ x ç›¸åŒ
        """
        if x.dim() == 2:
            seq_len, d_model = x.shape
            batch_size = 1
            x = x.unsqueeze(1)  # [seq_len, 1, d_model]
        else:
            seq_len, batch_size, d_model = x.shape
        
        if positions is None:
            positions = torch.arange(seq_len, device=x.device)
        
        # è®¡ç®—è§’åº¦
        angles = positions.unsqueeze(-1) * self.inv_freq.unsqueeze(0)  # [seq_len, d_model//2]
        
        # è®¡ç®— cos å’Œ sin
        cos = torch.cos(angles)  # [seq_len, d_model//2]
        sin = torch.sin(angles)  # [seq_len, d_model//2]
        
        # å°† x åˆ†æˆä¸¤éƒ¨åˆ†
        x1, x2 = x.chunk(2, dim=-1)  # æ¯ä¸ª [seq_len, batch_size, d_model//2]
        
        # åº”ç”¨æ—‹è½¬
        x1_rot = x1 * cos.unsqueeze(1) - x2 * sin.unsqueeze(1)
        x2_rot = x1 * sin.unsqueeze(1) + x2 * cos.unsqueeze(1)
        
        # æ‹¼æ¥
        x_rot = torch.cat([x1_rot, x2_rot], dim=-1)  # [seq_len, batch_size, d_model]
        
        if x.dim() == 2:
            x_rot = x_rot.squeeze(1)  # [seq_len, d_model]
        
        return x_rot


class TemporalReasoning(nn.Module):
    """
    å› æœæ—¶åºæ¨ç†æ¨¡å— (ä¿®å¤ç‰ˆ)
    
    ä½¿ç”¨ RoPE + Causal Transformer Encoder å¤„ç†æ—¶é—´åºåˆ—
    åº”ç”¨ä¸¥æ ¼å› æœæ©ç ï¼Œç¡®ä¿ t æ—¶åˆ»åªä¾èµ– 0...t æ—¶åˆ»çš„ä¿¡æ¯
    """
    
    def __init__(self,
                 d_model: int,
                 num_heads: int = 8,
                 num_layers: int = 2,
                 dim_feedforward: int = 1024,
                 dropout: float = 0.1,
                 max_seq_len: int = 160):
        super().__init__()
        self.d_model = d_model
        self.num_heads = num_heads
        self.num_layers = num_layers
        
        # RoPE ä½ç½®ç¼–ç 
        self.rope = RoPE(d_model, max_seq_len)
        
        # Transformer Encoder å±‚
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=num_heads,
            dim_feedforward=dim_feedforward,
            dropout=dropout,
            activation='gelu',
            batch_first=False,  # ä½¿ç”¨ [seq_len, batch, features] æ ¼å¼
            norm_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        self.dropout = nn.Dropout(dropout)
    
    def forward(self, 
                node_sequences: Dict[str, torch.Tensor],
                padding_masks: Optional[Dict[str, torch.Tensor]] = None) -> Dict[str, torch.Tensor]:
        """
        å¯¹æ¯ä¸ªèŠ‚ç‚¹ç±»å‹çš„æ—¶é—´åºåˆ—è¿›è¡Œå› æœæ¨ç†
        
        Args:
            node_sequences: Dict[node_type, Tensor] [seq_len, num_nodes, d_model]
            padding_masks: Dict[node_type, Tensor] [num_nodes] (True è¡¨ç¤ºæœ‰æ•ˆèŠ‚ç‚¹)
                           æ³¨æ„ï¼šè¿™é‡Œçš„ Mask é€»è¾‘é€šå¸¸æ˜¯ True=Valid, False=Invalid
                           ä½† Transformer éœ€è¦ True=Ignore, False=Keep
        """
        output_sequences = {}
        
        for node_type, seq_features in node_sequences.items():
            seq_len, num_nodes, d_model = seq_features.shape
            
            if seq_len == 0 or num_nodes == 0:
                output_sequences[node_type] = seq_features
                continue
            
            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šå½»åº•ç§»é™¤åŸºäºç‰¹å¾å€¼çš„ padding æ£€æµ‹
            # é»˜è®¤æ—  Mask (æ‰€æœ‰èŠ‚ç‚¹æœ‰æ•ˆ)ï¼Œåªä½¿ç”¨å¤–éƒ¨ä¼ å…¥çš„ explicit mask
            src_key_padding_mask = None
            if padding_masks is not None and node_type in padding_masks:
                valid_mask = padding_masks[node_type]
                # True=Ignore, False=Keep
                if valid_mask.shape[0] == num_nodes:
                     src_key_padding_mask = ~valid_mask.bool().unsqueeze(0).expand(seq_len, -1).t() # [batch, seq_len]
            
            # åº”ç”¨ RoPE
            seq_features = self.rope(seq_features)
            seq_features = self.dropout(seq_features)
            
            # Reshape: [seq_len, batch_size, d_model]
            batch_size = num_nodes
            seq_features = seq_features.view(seq_len, batch_size, d_model)
            
            # å› æœæ©ç 
            causal_mask = torch.triu(torch.ones(seq_len, seq_len, device=seq_features.device, dtype=torch.bool), diagonal=1) if seq_len > 1 else None
            
            # ğŸ”¥ ä¿®å¤ï¼šç›´æ¥ä¼ é€’å‚æ•°ï¼Œç®€åŒ–è°ƒç”¨
            output = self.transformer(seq_features, mask=causal_mask, src_key_padding_mask=src_key_padding_mask)
            output = output.view(seq_len, num_nodes, d_model)
            output_sequences[node_type] = output
        
        return output_sequences


class StepPredictor(nn.Module):
    """
    æ•…éšœæ—¶é—´æ­¥é¢„æµ‹æ¨¡å—ï¼ˆå¢å¼ºç‰ˆï¼‰
    
    ä»æ—¶åºç‰¹å¾ä¸­é¢„æµ‹æ•…éšœå‘ç”Ÿçš„æ—¶é—´æ­¥
    ä½¿ç”¨ Max-Pooling + Attention ç»“åˆç­–ç•¥ï¼Œé˜²æ­¢æ•…éšœä¿¡å·è¢«ç¨€é‡Š
    
    ç­–ç•¥ï¼š
    1. å¯¹æ¯ä¸ª Agent ç‹¬ç«‹è®¡ç®—æ•…éšœåˆ†æ•°ï¼ˆFault Scoreï¼‰
    2. å–è¯¥æ—¶é—´æ­¥æ‰€æœ‰ Agent ä¸­çš„æœ€å¤§æ•…éšœåˆ†ä½œä¸ºè¯¥æ­¥çš„åˆ†æ•°
    3. è¿™æ ·åªè¦æœ‰ä¸€ä¸ª Agent åœ¨æŸä¸€æ­¥è¡¨ç°æå·®ï¼Œè¯¥æ­¥å°±ä¼šè¢«æ ‡è®°ä¸ºé«˜é£é™©
    
    è¾“å…¥ï¼šæ—¶åºç‰¹å¾åºåˆ— [seq_len, num_agents, d_model]
    è¾“å‡ºï¼šæ¯ä¸ªæ—¶é—´æ­¥æ˜¯æ•…éšœæ­¥çš„ logits [seq_len]
    """
    
    def __init__(self,
                 d_model: int,
                 hidden_dim: int = 128,
                 dropout: float = 0.1):
        """
        Args:
            d_model: è¾“å…¥ç‰¹å¾ç»´åº¦
            hidden_dim: éšè—å±‚ç»´åº¦
            dropout: Dropout æ¯”ç‡
        """
        super().__init__()
        self.d_model = d_model
        self.hidden_dim = hidden_dim
        
        # Agent æ•…éšœåˆ†æ•°è®¡ç®—å™¨ï¼ˆå¯¹æ¯ä¸ª Agent ç‹¬ç«‹æ‰“åˆ†ï¼‰
        # è¾“å…¥: [d_model]ï¼Œè¾“å‡º: [1] (æ•…éšœåˆ†æ•° logit)
        # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨ GELU é˜²æ­¢æ­»ç¥ç»å…ƒ
        self.agent_scorer = nn.Sequential(
            nn.Linear(d_model, hidden_dim),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim // 2, 1)  # è¾“å‡ºæ¯ä¸ª Agent çš„æ•…éšœåˆ†æ•°
        )
    
    def forward(self, agent_features: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            agent_features: Agent æ—¶åºç‰¹å¾ [seq_len, num_agents, d_model]
            
        Returns:
            step_logits: æ¯ä¸ªæ—¶é—´æ­¥æ˜¯æ•…éšœæ­¥çš„ logits [seq_len]
        """
        seq_len, num_agents, d_model = agent_features.shape
        
        # 1. å¯¹æ¯ä¸ª Agent ç‹¬ç«‹è®¡ç®—æ•…éšœåˆ†æ•°
        # agent_features: [seq_len, num_agents, d_model]
        # é‡å¡‘ä¸º [seq_len * num_agents, d_model] ä»¥ä¾¿æ‰¹é‡å¤„ç†
        agent_features_flat = agent_features.view(-1, d_model)  # [seq_len * num_agents, d_model]
        
        # è®¡ç®—æ¯ä¸ª Agent çš„æ•…éšœåˆ†æ•°
        agent_logits = self.agent_scorer(agent_features_flat)  # [seq_len * num_agents, 1]
        agent_logits = agent_logits.squeeze(-1)  # [seq_len * num_agents]
        
        # é‡å¡‘å› [seq_len, num_agents]
        agent_logits = agent_logits.view(seq_len, num_agents)  # [seq_len, num_agents]
        
        # 2. å–è¯¥æ—¶é—´æ­¥æ‰€æœ‰ Agent ä¸­çš„æœ€å¤§æ•…éšœåˆ†ä½œä¸ºè¯¥æ­¥çš„åˆ†æ•°
        # è¿™æ ·åªè¦æœ‰ä¸€ä¸ª Agent åœ¨æŸä¸€æ­¥è¡¨ç°æå·®ï¼Œè¯¥æ­¥å°±ä¼šè¢«æ ‡è®°ä¸ºé«˜é£é™©
        step_logits, _ = torch.max(agent_logits, dim=1)  # [seq_len]
        
        return step_logits


class MoEHead(nn.Module):
    """
    ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„ MoE è¯Šæ–­å¤´
    
    ä½¿ç”¨ Top-2 Router å’Œ Dirichlet åˆ†å¸ƒè¾“å‡º
    """
    
    def __init__(self,
                 d_model: int,
                 num_experts: int = 4,
                 num_classes: int = 10,  # å‡è®¾æœ€å¤š10ä¸ª Agent èŠ‚ç‚¹
                 expert_hidden_dim: int = 256,
                 dropout: float = 0.1,
                 noise_std: float = 0.1):
        """
        Args:
            d_model: è¾“å…¥ç‰¹å¾ç»´åº¦
            num_experts: ä¸“å®¶æ•°é‡
            num_classes: è¾“å‡ºç±»åˆ«æ•°ï¼ˆAgent èŠ‚ç‚¹æ•°ï¼‰
            expert_hidden_dim: ä¸“å®¶ç½‘ç»œéšè—å±‚ç»´åº¦
            dropout: Dropout æ¯”ç‡
            noise_std: Noisy Top-k è·¯ç”±çš„å™ªå£°æ ‡å‡†å·®
        """
        super().__init__()
        self.d_model = d_model
        self.num_experts = num_experts
        self.num_classes = num_classes
        self.noise_std = noise_std
        
        # Gating Network (Top-2 Router)
        # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨ GELU é˜²æ­¢æ­»ç¥ç»å…ƒ
        self.gate = nn.Sequential(
            nn.Linear(d_model, d_model),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(d_model, num_experts)
        )
        
        # Expert Networks
        # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨ GELU é˜²æ­¢æ­»ç¥ç»å…ƒ
        self.experts = nn.ModuleList([
            nn.Sequential(
                nn.Linear(d_model, expert_hidden_dim),
                nn.GELU(),
                nn.Dropout(dropout),
                nn.Linear(expert_hidden_dim, num_classes)
            ) for _ in range(num_experts)
        ])
        
        # ç”¨äº Dirichlet åˆ†å¸ƒè¾“å‡ºçš„å‚æ•°
        # Dirichlet åˆ†å¸ƒéœ€è¦ alpha å‚æ•°ï¼ˆæµ“åº¦å‚æ•°ï¼‰
        # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨ GELU é˜²æ­¢æ­»ç¥ç»å…ƒ
        self.alpha_proj = nn.Sequential(
            nn.Linear(d_model, expert_hidden_dim),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(expert_hidden_dim, num_classes),
            nn.Softplus()  # ç¡®ä¿ alpha > 0
        )
    
    def noisy_top_k_gating(self, x: torch.Tensor, k: int = 2) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Noisy Top-k Gating
        
        Args:
            x: è¾“å…¥ç‰¹å¾ [batch_size, d_model]
            k: Top-k å€¼
            
        Returns:
            gate_weights: é—¨æ§æƒé‡ [batch_size, num_experts]
            load: æ¯ä¸ªä¸“å®¶çš„è´Ÿè½½ [num_experts]
        """
        batch_size = x.size(0)
        
        # è®¡ç®—åŸºç¡€é—¨æ§åˆ†æ•°
        logits = self.gate(x)  # [batch_size, num_experts]
        
        # æ·»åŠ å™ªå£°ï¼ˆè®­ç»ƒæ—¶ï¼‰
        if self.training:
            noise = torch.randn_like(logits) * self.noise_std
            logits = logits + noise
        
        # Top-k é€‰æ‹©
        top_k_values, top_k_indices = torch.topk(logits, k, dim=-1)  # [batch_size, k]
        
        # åˆ›å»ºç¨€ç–é—¨æ§æƒé‡
        gate_weights = torch.zeros_like(logits)  # [batch_size, num_experts]
        gate_weights.scatter_(1, top_k_indices, top_k_values)
        
        # Softmax å½’ä¸€åŒ–
        gate_weights = F.softmax(gate_weights, dim=-1)
        
        # è®¡ç®—è´Ÿè½½ï¼ˆç”¨äºè´Ÿè½½å‡è¡¡ï¼‰
        load = gate_weights.sum(dim=0)  # [num_experts]
        
        return gate_weights, load
    
    def forward(self, 
                node_features: Dict[str, torch.Tensor],
                agent_indices: Optional[Dict[str, torch.Tensor]] = None) -> Dict[str, torch.Tensor]:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            node_features: æ¯ä¸ªèŠ‚ç‚¹ç±»å‹çš„ç‰¹å¾
                å¯¹äº Agent èŠ‚ç‚¹ï¼šå½¢çŠ¶ä¸º [num_agents, d_model] æˆ– [seq_len, num_agents, d_model]
            agent_indices: Agent èŠ‚ç‚¹çš„ç´¢å¼•æ˜ å°„ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            Dict åŒ…å«ï¼š
                - 'logits': æ•…éšœæ¦‚ç‡ logits [num_agents, num_classes] æˆ– [seq_len, num_agents, num_classes]
                - 'alpha': Dirichlet åˆ†å¸ƒå‚æ•° [num_agents, num_classes] æˆ– [seq_len, num_agents, num_classes]
                - 'gate_weights': é—¨æ§æƒé‡ [num_agents, num_experts] æˆ– [seq_len, num_agents, num_experts]
        """
        # å¤„ç†æ²¡æœ‰ 'Agent' èŠ‚ç‚¹çš„æƒ…å†µ
        if 'Agent' not in node_features:
            # è¿”å›é›¶è¾“å‡ºï¼ˆç”¨äºæµ‹è¯•æˆ–æ— æ•ˆæ•°æ®ï¼‰
            import warnings
            warnings.warn(
                "MoEHead: 'Agent' node features not found. Returning zero outputs. "
                f"Available node types: {list(node_features.keys())}",
                UserWarning
            )
            # å°è¯•ä»å…¶ä»–èŠ‚ç‚¹ç±»å‹æ¨æ–­åºåˆ—é•¿åº¦
            is_sequence = False  # é»˜è®¤å€¼
            if node_features:
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„èŠ‚ç‚¹ç±»å‹æ¥æ¨æ–­å½¢çŠ¶
                first_type = list(node_features.keys())[0]
                first_feat = node_features[first_type]
                is_sequence = first_feat.dim() == 3
                if is_sequence:
                    seq_len = first_feat.shape[0]
                    num_agents = 1  # é»˜è®¤è‡³å°‘1ä¸ªagentï¼ˆç”¨äºè¾“å‡ºç»´åº¦ï¼‰
                    device = first_feat.device
                    dtype = first_feat.dtype
                else:
                    seq_len = 1
                    num_agents = 1
                    device = first_feat.device
                    dtype = first_feat.dtype
            else:
                # å®Œå…¨æ²¡æœ‰èŠ‚ç‚¹ï¼Œè¿”å›æœ€å°è¾“å‡º
                seq_len = 1
                num_agents = 1
                is_sequence = False
                device = next(self.parameters()).device
                dtype = next(self.parameters()).dtype
            
            # åˆ›å»ºé›¶è¾“å‡º
            if is_sequence:
                logits = torch.zeros(seq_len, num_agents, self.num_classes, device=device, dtype=dtype)
                alpha = torch.ones(seq_len, num_agents, self.num_classes, device=device, dtype=dtype) * 1e-6
                gate_weights = torch.zeros(seq_len, num_agents, self.num_experts, device=device, dtype=dtype)
            else:
                logits = torch.zeros(num_agents, self.num_classes, device=device, dtype=dtype)
                alpha = torch.ones(num_agents, self.num_classes, device=device, dtype=dtype) * 1e-6
                gate_weights = torch.zeros(num_agents, self.num_experts, device=device, dtype=dtype)
            
            load = torch.zeros(self.num_experts, device=device, dtype=dtype)
            
            return {
                'logits': logits,
                'alpha': alpha,
                'gate_weights': gate_weights,
                'load': load
            }
        
        agent_feat = node_features['Agent']  # [num_agents, d_model] æˆ– [seq_len, num_agents, d_model]
        
        # å¤„ç†åºåˆ—è¾“å…¥
        is_sequence = agent_feat.dim() == 3
        if is_sequence:
            seq_len, num_agents, d_model = agent_feat.shape
            agent_feat = agent_feat.view(-1, d_model)  # [seq_len * num_agents, d_model]
        else:
            num_agents, d_model = agent_feat.shape
        
        # Noisy Top-2 Gating
        gate_weights, load = self.noisy_top_k_gating(agent_feat, k=2)  # [batch, num_experts]
        
        # Expert è¾“å‡º
        expert_outputs = []
        for expert in self.experts:
            expert_out = expert(agent_feat)  # [batch, num_classes]
            expert_outputs.append(expert_out)
        
        expert_outputs = torch.stack(expert_outputs, dim=1)  # [batch, num_experts, num_classes]
        
        # åŠ æƒèšåˆä¸“å®¶è¾“å‡º
        gate_weights_expanded = gate_weights.unsqueeze(-1)  # [batch, num_experts, 1]
        logits = (expert_outputs * gate_weights_expanded).sum(dim=1)  # [batch, num_classes]
        
        # è®¡ç®— Dirichlet åˆ†å¸ƒå‚æ•° alpha
        alpha = self.alpha_proj(agent_feat)  # [batch, num_classes]
        # æ·»åŠ å°çš„æ­£æ•°ç¡®ä¿ alpha > 0
        alpha = alpha + 1e-6
        
        # å¦‚æœè¾“å…¥æ˜¯åºåˆ—ï¼Œé‡å¡‘å›åŸå§‹å½¢çŠ¶
        if is_sequence:
            logits = logits.view(seq_len, num_agents, self.num_classes)
            alpha = alpha.view(seq_len, num_agents, self.num_classes)
            gate_weights = gate_weights.view(seq_len, num_agents, self.num_experts)
        
        return {
            'logits': logits,
            'alpha': alpha,
            'gate_weights': gate_weights,
            'load': load
        }


class ASTRAMoE(nn.Module):
    """
    ASTRA-MoE å®Œæ•´æ¨¡å‹
    
    æ•´åˆå››ä¸ªç»„ä»¶ï¼š
    1. MicroStateEncoder
    2. EdgeEnhancedHGT
    3. TemporalReasoning
    4. MoEHead
    """
    
    def __init__(self,
                 node_feat_dim: int = 8192,  # ğŸ”¥ Qwen-8B: 4096 (åµŒå…¥) + 4096 (å…ƒæ•°æ®)
                 edge_feat_dim: int = 32,
                 d_model: int = 128,
                 num_heads: int = 4,
                 num_hgt_layers: int = 2,
                 num_temporal_layers: int = 2,
                 num_experts: int = 4,
                 num_classes: int = 10,
                 dropout: float = 0.5,
                 max_seq_len: int = 160):  # Updated: test data max length is 130, set to 160 with margin
        """
        Args:
            node_feat_dim: è¾“å…¥èŠ‚ç‚¹ç‰¹å¾ç»´åº¦ï¼ˆæ¥è‡ª data_adapterï¼‰
            edge_feat_dim: è¾¹ç‰¹å¾ç»´åº¦ï¼ˆæ¥è‡ª data_adapterï¼‰
            d_model: æ¨¡å‹å†…éƒ¨ç»Ÿä¸€ç»´åº¦
            num_heads: æ³¨æ„åŠ›å¤´æ•°
            num_hgt_layers: HGT å±‚æ•°
            num_temporal_layers: æ—¶åº Transformer å±‚æ•°
            num_experts: MoE ä¸“å®¶æ•°é‡
            num_classes: è¾“å‡ºç±»åˆ«æ•°ï¼ˆAgent èŠ‚ç‚¹æ•°ï¼‰
            dropout: Dropout æ¯”ç‡
            max_seq_len: æœ€å¤§åºåˆ—é•¿åº¦
        """
        super().__init__()
        
        # 1. å¤šæ¨¡æ€å¾®è§‚çŠ¶æ€ç¼–ç å™¨
        self.micro_encoder = MicroStateEncoder(
            node_feat_dim=node_feat_dim,
            d_model=d_model,
            dropout=dropout
        )
        
        # 2. ç©ºé—´å›¾ç¼–ç å™¨ï¼ˆä½¿ç”¨ STGATï¼‰
        self.spatial_encoder = SpatialGraphEncoder(
            d_model=d_model,
            edge_dim=edge_feat_dim,
            num_heads=num_heads,
            num_layers=num_hgt_layers,
            dropout=dropout
        )
        
        # 3. å› æœæ—¶åºæ¨ç†
        self.temporal = TemporalReasoning(
            d_model=d_model,
            num_heads=num_heads,
            num_layers=num_temporal_layers,
            dropout=dropout,
            max_seq_len=max_seq_len
        )
        
        # 4. MoE è¯Šæ–­å¤´
        self.moe_head = MoEHead(
            d_model=d_model,
            num_experts=num_experts,
            num_classes=num_classes,
            dropout=dropout
        )
        
        # 5. æ•…éšœæ—¶é—´æ­¥é¢„æµ‹å™¨ï¼ˆå¢å¼ºç‰ˆï¼šMax-Pooling + Attention ç»“åˆï¼‰
        self.step_predictor = StepPredictor(
            d_model=d_model,
            hidden_dim=128,
            dropout=dropout
        )
        
        # === æ–°å¢ï¼šCritic ç½‘ç»œ (ç”¨äº MAPPO) ===
        # è¾“å…¥æ˜¯ Graph Embeddingï¼Œè¾“å‡ºæ˜¯ State Value (æ ‡é‡)
        self.critic = nn.Sequential(
            nn.Linear(d_model, d_model),
            nn.Tanh(),
            nn.Linear(d_model, 1)
        )
    
    def forward(self, 
                graph_list: List[HeteroGraph],
                return_intermediate: bool = False,
                agent_mask: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            graph_list: æ—¶é—´æ­¥åºåˆ—ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ª HeteroGraph å¿«ç…§
            return_intermediate: æ˜¯å¦è¿”å›ä¸­é—´ç»“æœ
            
        Returns:
            Dict åŒ…å«ï¼š
                - 'logits': æ•…éšœæ¦‚ç‡ logits [seq_len, num_agents, num_classes]
                - 'alpha': Dirichlet åˆ†å¸ƒå‚æ•° [seq_len, num_agents, num_classes]
                - 'gate_weights': é—¨æ§æƒé‡ [seq_len, num_agents, num_experts]
                - (å¯é€‰) 'intermediate': ä¸­é—´ç»“æœå­—å…¸
        """
        seq_len = len(graph_list)
        
        # ğŸ”¥ è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å° graph_list çš„é•¿åº¦å’Œå†…å®¹
        if seq_len > 20:  # åªæ‰“å°å¼‚å¸¸é•¿çš„åºåˆ—
            print(f"[ASTRA Model] âš ï¸  WARNING: graph_list length is {seq_len}, which seems unusually long!")
            print(f"  First few graphs: {[g.get_node_types() for g in graph_list[:5]]}")
            print(f"  Last few graphs: {[g.get_node_types() for g in graph_list[-5:]]}")
            # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤çš„å›¾
            graph_ids = [id(g) for g in graph_list]
            if len(graph_ids) != len(set(graph_ids)):
                print(f"  âš ï¸  WARNING: Duplicate graphs detected! {len(graph_ids) - len(set(graph_ids))} duplicates")
        
        # æ­¥éª¤ 1: å¾®è§‚çŠ¶æ€ç¼–ç ï¼ˆæ¯ä¸ªæ—¶é—´æ­¥ï¼‰
        # é¦–å…ˆæ”¶é›†æ‰€æœ‰æ—¶é—´æ­¥çš„æ‰€æœ‰èŠ‚ç‚¹ç±»å‹ï¼Œç¡®ä¿æ‰€æœ‰èŠ‚ç‚¹ç±»å‹éƒ½è¢«å¤„ç†
        all_node_types = set()
        for graph in graph_list:
            all_node_types.update(graph.get_node_types())
        
        encoded_sequences = {node_type: [] for node_type in all_node_types}  # Dict[node_type, List[Tensor]]
        
        for t, graph in enumerate(graph_list):
            encoded_nodes = self.micro_encoder(graph)
            
            # æ”¶é›†æ¯ä¸ªèŠ‚ç‚¹ç±»å‹çš„ç‰¹å¾
            # å¯¹äºå­˜åœ¨çš„èŠ‚ç‚¹ç±»å‹ï¼Œæ·»åŠ ç¼–ç ç»“æœï¼›å¯¹äºä¸å­˜åœ¨çš„ï¼Œæ·»åŠ é›¶å‘é‡
            for node_type in all_node_types:
                if node_type in encoded_nodes:
                    encoded_sequences[node_type].append(encoded_nodes[node_type])
                else:
                    # å¦‚æœè¯¥æ—¶é—´æ­¥æ²¡æœ‰è¯¥èŠ‚ç‚¹ç±»å‹ï¼Œéœ€è¦åˆ›å»ºä¸€ä¸ªé›¶å‘é‡
                    # ä½†æˆ‘ä»¬éœ€è¦çŸ¥é“ç»´åº¦ï¼Œæ‰€ä»¥å…ˆæ£€æŸ¥å…¶ä»–æ—¶é—´æ­¥æ˜¯å¦æœ‰è¯¥èŠ‚ç‚¹ç±»å‹
                    # æˆ–è€…ä½¿ç”¨é»˜è®¤ç»´åº¦ï¼ˆä»ç¬¬ä¸€ä¸ªæœ‰è¯¥èŠ‚ç‚¹ç±»å‹çš„æ—¶é—´æ­¥è·å–ï¼‰
                    # è¿™é‡Œæˆ‘ä»¬æš‚æ—¶è·³è¿‡ï¼Œåœ¨åç»­å¯¹é½æ—¶å¤„ç†
                    # ä¸ºäº†ä¿æŒä¸€è‡´æ€§ï¼Œæˆ‘ä»¬éœ€è¦çŸ¥é“ d_model ç»´åº¦
                    # å…ˆå°è¯•ä»å·²ç¼–ç çš„èŠ‚ç‚¹è·å–ç»´åº¦
                    if encoded_sequences[node_type]:
                        # å¦‚æœä¹‹å‰å·²ç»æœ‰è¯¥èŠ‚ç‚¹ç±»å‹ï¼Œä½¿ç”¨ç›¸åŒçš„ç»´åº¦
                        d_model = encoded_sequences[node_type][0].shape[1]
                        num_nodes = 0  # è¯¥æ—¶é—´æ­¥æ²¡æœ‰è¯¥èŠ‚ç‚¹ç±»å‹
                        zero_feat = torch.zeros(num_nodes, d_model, 
                                               device=next(self.parameters()).device,
                                               dtype=next(self.parameters()).dtype)
                        encoded_sequences[node_type].append(zero_feat)
                    else:
                        # å¦‚æœè¿™æ˜¯ç¬¬ä¸€æ¬¡é‡åˆ°è¯¥èŠ‚ç‚¹ç±»å‹ï¼Œä½†å½“å‰æ—¶é—´æ­¥æ²¡æœ‰
                        # ä½¿ç”¨é»˜è®¤ç»´åº¦ d_model
                        d_model = self.micro_encoder.d_model
                        zero_feat = torch.zeros(0, d_model,
                                               device=next(self.parameters()).device,
                                               dtype=next(self.parameters()).dtype)
                        encoded_sequences[node_type].append(zero_feat)
        
        # è½¬æ¢ä¸ºåºåˆ—å¼ é‡
        node_sequences = {}
        for node_type, feat_list in encoded_sequences.items():
            # è¿‡æ»¤æ‰ç©ºå¼ é‡ï¼ˆ0ä¸ªèŠ‚ç‚¹ï¼‰ä»¥è®¡ç®—æœ€å¤§èŠ‚ç‚¹æ•°
            non_empty_feats = [f for f in feat_list if f.shape[0] > 0]
            if non_empty_feats:
                max_nodes = max(f.shape[0] for f in non_empty_feats)
                d_model = non_empty_feats[0].shape[1]
            else:
                # å¦‚æœæ‰€æœ‰æ—¶é—´æ­¥éƒ½æ²¡æœ‰è¯¥èŠ‚ç‚¹ç±»å‹ï¼Œä½¿ç”¨é»˜è®¤ç»´åº¦
                d_model = self.micro_encoder.d_model
                max_nodes = 0
            
            # å¯¹é½åˆ°æœ€å¤§èŠ‚ç‚¹æ•°ï¼ˆä½¿ç”¨é›¶å¡«å……ï¼‰
            aligned_feats = []
            for feat in feat_list:
                num_nodes = feat.shape[0]
                if num_nodes < max_nodes:
                    padding = torch.zeros(max_nodes - num_nodes, d_model, 
                                        device=feat.device, dtype=feat.dtype)
                    feat = torch.cat([feat, padding], dim=0)
                elif num_nodes == 0 and max_nodes > 0:
                    # å¦‚æœå½“å‰æ—¶é—´æ­¥æ²¡æœ‰èŠ‚ç‚¹ï¼Œä½†å…¶ä»–æ—¶é—´æ­¥æœ‰ï¼Œåˆ›å»ºé›¶å‘é‡
                    feat = torch.zeros(max_nodes, d_model,
                                     device=feat.device if feat.numel() > 0 else next(self.parameters()).device,
                                     dtype=feat.dtype if feat.numel() > 0 else next(self.parameters()).dtype)
                aligned_feats.append(feat)
            
            # å †å ä¸ºåºåˆ— [seq_len, max_nodes, d_model]
            node_sequences[node_type] = torch.stack(aligned_feats, dim=0)
        
        # æ­¥éª¤ 2: ç©ºé—´ç¼–ç ï¼ˆæ¯ä¸ªæ—¶é—´æ­¥ç‹¬ç«‹è¿›è¡Œ STGATï¼‰
        # ä½¿ç”¨ä¸å¾®è§‚ç¼–ç ç›¸åŒçš„èŠ‚ç‚¹ç±»å‹é›†åˆ
        spatial_encoded_sequences = {node_type: [] for node_type in all_node_types}
        
        for t, graph in enumerate(graph_list):
            # è·å–å½“å‰æ—¶é—´æ­¥çš„ç¼–ç èŠ‚ç‚¹
            current_encoded = {node_type: node_sequences[node_type][t] 
                             for node_type in node_sequences.keys()}
            
            # STGAT ç©ºé—´ç¼–ç 
            spatial_encoded = self.spatial_encoder(graph, current_encoded)
            
            # æ”¶é›†ç»“æœ
            # å¯¹äºå­˜åœ¨çš„èŠ‚ç‚¹ç±»å‹ï¼Œæ·»åŠ ç¼–ç ç»“æœï¼›å¯¹äºä¸å­˜åœ¨çš„ï¼Œæ·»åŠ é›¶å‘é‡
            for node_type in all_node_types:
                if node_type in spatial_encoded:
                    spatial_encoded_sequences[node_type].append(spatial_encoded[node_type])
                else:
                    # å¦‚æœè¯¥æ—¶é—´æ­¥æ²¡æœ‰è¯¥èŠ‚ç‚¹ç±»å‹ï¼Œåˆ›å»ºé›¶å‘é‡
                    if spatial_encoded_sequences[node_type]:
                        d_model = spatial_encoded_sequences[node_type][0].shape[1]
                        num_nodes = 0
                        zero_feat = torch.zeros(num_nodes, d_model,
                                               device=next(self.parameters()).device,
                                               dtype=next(self.parameters()).dtype)
                        spatial_encoded_sequences[node_type].append(zero_feat)
                    else:
                        # ä» node_sequences è·å–ç»´åº¦
                        if node_type in node_sequences:
                            d_model = node_sequences[node_type].shape[2]  # [seq_len, num_nodes, d_model]
                            num_nodes = 0
                            zero_feat = torch.zeros(num_nodes, d_model,
                                                   device=next(self.parameters()).device,
                                                   dtype=next(self.parameters()).dtype)
                            spatial_encoded_sequences[node_type].append(zero_feat)
                        else:
                            # ä½¿ç”¨é»˜è®¤ç»´åº¦
                            d_model = self.spatial_encoder.d_model
                            zero_feat = torch.zeros(0, d_model,
                                                   device=next(self.parameters()).device,
                                                   dtype=next(self.parameters()).dtype)
                            spatial_encoded_sequences[node_type].append(zero_feat)
        
        # è½¬æ¢ä¸ºåºåˆ—å¼ é‡
        spatial_sequences = {}
        for node_type, feat_list in spatial_encoded_sequences.items():
            # è¿‡æ»¤æ‰ç©ºå¼ é‡ï¼ˆ0ä¸ªèŠ‚ç‚¹ï¼‰ä»¥è®¡ç®—æœ€å¤§èŠ‚ç‚¹æ•°
            non_empty_feats = [f for f in feat_list if f.shape[0] > 0]
            if non_empty_feats:
                max_nodes = max(f.shape[0] for f in non_empty_feats)
                d_model = non_empty_feats[0].shape[1]
            else:
                # å¦‚æœæ‰€æœ‰æ—¶é—´æ­¥éƒ½æ²¡æœ‰è¯¥èŠ‚ç‚¹ç±»å‹ï¼Œä½¿ç”¨é»˜è®¤ç»´åº¦
                d_model = self.spatial_encoder.d_model
                max_nodes = 0
            
            aligned_feats = []
            for feat in feat_list:
                num_nodes = feat.shape[0]
                if num_nodes < max_nodes:
                    padding = torch.zeros(max_nodes - num_nodes, d_model,
                                        device=feat.device, dtype=feat.dtype)
                    feat = torch.cat([feat, padding], dim=0)
                elif num_nodes == 0 and max_nodes > 0:
                    # å¦‚æœå½“å‰æ—¶é—´æ­¥æ²¡æœ‰èŠ‚ç‚¹ï¼Œä½†å…¶ä»–æ—¶é—´æ­¥æœ‰ï¼Œåˆ›å»ºé›¶å‘é‡
                    feat = torch.zeros(max_nodes, d_model,
                                     device=feat.device if feat.numel() > 0 else next(self.parameters()).device,
                                     dtype=feat.dtype if feat.numel() > 0 else next(self.parameters()).dtype)
                aligned_feats.append(feat)
            
            spatial_sequences[node_type] = torch.stack(aligned_feats, dim=0)
        
        # æ­¥éª¤ 3: æ—¶åºæ¨ç†
        # ğŸ”¥ æ„å»º padding_masks å­—å…¸ä¼ ç»™ TemporalReasoning
        padding_masks = {}
        if agent_mask is not None:
            # agent_mask: [B, max_N]
            # node_sequences['Agent']: [seq_len, B, max_N, d] -> processed as [seq_len, B*max_N, d] inside?
            # âŒ ç­‰ç­‰ï¼Œtrain.py é‡Œæˆ‘ä»¬æ˜¯é€ä¸ªæ ·æœ¬ forward çš„ï¼
            # train.py: for i, graph_list in enumerate(graph_lists): output = model(graph_list_device)
            # æ‰€ä»¥è¿™é‡Œçš„ batch_size å…¶å®æ˜¯ 1 (æˆ–è€…è¯´ num_nodes å°±æ˜¯å½“å‰å›¾çš„èŠ‚ç‚¹æ•°)
            
            # æ—¢ç„¶æ˜¯é€ä¸ªæ ·æœ¬ forwardï¼Œæˆ‘ä»¬ä¸éœ€è¦å¤æ‚çš„ mask å¯¹é½
            # æˆ‘ä»¬å¯ä»¥ç›´æ¥è®© TemporalReasoning è®¤ä¸ºæ‰€æœ‰èŠ‚ç‚¹éƒ½æ˜¯æœ‰æ•ˆçš„
            # å› ä¸ºåªæœ‰ collate_fn äº§ç”Ÿçš„ padding æ‰æ˜¯éœ€è¦ mask çš„
            # è€Œ ghost nodes æ˜¯æœ‰æ•ˆçš„ï¼
            
            # âœ… ç­–ç•¥ï¼šç›´æ¥ä¸ä¼  maskï¼Œæˆ–è€…ä¼ å…¨ True çš„ mask
            pass

        # ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šç›´æ¥è°ƒç”¨ï¼Œä¸è¦è®© TemporalReasoning è‡ªå·±å»çŒœ
        # åªè¦ä¸ä¼  maskï¼ŒTemporalReasoning (ä¿®å¤ç‰ˆ) å°±ä¼šé»˜è®¤æ‰€æœ‰èŠ‚ç‚¹éƒ½æœ‰æ•ˆ
        temporal_sequences = self.temporal(spatial_sequences, padding_masks=padding_masks if padding_masks else None)
        
        # === æ–°å¢ï¼šè®¡ç®— Global Feature (ç”¨äºå¯¹æ¯”å­¦ä¹ å’Œ Critic) ===
        # å‡è®¾ temporal_sequences['Agent'] æ˜¯ [seq_len, num_agents, d_model]
        # æˆ‘ä»¬åšä¸€ä¸ª Global Pooling å¾—åˆ°æ•´å¼ å›¾çš„è¡¨ç¤ºï¼Œç”¨äº Critic å’Œ å¯¹æ¯”å­¦ä¹ 
        # Mean Pooling over time and agents
        global_feat = None
        agent_key = None
        for key in temporal_sequences.keys():
            if key.lower() == 'agent':
                agent_key = key
                break
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ° Agent é”®ï¼Œå°è¯•ç›´æ¥ä½¿ç”¨ 'Agent'
        if agent_key is None and 'Agent' in temporal_sequences:
            agent_key = 'Agent'
        
        if agent_key is not None and agent_key in temporal_sequences:
            agent_temporal = temporal_sequences[agent_key]  # [seq_len, num_agents, d_model]
            if agent_temporal.numel() > 0:
                # Mean Pooling over time and agents
                global_feat = agent_temporal.mean(dim=(0, 1))  # [d_model]
                # æ‰©å±• batch ç»´åº¦ï¼ˆè™½ç„¶è¿™é‡Œ batch_size=1ï¼Œä½†ä¸ºäº†å…¼å®¹æ€§ï¼‰
                if global_feat.dim() == 1:
                    global_feat = global_feat.unsqueeze(0)  # [1, d_model]
            else:
                global_feat = torch.zeros(1, self.micro_encoder.d_model, 
                                        device=next(self.parameters()).device,
                                        dtype=next(self.parameters()).dtype)
        else:
            # Fallback: ä½¿ç”¨é›¶å‘é‡
            global_feat = torch.zeros(1, self.micro_encoder.d_model,
                                    device=next(self.parameters()).device,
                                    dtype=next(self.parameters()).dtype)
        
        # Critic è¾“å‡º (Value)
        state_value = self.critic(global_feat)  # [1, 1] æˆ– [batch, 1]
        
        # æ­¥éª¤ 4: MoE è¯Šæ–­å¤´
        moe_output = self.moe_head(temporal_sequences)
        
        # æ­¥éª¤ 5: æ•…éšœæ—¶é—´æ­¥é¢„æµ‹
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šå¼ºåˆ¶åˆå§‹åŒ– step_logitsï¼Œç¡®ä¿æ— è®ºä»€ä¹ˆæƒ…å†µéƒ½è¿”å›
        seq_len = len(graph_list)
        device = next(self.parameters()).device
        dtype = next(self.parameters()).dtype
        
        # ğŸ”¥ å¼ºåˆ¶åˆå§‹åŒ– step_logits ä¸º Noneï¼Œé˜²æ­¢å˜é‡ä½œç”¨åŸŸé—®é¢˜
        step_logits = None
        
        # æ£€æŸ¥ temporal_sequences ä¸­æ˜¯å¦æœ‰ 'Agent' é”®ï¼ˆæ³¨æ„å¤§å°å†™ï¼‰
        agent_key = None
        for key in temporal_sequences.keys():
            if key.lower() == 'agent':
                agent_key = key
                break
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ° Agent é”®ï¼Œå°è¯•ç›´æ¥ä½¿ç”¨ 'Agent'
        if agent_key is None and 'Agent' in temporal_sequences:
            agent_key = 'Agent'
        
        # ğŸ”¥ è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°å¯ç”¨çš„é”®
        if agent_key is None:
            print(f"[ASTRA Model] âš ï¸  No 'Agent' key found. Available keys: {list(temporal_sequences.keys())}")
        
        if agent_key is not None and agent_key in temporal_sequences:
            agent_temporal = temporal_sequences[agent_key]  # [seq_len, num_agents, d_model]
            
            # ğŸ”¥ å…³é”®æ£€æŸ¥ï¼šç¡®ä¿ agent_temporal æœ‰æœ‰æ•ˆçš„ Agent èŠ‚ç‚¹
            if agent_temporal.dim() == 3:
                seq_len_check, num_agents, d_model = agent_temporal.shape
                # ğŸ”¥ å…³é”®ä¿®å¤ï¼šå¦‚æœ agent_temporal çš„é•¿åº¦ä¸ seq_len ä¸ä¸€è‡´ï¼Œéœ€è¦è°ƒæ•´
                if seq_len_check != seq_len:
                    print(f"[ASTRA Model] âš ï¸  agent_temporal length mismatch: expected {seq_len}, got {seq_len_check}")
                    print(f"  This indicates a bug in the model! graph_list length={seq_len}, but agent_temporal length={seq_len_check}")
                    print(f"  This will cause index out of bounds errors in loss calculation!")
                    # ğŸ”¥ å¼ºåˆ¶æˆªæ–­åˆ° seq_lenï¼ˆè¿™æ˜¯æ­£ç¡®çš„é•¿åº¦ï¼‰
                    if seq_len_check > seq_len:
                        agent_temporal = agent_temporal[:seq_len]
                        seq_len_check = seq_len
                        print(f"[ASTRA Model] âœ… Truncated agent_temporal to shape: {agent_temporal.shape}")
                    elif seq_len_check < seq_len:
                        # å¡«å…… agent_temporal åˆ° seq_len
                        pad_size = seq_len - seq_len_check
                        padding = torch.zeros(pad_size, num_agents, d_model, device=device, dtype=dtype)
                        agent_temporal = torch.cat([agent_temporal, padding], dim=0)
                        seq_len_check = seq_len
                        print(f"[ASTRA Model] âœ… Padded agent_temporal to shape: {agent_temporal.shape}")
                
                if num_agents > 0:
                    # æœ‰æœ‰æ•ˆçš„ Agent èŠ‚ç‚¹ï¼Œæ­£å¸¸é¢„æµ‹
                    try:
                        step_logits = self.step_predictor(agent_temporal)  # [seq_len]
                        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šç¡®ä¿ step_logits çš„å½¢çŠ¶æ­£ç¡®ï¼ˆä½¿ç”¨ seq_lenï¼Œè€Œä¸æ˜¯ seq_len_checkï¼‰
                        if step_logits.shape[0] != seq_len:
                            print(f"[ASTRA Model] âš ï¸  StepPredictor output shape mismatch: expected {seq_len}, got {step_logits.shape[0]}")
                            # è°ƒæ•´å½¢çŠ¶
                            if step_logits.shape[0] < seq_len:
                                padding = torch.full((seq_len - step_logits.shape[0],), float('-inf'), device=device, dtype=dtype)
                                step_logits = torch.cat([step_logits, padding], dim=0)
                            else:
                                step_logits = step_logits[:seq_len]
                        # ğŸ”¥ åŒé‡æ£€æŸ¥ï¼šç¡®ä¿ä¿®å¤åé•¿åº¦æ­£ç¡®
                        if step_logits.shape[0] != seq_len:
                            print(f"[ASTRA Model] âŒ CRITICAL: step_logits length still wrong after fix: {step_logits.shape[0]} != {seq_len}")
                            step_logits = torch.full((seq_len,), float('-inf'), device=device, dtype=dtype)
                    except Exception as e:
                        print(f"[ASTRA Model] âŒ StepPredictor Exception: {e}")
                        print(f"  agent_temporal shape: {agent_temporal.shape}")
                        import traceback
                        traceback.print_exc()
                        # Fallback: åˆ›å»º -inf è¾“å‡ºï¼ˆè¡¨ç¤ºæ— é¢„æµ‹ï¼‰
                        step_logits = torch.full((seq_len,), float('-inf'), device=device, dtype=dtype)
                else:
                    # Agent é”®å­˜åœ¨ä½† num_agents == 0ï¼Œåˆ›å»º fallback è¾“å‡º
                    print(f"[ASTRA Model] âš ï¸  Agent key '{agent_key}' exists but num_agents=0, using fallback")
                    step_logits = torch.full((seq_len,), float('-inf'), device=device, dtype=dtype)
            else:
                # Agent å¼ é‡ç»´åº¦ä¸æ­£ç¡®
                print(f"[ASTRA Model] âš ï¸  Agent temporal features have incorrect dimensions: {agent_temporal.shape}, expected [seq_len, num_agents, d_model]")
                step_logits = torch.full((seq_len,), float('-inf'), device=device, dtype=dtype)
        else:
            # å®Œå…¨æ²¡æœ‰ Agent èŠ‚ç‚¹ç±»å‹
            print(f"[ASTRA Model] âš ï¸  No 'Agent' node type found in temporal_sequences. Available keys: {list(temporal_sequences.keys())}")
            # ä½¿ç”¨ -inf è¡¨ç¤ºæ— æ¦‚ç‡ï¼ˆè€Œä¸æ˜¯ 0ï¼Œå› ä¸º 0 åœ¨ softmax åä»æœ‰æ¦‚ç‡ï¼‰
            step_logits = torch.full((seq_len,), float('-inf'), device=device, dtype=dtype)
        
        # ğŸ”¥ åŒé‡ä¿é™©ï¼šå¦‚æœæ²¡æœ‰ç”Ÿæˆ step_logitsï¼Œåˆ›å»ºä¸€ä¸ªå…¨ -inf çš„ Tensor
        if step_logits is None:
            print(f"[ASTRA Model] âŒ CRITICAL: step_logits is None! Creating fallback.")
            step_logits = torch.full((seq_len,), float('-inf'), device=device, dtype=dtype)
        
        # ğŸ”¥ å¼ºåˆ¶ç¡®ä¿ step_logits å­˜åœ¨ä¸”å½¢çŠ¶æ­£ç¡®
        assert step_logits is not None, "step_logits must not be None after all checks"
        assert step_logits.shape[0] == seq_len, f"step_logits shape mismatch: expected {seq_len}, got {step_logits.shape[0]}"
        
        # ğŸ”¥ è°ƒè¯•ä¿¡æ¯ï¼šç¡®è®¤ step_logits å·²åˆ›å»º
        if step_logits.isnan().any():
            print(f"[ASTRA Model] âš ï¸  step_logits contains NaN values!")
        if (step_logits == float('-inf')).all():
            print(f"[ASTRA Model] âš ï¸  step_logits are all -inf (no valid predictions)")
        
        # æ„å»ºè¾“å‡º
        # ğŸ”¥ ASTRA-CL: æå– Agent embeddings ç”¨äºå¯¹æ¯”å­¦ä¹ 
        # ç¡®ä¿å§‹ç»ˆè¿”å›è¯¥é”®ï¼Œé¿å…ä¸‹æ¸¸è·³è¿‡ CL Loss
        agent_embeddings = None
        if agent_key is not None and agent_key in temporal_sequences:
            agent_embeddings = temporal_sequences[agent_key]  # [seq_len, num_agents, d_model]
        else:
            # å…œåº•è¿”å›é›¶å¼ é‡ä»¥ä¿æŒæ¥å£å®Œæ•´
            agent_embeddings = torch.zeros(
                seq_len,
                0,
                self.micro_encoder.d_model,
                device=device,
                dtype=dtype,
            )
        
        output = {
            'logits': moe_output['logits'],
            'alpha': moe_output['alpha'],
            'gate_weights': moe_output['gate_weights'],
            'load': moe_output['load'],
            'step_logits': step_logits,  # [seq_len] - ğŸ”¥ ç»å¯¹å­˜åœ¨
            'global_feat': global_feat,  # [1, d_model] ç”¨äºå¯¹æ¯”å­¦ä¹ 
            'state_value': state_value,   # [1, 1] ç”¨äº RL
            'agent_embeddings': agent_embeddings  # [seq_len, num_agents, d_model] ç”¨äº ASTRA-CL
        }
        
        # ğŸ”¥ æœ€ç»ˆæ£€æŸ¥ï¼šç¡®ä¿ output å­—å…¸åŒ…å« step_logits
        if 'step_logits' not in output:
            raise RuntimeError("CRITICAL ERROR: 'step_logits' missing in output dict after assignment!")
        
        # ğŸ”¥ è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°è¾“å‡ºé”®
        if hasattr(self, '_debug_print_count'):
            self._debug_print_count += 1
        else:
            self._debug_print_count = 1
        
        if self._debug_print_count <= 3:  # åªæ‰“å°å‰3æ¬¡
            print(f"[ASTRA Model] âœ… Forward pass {self._debug_print_count}: output keys = {list(output.keys())}")
            print(f"  step_logits shape: {output['step_logits'].shape}, dtype: {output['step_logits'].dtype}")
        
        if return_intermediate:
            output['intermediate'] = {
                'encoded_nodes': encoded_sequences,
                'spatial_encoded': spatial_encoded_sequences,
                'temporal_sequences': temporal_sequences
            }
        
        return output


def test_model():
    """æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­"""
    from astra.data.adapter import GraphDataConverter, reconstruct_graph_from_json
    from pathlib import Path
    import json
    
    # æŸ¥æ‰¾å¯ç”¨çš„æµ‹è¯•æ–‡ä»¶ï¼ˆåœ¨ outputs ç›®å½•åŠå…¶å­ç›®å½•ä¸­é€’å½’æœç´¢ï¼‰
    output_dir = Path("outputs")
    test_file = None
    
    # ä¼˜å…ˆæŸ¥æ‰¾ Algorithm-Generated æ–‡ä»¶ï¼Œç„¶ååœ¨å­ç›®å½•ä¸­æœç´¢
    for pattern in ["Algorithm-Generated_*_graph.json", "Hand-Crafted_*_graph.json"]:
        # å…ˆåœ¨æ ¹ç›®å½•æŸ¥æ‰¾
        files = sorted(output_dir.glob(pattern))
        if not files:
            # å¦‚æœæ ¹ç›®å½•æ²¡æœ‰ï¼Œåœ¨å­ç›®å½•ä¸­é€’å½’æŸ¥æ‰¾
            files = sorted(output_dir.glob(f"**/{pattern}"))
        if files:
            test_file = files[0]
            break
    
    if test_file is None or not test_file.exists():
        print(f"æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·ç¡®ä¿ outputs ç›®å½•ï¼ˆæˆ–å…¶å­ç›®å½•ï¼‰ä¸‹æœ‰ Algorithm-Generated_*_graph.json æˆ– Hand-Crafted_*_graph.json æ–‡ä»¶")
        return
    
    print(f"ä½¿ç”¨æµ‹è¯•æ–‡ä»¶: {test_file}")
    
    with open(test_file, 'r', encoding='utf-8') as f:
        graph_data = json.load(f)
    
    # ä» JSON æ•°æ®é‡å»º DynamicGraphï¼ˆä¸å†ä½¿ç”¨ MainParserï¼‰
    graph = reconstruct_graph_from_json(graph_data)
    print(f"åŠ è½½çš„å›¾: {graph}")
    print(f"èŠ‚ç‚¹æ•°: {len(graph.nodes)}")
    print(f"è¾¹æ•°: {len(graph.edges)}")
    
    # æ•°æ®è½¬æ¢
    converter = GraphDataConverter(node_feat_dim=4096, edge_feat_dim=32)  # ğŸ”¥ ä¿®æ­£: 384 (æ–‡æœ¬) + 3712 (å…ƒæ•°æ®) = 4096
    converter.fit([graph])
    graph_list, labels = converter.convert(graph)
    
    print(f"\nè½¬æ¢ç»“æœ:")
    print(f"æ—¶é—´æ­¥æ•°: {len(graph_list)}")
    print(f"æ ‡ç­¾: {labels}")
    
    # æ£€æŸ¥æ‰€æœ‰å›¾ä¸­å­˜åœ¨çš„èŠ‚ç‚¹ç±»å‹
    all_node_types = set()
    for graph in graph_list:
        all_node_types.update(graph.get_node_types())
    print(f"\nå­˜åœ¨çš„èŠ‚ç‚¹ç±»å‹: {sorted(all_node_types)}")
    
    # æ˜¾ç¤ºæ¯ä¸ªæ—¶é—´æ­¥çš„èŠ‚ç‚¹ç±»å‹å’Œæ•°é‡
    for i, graph in enumerate(graph_list):
        print(f"  æ—¶é—´æ­¥ {i}: {[(nt, graph.num_nodes(nt)) for nt in graph.get_node_types()]}")
    
    # åˆ›å»ºæ¨¡å‹
    # è®¡ç®— Agent èŠ‚ç‚¹çš„æœ€å¤§æ•°é‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    agent_counts = [len(graph.node_features['Agent']) for graph in graph_list 
                    if 'Agent' in graph.node_features]
    
    if not agent_counts:
        print("\nâš ï¸  è­¦å‘Š: æ²¡æœ‰æ‰¾åˆ° 'Agent' èŠ‚ç‚¹ç±»å‹")
        print("   ä½¿ç”¨é»˜è®¤å€¼ num_classes=1")
        num_agents = 1
    else:
        num_agents = max(agent_counts)
        print(f"\nAgent èŠ‚ç‚¹æ•°é‡: {num_agents} (æœ€å¤§)")
    
    model = ASTRAMoE(
        node_feat_dim=4096,  # ğŸ”¥ ä¿®æ­£: 384 (æ–‡æœ¬) + 3712 (å…ƒæ•°æ®) = 4096
        edge_feat_dim=32,
        d_model=256,
        num_heads=8,
        num_hgt_layers=2,
        num_temporal_layers=2,
        num_experts=4,
        num_classes=num_agents,
        dropout=0.1,
        max_seq_len=len(graph_list)
    )
    
    print(f"\næ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    
    # å‰å‘ä¼ æ’­
    print("\nå¼€å§‹å‰å‘ä¼ æ’­...")
    output = model(graph_list)
    
    print(f"\nè¾“å‡ºå½¢çŠ¶:")
    print(f"  logits: {output['logits'].shape}")
    print(f"  alpha: {output['alpha'].shape}")
    print(f"  gate_weights: {output['gate_weights'].shape}")
    print(f"  load: {output['load'].shape}")
    
    print("\nâœ… æ¨¡å‹æµ‹è¯•é€šè¿‡ï¼")


if __name__ == "__main__":
    test_model()

