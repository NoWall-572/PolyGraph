"""
åŠ¨æ€å¼‚æ„å› æœå›¾ (DHCG) è§£æå™¨ - è¯­ä¹‰å¢å¼ºç‰ˆ
ç”¨äºè§£æ Who&When æ•°æ®é›†çš„ JSON æ—¥å¿—å¹¶æ„å»ºåŠ¨æ€å¼‚æ„å›¾
åŒ…å« Agent èº«ä»½åµŒå…¥ (Identity Embedding) ä»¥æå‡ Sim-to-Real æ³›åŒ–èƒ½åŠ›
æ”¯æŒå•ä¸ªæ–‡ä»¶å’Œç›®å½•æ‰¹é‡å¤„ç†
"""

import json
import re
import sys
import os
import argparse
from pathlib import Path
from typing import Dict, Any, List, Tuple, Optional
from collections import defaultdict

# åœ¨å¯¼å…¥torchç›¸å…³åº“ä¹‹å‰ç¦ç”¨CUDAï¼Œé¿å…å…¼å®¹æ€§é—®é¢˜
os.environ['CUDA_VISIBLE_DEVICES'] = ''  # ç¦ç”¨CUDA

from sentence_transformers import SentenceTransformer

# å…¨å±€æ¨¡å‹å®ä¾‹ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰
_model = None


def get_embedding_model():
    """è·å–æˆ–åˆå§‹åŒ–sentence-transformersæ¨¡å‹ï¼ˆå¼ºåˆ¶ä½¿ç”¨CPUï¼‰"""
    global _model
    if _model is None:
        model_name = 'sentence-transformers/bert-base-nli-mean-tokens'  # é»˜è®¤æ¨¡å‹åç§°
        try:
            # ğŸ”¥ ä¿®æ­£ 1: å°è¯•è®¾ç½®ç¯å¢ƒå˜é‡æˆ–ä½¿ç”¨é•œåƒ (å¦‚æœæ‚¨çš„ç¯å¢ƒæ”¯æŒ)
            # os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com' # ç¤ºä¾‹ï¼šä½¿ç”¨å›½å†…é•œåƒ
            
            # ğŸ”¥ ä¿®æ­£ 2: ä¼˜å…ˆä½¿ç”¨æœ¬åœ°ç¼“å­˜è·¯å¾„
            local_cache_path = Path.home() / '.cache/huggingface/hub/models--sentence-transformers--bert-base-nli-mean-tokens'
            if local_cache_path.exists():
                # å°è¯•æ‰¾åˆ°å®é™…çš„æ¨¡å‹æ–‡ä»¶è·¯å¾„
                snapshot_dirs = list(local_cache_path.glob('snapshots/*'))
                if snapshot_dirs:
                    model_name = str(snapshot_dirs[0])
                    print(f"âœ… ä½¿ç”¨æœ¬åœ°æ¨¡å‹ç¼“å­˜: {model_name}")
                else:
                    model_name = 'sentence-transformers/bert-base-nli-mean-tokens'
            else:
                model_name = 'sentence-transformers/bert-base-nli-mean-tokens'
            
            _model = SentenceTransformer(model_name, device='cpu')
        except Exception as e:
            # å¦‚æœä¸Šé¢çš„æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æ›´åŸºç¡€çš„æ¨¡å‹
            print(f"è­¦å‘Š: æ— æ³•åŠ è½½ {model_name}ï¼Œå°è¯•ä½¿ç”¨ all-MiniLM-L6-v2: {e}")
            try:
                local_cache_path_mini = Path.home() / '.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2'
                if local_cache_path_mini.exists():
                    snapshot_dirs_mini = list(local_cache_path_mini.glob('snapshots/*'))
                    if snapshot_dirs_mini:
                        model_name_mini = str(snapshot_dirs_mini[0])
                        print(f"âœ… ä½¿ç”¨æœ¬åœ°æ¨¡å‹ç¼“å­˜: {model_name_mini}")
                    else:
                        model_name_mini = 'all-MiniLM-L6-v2'
                else:
                    model_name_mini = 'all-MiniLM-L6-v2'
                     
                _model = SentenceTransformer(model_name_mini, device='cpu')
            except Exception as e2:
                print(f"é”™è¯¯: æ— æ³•åŠ è½½ä»»ä½•æ¨¡å‹: {e2}")
                raise
    return _model


class Node:
    """å›¾èŠ‚ç‚¹ç±»"""
    def __init__(self, node_id: str, node_type: str, creation_time: int, artifact_type: Optional[str] = None):
        self.id: str = node_id
        self.type: str = node_type  # e.g., "Agent", "Tool", "Artifact", "Environment"
        self.created_at: int = creation_time
        # features[t] å­˜å‚¨èŠ‚ç‚¹åœ¨æ—¶é—´æ­¥ t çš„åŠ¨æ€ç‰¹å¾
        self.features: Dict[int, Dict[str, Any]] = {}
        # artifact_type: ä»…å¯¹ArtifactèŠ‚ç‚¹æœ‰æ•ˆï¼Œå€¼ä¸º"file"æˆ–"url"
        self.artifact_type: Optional[str] = artifact_type

    def __repr__(self):
        artifact_info = f", artifact_type='{self.artifact_type}'" if self.artifact_type else ""
        return f"Node(id='{self.id}', type='{self.type}', created_at={self.created_at}{artifact_info})"


class Edge:
    """å›¾è¾¹ç±»"""
    def __init__(self, source_id: str, target_id: str, edge_type: str, timestamp: int, features: Dict[str, Any]):
        self.source: str = source_id
        self.target: str = target_id
        self.type: str = edge_type  # e.g., "Communicate", "Invoke", "Return", "Reference", "Affect"
        self.timestamp: int = timestamp
        self.features: Dict[str, Any] = features

    def __repr__(self):
        features_str = f", Features: {self.features}" if self.features else ""
        return f"Edge(t={self.timestamp}): {self.source} -> {self.target} (Type: {self.type}{features_str})"


class DynamicGraph:
    """åŠ¨æ€å¼‚æ„å›¾ç±»"""
    def __init__(self, question: str, ground_truth: Dict[str, Any]):
        self.question: str = question
        self.ground_truth: Dict[str, Any] = ground_truth
        self.nodes: Dict[str, Node] = {}  # Key: node_id
        self.edges: List[Edge] = []

    def add_node(self, node: Node):
        """æ·»åŠ èŠ‚ç‚¹åˆ°å›¾ä¸­"""
        if node.id not in self.nodes:
            self.nodes[node.id] = node

    def add_edge(self, edge: Edge):
        """æ·»åŠ è¾¹åˆ°å›¾ä¸­"""
        self.edges.append(edge)

    def __repr__(self):
        question_preview = self.question[:30] + "..." if len(self.question) > 30 else self.question
        return (f"DynamicGraph(\n"
                f"  Nodes: {len(self.nodes)},\n"
                f"  Edges: {len(self.edges)},\n"
                f"  Question: '{question_preview}'\n)")


def GetOrCreateNode(name: str, node_type: str, t: int, node_registry: Dict[str, Node], artifact_type: Optional[str] = None) -> Node:
    """
    è·å–æˆ–åˆ›å»ºèŠ‚ç‚¹
    """
    if name not in node_registry:
        # å¦‚æœæ˜¯ArtifactèŠ‚ç‚¹ï¼Œæ ¹æ®nameåˆ¤æ–­artifact_type
        if node_type == "Artifact" and artifact_type is None:
            if "http" in name.lower():
                artifact_type = "url"
            else:
                artifact_type = "file"
        node = Node(name, node_type, t, artifact_type=artifact_type)
        node_registry[name] = node
    return node_registry[name]


def DetermineNodeType(actor: str, system_prompt: Dict[str, Any], event: Dict[str, Any]) -> str:
    """
    ç¡®å®šèŠ‚ç‚¹çš„ç±»å‹
    
    ğŸ”¥ ASTRA-Gen 3.0 å¢å¼ºï¼š
    1. ä¸¥æ ¼åŒ¹é… Computer_terminalï¼ˆä¸‹åˆ’çº¿ï¼‰ä¸º Tool
    2. åŒ¹é… Coderã€Surfer ç­‰ Agent ç±»å‹
    """
    # å¼ºåˆ¶åŒ¹é… ASTRA-Gen 3.0 çš„å‘½åï¼šComputer_terminalï¼ˆä¸‹åˆ’çº¿ï¼‰
    if actor == "Computer_terminal":
        return "Tool"

    # å¦‚æœeventä¸­åŒ…å«exitcodeå­—æ®µï¼Œæˆ–è€…contentä¸­åŒ…å«"exitcode:"ï¼Œè¿”å›"Tool"
    if "exitcode" in event:
        return "Tool"
    content = event.get('content', '')
    if re.search(r'exitcode:\s*\d+', content, re.IGNORECASE):
        return "Tool"

    # å¦‚æœactoråœ¨system_promptçš„é”®ä¸­ï¼Œè¿”å›"Agent"
    if system_prompt and actor in system_prompt:
        return "Agent"

    # å¦‚æœactorçš„åå­—åŒ¹é…æ­£åˆ™è¡¨è¾¾å¼ï¼Œè¿”å›"Agent"
    # ğŸ”¥ å¢å¼ºï¼šåŒ¹é… ASTRA-Gen 3.0 çš„ Agent å‘½åï¼ˆCoderã€Surferã€Orchestratorç­‰ï¼‰
    if re.search(r'(Expert|Assistant|Orchestrator|Surfer|Coder|Planner)', actor):
        return "Agent"

    # é»˜è®¤è¿”å›"Agent" (å®½æ¾ç­–ç•¥ï¼Œé˜²æ­¢çœŸå®æ•°æ®ä¸­çš„æœªçŸ¥Agentè¢«æ¼åˆ¤)
    return "Agent"


def FindCallerAgent(tool_node: Node, t: int, history: List[Dict[str, Any]],
                   system_prompt: Dict[str, Any]) -> str:
    """
    æŸ¥æ‰¾è°ƒç”¨å·¥å…·çš„Agent
    """
    # ä»æ—¶é—´æ­¥ t-1 å¼€å§‹å‘ä¸Šå›æº¯
    for tau in range(t - 1, -1, -1):
        if tau < len(history):
            prev_event = history[tau]
            prev_actor = prev_event.get('name') or prev_event.get('role', '')
            prev_content = prev_event.get('content', '')

            # æ£€æŸ¥prev_actoræ˜¯å¦æ˜¯Agentç±»å‹
            actor_type = DetermineNodeType(prev_actor, system_prompt, prev_event)
            if actor_type == "Agent":
                # æ£€æŸ¥prev_contentæ˜¯å¦åŒ…å«ä»£ç å—ï¼ˆè¡¨ç¤ºè°ƒç”¨äº†å·¥å…·ï¼‰
                code_block_pattern = r'```(?:python|sh|bash|javascript|js|java|cpp|c\+\+|c|go|rust|sql|html|css|xml|json|yaml|yml|markdown|md|text|plaintext)[\s\S]*?```'
                if re.search(code_block_pattern, prev_content, re.IGNORECASE):
                    return prev_actor

    return "Broadcast"


def ParseEdges(source_node: Node, content: str, t: int, history: List[Dict[str, Any]],
               node_registry: Dict[str, Node], event: Dict[str, Any], system_prompt: Dict[str, Any],
               mention_counter: Dict[str, int]) -> List[Tuple[str, str, str, Dict[str, Any]]]:
    """
    è§£æè¾¹
    """
    interactions = []

    # 1. Invoke: å¦‚æœsource_node.type == "Agent" å¹¶ä¸”contentåŒ…å«ä»£ç å—
    if source_node.type == "Agent":
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä»£ç å—
        code_block_pattern = r'```(?:python|sh|bash|javascript|js|java|cpp|c\+\+|c|go|rust|sql|html|css|xml|json|yaml|yml|markdown|md|text|plaintext)[\s\S]*?```'
        if re.search(code_block_pattern, content, re.IGNORECASE):
            interactions.append(("Computer_terminal", "Tool", "Invoke", {"intent": "Command"}))

    # 2. Return: å¦‚æœsource_node.type == "Tool"
    if source_node.type == "Tool":
        exitcode = None
        if "exitcode" in event:
            exitcode = event.get("exitcode")
        else:
            exitcode_match = re.search(r'exitcode:\s*(\d+)', content, re.IGNORECASE)
            if exitcode_match:
                exitcode = exitcode_match.group(1)

        status = "unknown"
        if exitcode is not None:
            # å°è¯•è½¬æ¢ä¸ºæ•´æ•°åˆ¤æ–­
            try:
                status = "success" if int(str(exitcode)) == 0 else "failure"
            except:
                pass

        # Returnè¾¹çš„æ„å›¾å›ºå®šä¸º"Inform"
        caller_agent = FindCallerAgent(source_node, t, history, system_prompt)
        interactions.append((caller_agent, "Agent", "Return", {"status": status, "intent": "Inform"}))

    # 3. Reference: æå–æ–‡ä»¶è·¯å¾„å’ŒURL
    reference_pattern = r'(\.\./[\w/.-]+|https?://[\w/.-]+|filename:\s*[\w.-]+)'
    references = re.findall(reference_pattern, content)
    references = list(set(references))

    for ref in references:
        ref_clean = ref.strip().rstrip('.,;:')
        if ref_clean.startswith("filename:"):
            ref_clean = ref_clean.replace("filename:", "").strip().rstrip('.,;:')

        mention_counter[ref_clean] += 1
        interactions.append((ref_clean, "Artifact", "Reference", {"intent": "Inform"}))

    # 4. Communicate
    mention_pattern = r'@(\w+)'
    mentions = re.findall(mention_pattern, content)

    intent = "Inform"
    if mentions:
        if '?' in content or content.strip().startswith('@'):
            intent = "Query"
        for mention in mentions:
            interactions.append((mention, "Agent", "Communicate", {"intent": intent}))
    else:
        if t > 0 and t - 1 < len(history):
            prev_event = history[t - 1]
            prev_actor = prev_event.get('name') or prev_event.get('role', '')
            if prev_actor != source_node.id:
                if not re.search(r'```[\s\S]*?```', content):
                    if '?' in content: intent = "Query"
                    interactions.append((prev_actor, "Agent", "Communicate", {"intent": intent}))
                else:
                    intent = "Broadcast"
                    interactions.append(("Broadcast", "Environment", "Communicate", {"intent": intent}))
            else:
                intent = "Broadcast"
                interactions.append(("Broadcast", "Environment", "Communicate", {"intent": intent}))
        else:
            intent = "Broadcast"
            interactions.append(("Broadcast", "Environment", "Communicate", {"intent": intent}))

    # 5. Affect
    error_pattern = r'(Timeout|OOM|Permission Denied|Network Error)'
    error_match = re.search(error_pattern, content, re.IGNORECASE)
    if error_match:
        event_type = error_match.group(1).lower()
        interactions.append(("__AFFECT__", "Environment", "Affect", {"intent": "Reject", "event_type": event_type}))

    return interactions


def ExtractNodeFeatures(source_node: Node, event: Dict[str, Any], t: int, history: List[Dict[str, Any]],
                        mention_counter: Dict[str, int], system_prompt: Dict[str, Any], env_event_type: Optional[str] = None) -> Dict[str, Any]:
    """
    æå–èŠ‚ç‚¹ç‰¹å¾ (è¯­ä¹‰å¢å¼ºç‰ˆ)

    ğŸ”¥ æ ¸å¿ƒæ”¹è¿›ï¼š
    1. æ¥æ”¶ system_prompt å‚æ•°
    2. å¦‚æœæ˜¯ Agent èŠ‚ç‚¹ï¼Œå°† Agent Name å’Œ Role Description æ‹¼æ¥åˆ° Content å‰é¢
    3. ç”Ÿæˆå¯Œè¯­ä¹‰ Embedding
    """
    features = {}
    content = event.get('content', '')

    model = get_embedding_model()

    # --- èº«ä»½åµŒå…¥é€»è¾‘å¼€å§‹ ---
    if source_node.type == "Agent":
        agent_name = source_node.id
        # å°è¯•ä» system_prompt è·å–è§’è‰²æè¿°
        # æœ‰äº›æ•°æ®é›† system_prompt å¯èƒ½æ˜¯ dictï¼Œæœ‰äº›å¯èƒ½æ˜¯ listï¼Œè¿™é‡Œåšä¸ªé˜²å¾¡
        role_desc = ""
        if isinstance(system_prompt, dict):
            role_desc = system_prompt.get(agent_name, "")

        # æ„é€ å¯Œæ–‡æœ¬ï¼š[èº«ä»½] + [æè¿°] + [å½“å‰åŠ¨ä½œ]
        rich_text = f"Agent: {agent_name}. Role: {role_desc}.\nAction: {content}"

        # æˆªæ–­é˜²æ­¢è¿‡é•¿ (BERTé€šå¸¸é™åˆ¶512 tokensï¼Œè¿™é‡ŒæŒ‰å­—ç¬¦æˆªæ–­åšä¸ªå¤§è‡´é™åˆ¶)
        if len(rich_text) > 2000:
            rich_text = rich_text[:2000]
    else:
        # å¯¹äº Tool æˆ– Artifactï¼Œåªçœ‹å†…å®¹
        rich_text = content
    # --- èº«ä»½åµŒå…¥é€»è¾‘ç»“æŸ ---

    # ä½¿ç”¨å¯Œæ–‡æœ¬ç”Ÿæˆ Embedding
    embedding = model.encode(rich_text, convert_to_numpy=True).tolist()
    features['content_embedding'] = embedding

    # [æ–°å¢] ç»“æ„åŒ– Ledger è§£æï¼ˆASTRA-Gen 3.0 å¢å¼ºï¼‰
    # é’ˆå¯¹ Orchestrator (thought) çš„ JSON Ledger æå–æ˜¾å¼ç‰¹å¾
    # èŠ‚ç‚¹åç§°æ ¼å¼ï¼šOrchestrator (thought)
    if source_node.type == "Agent" and "thought" in source_node.id.lower() and "{" in content:
        try:
            # å°è¯•æå– JSON Ledger
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                ledger = json.loads(json_match.group(0))
                # æå–ç‰¹å¾ 1: Agent è‡ªè®¤ä¸ºæ˜¯å¦å®Œæˆä»»åŠ¡ (0.0/1.0)
                is_satisfied = ledger.get("is_request_satisfied", {})
                if isinstance(is_satisfied, dict):
                    features['satisfied_signal'] = 1.0 if is_satisfied.get("answer") else 0.0
                else:
                    features['satisfied_signal'] = 1.0 if is_satisfied else 0.0
                
                # æå–ç‰¹å¾ 2: å½“å‰è®¡åˆ’çš„æ­¥æ•° (åæ˜ ä»»åŠ¡å¤æ‚åº¦)
                plan = ledger.get("plan", [])
                features['plan_length'] = float(len(plan))
        except (json.JSONDecodeError, KeyError, AttributeError):
            # è§£æå¤±è´¥å°±å¿½ç•¥ï¼Œä¸å½±å“ä¸»æµç¨‹
            pass

    # 2. Toolç‰¹å¾ï¼ˆASTRA-Gen 3.0 å¢å¼ºï¼šä½¿ç”¨æ•°å€¼çŠ¶æ€ï¼‰
    if source_node.type == "Tool":
        exitcode = None
        if "exitcode" in event:
            exitcode = event.get("exitcode")
        else:
            # æ³¨æ„ä¸‹åˆ’çº¿åŒ¹é… Computer_terminal
            if "Computer_terminal" in source_node.id or "exitcode:" in content:
                exitcode_match = re.search(r'exitcode:\s*(\d+)', content, re.IGNORECASE)
                if exitcode_match:
                    exitcode = exitcode_match.group(1)

        # ğŸ”¥ ä¼˜åŒ–ï¼šä½¿ç”¨æ•°å€¼çŠ¶æ€ï¼ˆ1.0=Success, -1.0=Fail, 0.0=Unknownï¼‰
        if exitcode is not None:
            try:
                exitcode_int = int(str(exitcode))
                if exitcode_int == 0:
                    features['tool_status'] = 1.0  # Success
                else:
                    features['tool_status'] = -1.0  # Fail
            except (ValueError, TypeError):
                features['tool_status'] = 0.0  # Unknown
        else:
            features['tool_status'] = 0.0  # Unknown
        
        # ä¿ç•™åŸæœ‰çš„ exitcode_status å­—ç¬¦ä¸²æ ¼å¼ï¼ˆå‘åå…¼å®¹ï¼‰
        status = "unknown"
        if exitcode is not None:
            try:
                status = "success" if int(str(exitcode)) == 0 else "failure"
            except:
                pass
        features['exitcode_status'] = status

    # 3. Agentç‰¹å¾
    if source_node.type == "Agent":
        features['is_terminate'] = "TERMINATE" in content.upper()
        features['plan_signal'] = bool(re.search(r'\b(Plan|Step)\b', content, re.IGNORECASE))

        count = 0
        for i in range(t + 1):
            if i < len(history):
                event_i = history[i]
                actor_name = event_i.get('name') or event_i.get('role', '')
                if actor_name == source_node.id:
                    count += 1
        features['active_ratio'] = count / (t + 1) if t >= 0 else 0.0

    # 4. Artifactç‰¹å¾
    if source_node.type == "Artifact":
        if source_node.artifact_type:
            features['artifact_type'] = source_node.artifact_type
        else:
            if "http" in source_node.id.lower():
                features['artifact_type'] = "url"
            else:
                features['artifact_type'] = "file"
        features['mention_count'] = mention_counter.get(source_node.id, 0)

    # 5. Environmentç‰¹å¾
    if source_node.type == "Environment":
        if env_event_type:
            features['env_event_type'] = env_event_type

    return features


def MainParser(json_data: Dict[str, Any]) -> DynamicGraph:
    """
    ä¸»è§£æå‡½æ•°

    ğŸ”¥ ä¿®æ”¹ï¼šåœ¨è°ƒç”¨ ExtractNodeFeatures æ—¶ä¼ å…¥ system_prompt
    """
    question = json_data.get('question', '')
    ground_truth = {
        'mistake_agent': json_data.get('mistake_agent', ''),
        'mistake_step': json_data.get('mistake_step', ''),
        'mistake_reason': json_data.get('mistake_reason', ''),
        'ground_truth': json_data.get('ground_truth', '')
    }
    graph = DynamicGraph(question, ground_truth)
    node_registry = graph.nodes

    GetOrCreateNode("Broadcast", "Environment", -1, node_registry)
    GetOrCreateNode("Env", "Environment", -1, node_registry)

    history = json_data.get('history', [])
    system_prompt = json_data.get('system_prompt', {})

    mention_counter = defaultdict(int)

    for t in range(len(history)):
        event = history[t]
        actor_name = event.get('name') or event.get('role', '')

        actor_type = DetermineNodeType(actor_name, system_prompt, event)
        source_node = GetOrCreateNode(actor_name, actor_type, t, node_registry)

        content = event.get('content', '')
        interactions = ParseEdges(source_node, content, t, history, node_registry, event, system_prompt, mention_counter)

        current_env_event_type = None

        for target_name, target_type, edge_type, edge_features in interactions:
            if edge_type == "Affect" and target_name == "__AFFECT__":
                env_node = GetOrCreateNode("Env", "Environment", -1, node_registry)
                if "event_type" in edge_features:
                    current_env_event_type = edge_features["event_type"]
                edge = Edge(env_node.id, source_node.id, edge_type, t, edge_features)
                graph.add_edge(edge)
            else:
                artifact_type = None
                if target_type == "Artifact":
                    if "http" in target_name.lower():
                        artifact_type = "url"
                    else:
                        artifact_type = "file"
                target_node = GetOrCreateNode(target_name, target_type, t, node_registry, artifact_type=artifact_type)
                edge = Edge(source_node.id, target_node.id, edge_type, t, edge_features)
                graph.add_edge(edge)

        env_event_type_for_features = current_env_event_type if source_node.id == "Env" and current_env_event_type else None

        # ğŸ”¥ è¿™é‡Œä¼ å…¥äº† system_prompt
        node_features = ExtractNodeFeatures(
            source_node, event, t, history, mention_counter,
            system_prompt, # æ–°å¢å‚æ•°
            env_event_type_for_features
        )
        source_node.features[t] = node_features

    return graph


def process_single_file(json_file: Path, verbose: bool = True, save_result: bool = False, output_dir: Optional[Path] = None, source_dir_name: Optional[str] = None) -> Optional[DynamicGraph]:
    """å¤„ç†å•ä¸ªJSONæ–‡ä»¶"""
    try:
        if verbose:
            print(f"Processing: {json_file.name}...")

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not json_file.exists():
            if verbose:
                print(f"  âœ— Error: File '{json_file}' does not exist.")
            return None

        # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡ä»¶ï¼ˆè€Œä¸æ˜¯ç›®å½•ï¼‰
        if not json_file.is_file():
            if verbose:
                print(f"  âœ— Error: '{json_file}' is not a file.")
            return None

        with open(json_file, 'r', encoding='utf-8') as f:
            json_data = json.load(f)

        graph = MainParser(json_data)

        if verbose:
            print(f"  âœ“ Success: {len(graph.nodes)} nodes, {len(graph.edges)} edges")

        if save_result and output_dir:
            output_dir.mkdir(parents=True, exist_ok=True)
            if source_dir_name:
                safe_dir_name = source_dir_name.replace('/', '_').replace('\\', '_').replace('&', '_')
                output_file = output_dir / f"{safe_dir_name}_{json_file.stem}_graph.json"
            else:
                output_file = output_dir / f"{json_file.stem}_graph.json"

            graph_dict = {
                'question': graph.question,
                'ground_truth': graph.ground_truth,
                'nodes': {},
                'edges': []
            }

            for node_id, node in graph.nodes.items():
                graph_dict['nodes'][node_id] = {
                    'id': node.id,
                    'type': node.type,
                    'created_at': node.created_at,
                    'features': {str(t): features for t, features in node.features.items()}
                }

            for edge in graph.edges:
                graph_dict['edges'].append({
                    'source': edge.source,
                    'target': edge.target,
                    'type': edge.type,
                    'timestamp': edge.timestamp,
                    'features': edge.features
                })

            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(graph_dict, f, ensure_ascii=False, indent=2)

            if verbose:
                print(f"  âœ“ Saved to: {output_file}")

        return graph

    except FileNotFoundError:
        if verbose: print(f"  âœ— Error: File '{json_file}' not found.")
        return None
    except json.JSONDecodeError as e:
        if verbose: print(f"  âœ— Error: Invalid JSON format in '{json_file}': {e}")
        return None
    except Exception as e:
        if verbose: print(f"  âœ— Error: {type(e).__name__}: {e}")
        return None


def process_directory(directory: Path, verbose: bool = True, save_result: bool = False, output_dir: Optional[Path] = None) -> Dict[str, Any]:
    """æ‰¹é‡å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰JSONæ–‡ä»¶ï¼Œæ”¯æŒè·³è¿‡å·²è§£æçš„æ–‡ä»¶"""
    json_files = sorted(directory.glob("*.json"))

    if not json_files:
        return {'total': 0, 'success': 0, 'failed': 0, 'skipped': 0, 'files': []}

    # ğŸ”¥ æ£€æŸ¥å·²è§£æçš„æ–‡ä»¶ (ç”¨äºè·³è¿‡)
    processed_count = 0
    files_to_process = []
    source_dir_name = directory.name

    if save_result and output_dir:
        # æ¨æ–­è¾“å‡ºæ–‡ä»¶åæ ¼å¼ï¼ˆä¸ process_single_file ä¸­çš„ä¿å­˜é€»è¾‘åŒæ­¥ï¼‰
        safe_dir_name = source_dir_name.replace('/', '_').replace('\\', '_').replace('&', '_')
        
        for json_file in json_files:
            output_file_name = f"{safe_dir_name}_{json_file.stem}_graph.json"
            output_file_path = output_dir / output_file_name
            
            if output_file_path.exists():
                processed_count += 1
                continue
            
            files_to_process.append(json_file)
    else:
        # å¦‚æœæ²¡æœ‰è¾“å‡ºç›®å½•æˆ–ä¸éœ€è¦ä¿å­˜ï¼Œå¤„ç†æ‰€æœ‰æ–‡ä»¶
        files_to_process = json_files

    print(f"\nFound {len(json_files)} JSON files in: {directory}")
    if processed_count > 0:
        print(f"â­ï¸  Skipping {processed_count} already parsed files.")
    if len(files_to_process) > 0:
        print(f"ğŸ“ Processing {len(files_to_process)} files...")
    print("=" * 60)

    results = {
        'total': len(json_files),
        'success': 0,
        'failed': 0,
        'skipped': processed_count,
        'files': []
    }

    # å¤„ç†éœ€è¦è§£æçš„æ–‡ä»¶
    for i, json_file in enumerate(files_to_process, 1):
        if verbose:
            print(f"\n[{i}/{len(files_to_process)}] ", end="")

        graph = process_single_file(json_file, verbose=verbose, save_result=save_result, output_dir=output_dir, source_dir_name=source_dir_name)

        if graph is not None:
            results['success'] += 1
            results['files'].append({'file': str(json_file), 'status': 'success'})
        else:
            results['failed'] += 1
            results['files'].append({'file': str(json_file), 'status': 'failed'})

    print("\n" + "=" * 60)
    if results['skipped'] > 0:
        print(f"Processing Complete! Total: {results['total']}, Success: {results['success']}, Failed: {results['failed']}, Skipped: {results['skipped']}")
    else:
        print(f"Processing Complete! Total: {results['total']}, Success: {results['success']}, Failed: {results['failed']}")
    print("=" * 60)

    return results


def main():
    """ä¸»æ‰§è¡Œå‡½æ•°"""
    parser = argparse.ArgumentParser(description='DHCG Parser')
    parser.add_argument('input_path', type=str)
    parser.add_argument('--save', action='store_true')
    parser.add_argument('--output', type=str, default='outputs')
    parser.add_argument('--quiet', action='store_true')

    args = parser.parse_args()
    input_path = Path(args.input_path)

    if not input_path.exists():
        script_dir = Path(__file__).parent
        project_root = script_dir.parent
        alternative_path = project_root / args.input_path
        if alternative_path.exists():
            input_path = alternative_path
        else:
            print(f"Error: Path '{args.input_path}' does not exist.")
            sys.exit(1)

    if input_path.is_file():
        if not input_path.suffix == '.json':
            sys.exit(1)
        output_dir = Path(args.output) if args.save else None
        source_dir_name = input_path.parent.name if input_path.parent.name else None
        process_single_file(input_path, verbose=not args.quiet, save_result=args.save, output_dir=output_dir, source_dir_name=source_dir_name)

    elif input_path.is_dir():
        output_dir = Path(args.output) if args.save else None
        process_directory(input_path, verbose=not args.quiet, save_result=args.save, output_dir=output_dir)

    else:
        sys.exit(1)


if __name__ == "__main__":
    main()