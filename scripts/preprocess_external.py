#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°†AgenTracerçš„TracerTrajæ•°æ®é›†è½¬æ¢ä¸ºæˆ‘ä»¬çš„HeteroGraphæ ¼å¼

è¾“å…¥ï¼šAgenTracerçš„parquet/jsonlæ ¼å¼
è¾“å‡ºï¼šæˆ‘ä»¬çš„graph JSONæ ¼å¼ï¼ˆåŒ…å«domainå­—æ®µï¼‰

æ•°æ®å­—æ®µï¼š
- trajectory: äº¤äº’æ—¥å¿—
- mistake_agent: æ•…éšœAgentï¼ˆGTï¼‰
- mistake_step: æ•…éšœStepï¼ˆGTï¼‰
- domain: Code/Math/Agenticï¼ˆç”¨äºåˆ†ç±»è¯„ä¼°ï¼‰
"""

# ğŸ”¥ å…³é”®ä¿®å¤ï¼šWindows GBKç¼–ç é—®é¢˜
import sys
import io
# è®¾ç½®æ ‡å‡†è¾“å‡ºä¸ºUTF-8ç¼–ç ï¼ˆé¿å…Windows GBKç¼–ç é—®é¢˜ï¼‰
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

import json
import pandas as pd
from pathlib import Path
from typing import Dict, Any, List, Optional
from tqdm import tqdm
import argparse
import random
import csv
import ast
import re

# ğŸ”¥ å…³é”®ä¿®å¤ï¼šå¢åŠ CSVå­—æ®µå¤§å°é™åˆ¶ï¼Œé˜²æ­¢å¤„ç†é•¿Contextæ—¶æŠ¥é”™
try:
    csv.field_size_limit(sys.maxsize)
except OverflowError:
    csv.field_size_limit(2147483647)  # é’ˆå¯¹æŸäº›ç³»ç»Ÿçš„å…¼å®¹å†™æ³•
import csv
import sys

# ğŸ”¥ å…³é”®ä¿®å¤ï¼šå¢åŠ CSVå­—æ®µå¤§å°é™åˆ¶ï¼Œé˜²æ­¢å¤„ç†é•¿Contextæ—¶æŠ¥é”™
try:
    csv.field_size_limit(sys.maxsize)
except OverflowError:
    csv.field_size_limit(2147483647)  # é’ˆå¯¹æŸäº›ç³»ç»Ÿçš„å…¼å®¹å†™æ³•

# å¯¼å…¥æˆ‘ä»¬çš„è§£æå™¨
try:
    from astra.parsing.dhcg_parser.parser_gpu import MainParser
    HAS_MAIN_PARSER = True
except ImportError:
    try:
        from astra.parsing.dhcg_parser.parser_gpu import parse_log_to_dynamic_graph
        HAS_MAIN_PARSER = False
    except ImportError:
        print("[è­¦å‘Š] æ— æ³•å¯¼å…¥è§£æå™¨å‡½æ•°")
        HAS_MAIN_PARSER = None

# ğŸ”¥ å…³é”®ä¿®å¤ï¼šè®¾ç½®ç¯å¢ƒå˜é‡ï¼Œæ§åˆ¶æ¨¡å‹åŠ è½½æ–¹å¼
import os
FORCE_CPU_MODE = os.getenv("FORCE_CPU", "").lower() in ["true", "1", "yes"]
USE_8BIT_QUANT = os.getenv("USE_8BIT", "true").lower() in ["true", "1", "yes"]

# ============================================================================
# ğŸ”¥ V4ç‰ˆæœ¬ï¼šåŸºäºæ ˆçš„æœ€å¤§åˆ—è¡¨æå–æ³•ï¼ˆè§£å†³CSVæ ¼å¼é”™ä¹±é—®é¢˜ï¼‰
# ============================================================================

def extract_longest_list_string(text: str) -> Optional[str]:
    """
    æ ¸å¿ƒç®—æ³•ï¼šåŸºäºæ ˆæ¥æå–å­—ç¬¦ä¸²ä¸­æœ€é•¿çš„ [...] ç»“æ„
    ä¸ä¾èµ– CSV åˆ†éš”ç¬¦ï¼Œç›´æ¥ä»ä¹±ç ä¸­æŠ“å–æœ€å¤§çš„ JSON/List å—
    
    Args:
        text: åŸå§‹æ–‡æœ¬è¡Œ
        
    Returns:
        æœ€é•¿çš„åˆ—è¡¨å­—ç¬¦ä¸²ï¼Œå¦‚æœæ‰¾ä¸åˆ°è¿”å›None
    """
    if not text or not isinstance(text, str):
        return None
    
    candidates = []
    stack = []
    
    for i, char in enumerate(text):
        if char == '[':
            stack.append(i)
        elif char == ']':
            if stack:
                start_index = stack.pop()
                # å¦‚æœæ ˆç©ºäº†ï¼Œè¯´æ˜é—­åˆäº†ä¸€ä¸ªæœ€å¤–å±‚çš„åˆ—è¡¨
                if not stack:
                    candidate = text[start_index : i+1]
                    candidates.append(candidate)
    
    if not candidates:
        return None
    
    # è¿”å›æœ€é•¿çš„é‚£ä¸ªå€™é€‰å­—ç¬¦ä¸²ï¼ˆHistory è‚¯å®šæ˜¯æœ€é•¿çš„ï¼‰
    return max(candidates, key=len)


def safe_eval_history(hist_str: str) -> List:
    """
    æå…¶å®½å®¹çš„è§£æå™¨ï¼Œå°è¯•å¤šç§æ–¹æ³•å°†å­—ç¬¦ä¸²è½¬ä¸º List
    
    Args:
        hist_str: historyå­—ç¬¦ä¸²
        
    Returns:
        è§£æåçš„åˆ—è¡¨ï¼Œå¦‚æœå¤±è´¥è¿”å›ç©ºåˆ—è¡¨
    """
    if not hist_str or not isinstance(hist_str, str):
        return []
    
    hist_str = hist_str.strip()
    if not hist_str or hist_str.lower() in ['nan', 'none', 'null', '']:
        return []
    
    # 1. é¢„å¤„ç†ï¼šä¿®å¤ Python 3.12 åæ–œæ é—®é¢˜
    try:
        # ç®€å•æš´åŠ›çš„ä¿®å¤ï¼šæŠŠæ‰€æœ‰ \ å˜æˆ \\ï¼Œç„¶åå†æŠŠæœ‰æ•ˆè½¬ä¹‰å˜å›
        clean_str = hist_str.replace('\\', '\\\\')
        clean_str = clean_str.replace('\\\\n', '\\n').replace('\\\\t', '\\t')
        clean_str = clean_str.replace('\\\\r', '\\r').replace('\\\\b', '\\b')
        clean_str = clean_str.replace('\\\\f', '\\f')
        clean_str = clean_str.replace('\\\\"', '\\"').replace("\\\\'", "\\'")
        clean_str = clean_str.replace('\\\\\\\\', '\\\\')  # ä¿ç•™çœŸæ­£çš„åæ–œæ 
        return ast.literal_eval(clean_str)
    except:
        pass

    # 2. åŸå§‹å°è¯•
    try:
        return ast.literal_eval(hist_str)
    except:
        pass

    # 3. å°è¯• JSON
    try:
        return json.loads(hist_str)
    except:
        pass
    
    # 4. å°è¯•ä¿®å¤å¸¸è§çš„Python/JSONå·®å¼‚
    try:
        fixed_str = hist_str.replace('null', 'None').replace('true', 'True').replace('false', 'False')
        return ast.literal_eval(fixed_str)
    except:
        pass
    
    return []


def normalize_history_item(item: Any) -> Optional[Dict]:
    """
    å°† history ä¸­çš„å•é¡¹ï¼ˆå¯èƒ½æ˜¯ tuple, dict, æˆ– listï¼‰ç»Ÿä¸€è½¬ä¸º dict
    é˜²æ­¢ 'int' object has no attribute 'get' é”™è¯¯
    
    Args:
        item: historyä¸­çš„å•ä¸ªå…ƒç´ 
        
    Returns:
        è§„èŒƒåŒ–åçš„å­—å…¸ï¼Œå¦‚æœæ— æ³•è½¬æ¢è¿”å›None
    """
    # å¦‚æœæ˜¯int/float/boolç­‰åŸºæœ¬ç±»å‹ï¼Œç›´æ¥è¿”å›Noneï¼ˆæ— æ•ˆæ•°æ®ï¼‰
    if isinstance(item, (int, float, bool, type(None))):
        return None
    
    if isinstance(item, dict):
        # å¿…é¡»åŒ…å« content å’Œ agent/name/role
        result = dict(item)  # å¤åˆ¶å­—å…¸
        
        # ç¡®ä¿æœ‰contentå­—æ®µ
        if 'content' not in result:
            result['content'] = result.get('message', result.get('text', ''))
        
        # ç¡®ä¿æœ‰agent/nameå­—æ®µ
        if 'agent' not in result and 'name' not in result:
            result['agent'] = result.get('role', 'Unknown')
            result['name'] = result.get('agent', 'Unknown')
        elif 'agent' not in result:
            result['agent'] = result.get('name', result.get('role', 'Unknown'))
        elif 'name' not in result:
            result['name'] = result.get('agent', result.get('role', 'Unknown'))
        
        # ç¡®ä¿æœ‰roleå­—æ®µ
        if 'role' not in result:
            result['role'] = result.get('agent', result.get('name', 'assistant'))
        
        return result
    
    if isinstance(item, (list, tuple)):
        # å¤„ç†å…ƒç»„æ ¼å¼: (Content, Agent, Role, Step)
        # æˆ–è€…æ˜¯: (Content, Agent)
        if len(item) >= 2:
            return {
                'content': str(item[0]) if len(item) > 0 else '',
                'agent': str(item[1]) if len(item) > 1 else 'Unknown',
                'name': str(item[1]) if len(item) > 1 else 'Unknown',
                'role': str(item[2]) if len(item) > 2 else 'assistant',
                'step': item[3] if len(item) > 3 else 0
            }
    
    # å…¶ä»–ç±»å‹ï¼ˆå¦‚å­—ç¬¦ä¸²ï¼‰å°è¯•åŒ…è£…ä¸ºå­—å…¸
    if isinstance(item, str):
        return {
            'content': item,
            'agent': 'Unknown',
            'name': 'Unknown',
            'role': 'assistant',
            'step': 0
        }
    
    return None


# ğŸ”¥ å…³é”®ä¿®å¤ï¼šä¸‰æ˜æ²»è§£ææ³• - ä»CSVè¡Œä¸­æå–å­—æ®µ
def sandwich_parse_csv_line(line: str) -> Optional[Dict[str, Any]]:
    """
    ä¸‰æ˜æ²»è§£ææ³•ï¼šä»è¢«é€—å·ç‚¸å¼€çš„CSVè¡Œä¸­æå–å­—æ®µ
    
    å‡è®¾æ ¼å¼ï¼šquestion, ground_truth, history[...], mistake_agent, mistake_step
    ç”±äºhistoryåŒ…å«å¤§é‡é€—å·ï¼Œpandasä¼šé”™è¯¯åˆ†å‰²ï¼Œæˆ‘ä»¬æ‰‹åŠ¨æå–ï¼š
    - å¼€å¤´æ˜¯question
    - ç»“å°¾æ˜¯mistake_agent, mistake_step
    - ä¸­é—´ç¬¬ä¸€ä¸ª[åˆ°æœ€åä¸€ä¸ª]æ˜¯history
    """
    if not line or not line.strip():
        return None
    
    line = line.strip()
    
    # 1. æ‰¾åˆ°historyçš„è¾¹ç•Œï¼ˆç¬¬ä¸€ä¸ª[å’Œæœ€åä¸€ä¸ª]ï¼‰
    start_bracket = line.find('[')
    end_bracket = line.rfind(']')
    
    if start_bracket == -1 or end_bracket == -1 or end_bracket <= start_bracket:
        # æ²¡æœ‰æ‰¾åˆ°historyè¾¹ç•Œï¼Œå°è¯•å…¶ä»–æ–¹æ³•
        return None
    
    # 2. æå–historyå­—ç¬¦ä¸²
    history_str = line[start_bracket:end_bracket+1]
    
    # 3. æå–questionï¼ˆç¬¬ä¸€ä¸ªé€—å·ä¹‹å‰ï¼Œä½†å¯èƒ½åŒ…å«å¼•å·ï¼‰
    question_part = line[:start_bracket].strip()
    # ç§»é™¤å¯èƒ½çš„å¼•å·
    if question_part.startswith('"') and question_part.endswith('"'):
        question_part = question_part[1:-1]
    elif question_part.startswith("'") and question_part.endswith("'"):
        question_part = question_part[1:-1]
    
    # æŒ‰é€—å·åˆ†å‰²ï¼Œå–ç¬¬ä¸€éƒ¨åˆ†ä½œä¸ºquestion
    question_parts = question_part.split(',')
    question = question_parts[0].strip() if question_parts else ''
    
    # 4. æå–mistake_agentå’Œmistake_stepï¼ˆæœ€åä¸€ä¸ª]ä¹‹åçš„éƒ¨åˆ†ï¼‰
    tail_part = line[end_bracket+1:].strip()
    tail_parts = [p.strip() for p in tail_part.split(',') if p.strip()]
    
    mistake_agent = 'Unknown'
    mistake_step = -1
    
    if len(tail_parts) >= 2:
        # å€’æ•°ç¬¬äºŒä¸ªæ˜¯mistake_agentï¼Œæœ€åä¸€ä¸ªæ˜¯mistake_step
        mistake_agent = tail_parts[-2]
        try:
            mistake_step = int(float(tail_parts[-1]))
        except:
            mistake_step = -1
    elif len(tail_parts) == 1:
        # åªæœ‰ä¸€ä¸ªï¼Œå¯èƒ½æ˜¯mistake_step
        try:
            mistake_step = int(float(tail_parts[0]))
        except:
            pass
    
    # 5. è§£æhistory
    try:
        history = clean_and_parse_history(history_str)
    except:
        history = []
    
    if not history:
        return None
    
    return {
        'question': question,
        'ground_truth': '',  # ground_truthå­—æ®µå¯èƒ½ä¹ŸåŒ…å«é€—å·ï¼Œæš‚æ—¶å¿½ç•¥
        'history': history,
        'mistake_agent': mistake_agent,
        'mistake_step': mistake_step
    }


# ğŸ”¥ V4ç‰ˆæœ¬ï¼šåŸºäºæ ˆçš„æœ€å¤§åˆ—è¡¨æå–æ³•
def extract_longest_list_string(text: str) -> Optional[str]:
    """
    æ ¸å¿ƒç®—æ³•ï¼šåŸºäºæ ˆæ¥æå–å­—ç¬¦ä¸²ä¸­æœ€é•¿çš„ [...] ç»“æ„
    ä¸ä¾èµ– CSV åˆ†éš”ç¬¦ï¼Œç›´æ¥ä»ä¹±ç ä¸­æŠ“å–æœ€å¤§çš„ JSON/List å—
    
    Args:
        text: åŸå§‹æ–‡æœ¬è¡Œ
        
    Returns:
        æœ€é•¿çš„åˆ—è¡¨å­—ç¬¦ä¸²ï¼Œå¦‚æœæ‰¾ä¸åˆ°è¿”å›None
    """
    if not text or not isinstance(text, str):
        return None
    
    candidates = []
    stack = []
    
    for i, char in enumerate(text):
        if char == '[':
            stack.append(i)
        elif char == ']':
            if stack:
                start_index = stack.pop()
                # å¦‚æœæ ˆç©ºäº†ï¼Œè¯´æ˜é—­åˆäº†ä¸€ä¸ªæœ€å¤–å±‚çš„åˆ—è¡¨
                if not stack:
                    candidate = text[start_index : i+1]
                    candidates.append(candidate)
    
    if not candidates:
        return None
    
    # è¿”å›æœ€é•¿çš„é‚£ä¸ªå€™é€‰å­—ç¬¦ä¸²ï¼ˆHistory è‚¯å®šæ˜¯æœ€é•¿çš„ï¼‰
    return max(candidates, key=len)


# ğŸ”¥ V4ç‰ˆæœ¬ï¼šæå…¶å®½å®¹çš„historyè§£æå™¨
def safe_eval_history(hist_str: str) -> List:
    """
    æå…¶å®½å®¹çš„è§£æå™¨ï¼Œå°è¯•å¤šç§æ–¹æ³•å°†å­—ç¬¦ä¸²è½¬ä¸º List
    
    Args:
        hist_str: historyå­—ç¬¦ä¸²
        
    Returns:
        è§£æåçš„åˆ—è¡¨ï¼Œå¦‚æœå¤±è´¥è¿”å›ç©ºåˆ—è¡¨
    """
    if not hist_str or not isinstance(hist_str, str):
        return []
    
    hist_str = hist_str.strip()
    if not hist_str or hist_str.lower() in ['nan', 'none', 'null', '']:
        return []
    
    # 1. é¢„å¤„ç†ï¼šä¿®å¤ Python 3.12 åæ–œæ é—®é¢˜
    # å°†æ— æ•ˆè½¬ä¹‰åºåˆ—ä¿®å¤ï¼Œä½†ä¿ç•™æœ‰æ•ˆè½¬ä¹‰
    try:
        # ç®€å•æš´åŠ›çš„ä¿®å¤ï¼šæŠŠæ‰€æœ‰ \ å˜æˆ \\ï¼Œç„¶åå†æŠŠæœ‰æ•ˆè½¬ä¹‰å˜å›
        clean_str = hist_str.replace('\\', '\\\\')
        clean_str = clean_str.replace('\\\\n', '\\n').replace('\\\\t', '\\t')
        clean_str = clean_str.replace('\\\\r', '\\r').replace('\\\\b', '\\b')
        clean_str = clean_str.replace('\\\\f', '\\f')
        clean_str = clean_str.replace('\\\\"', '\\"').replace("\\\\'", "\\'")
        clean_str = clean_str.replace('\\\\\\\\', '\\\\')  # ä¿ç•™çœŸæ­£çš„åæ–œæ 
        return ast.literal_eval(clean_str)
    except:
        pass

    # 2. åŸå§‹å°è¯•
    try:
        return ast.literal_eval(hist_str)
    except:
        pass

    # 3. å°è¯• JSON
    try:
        return json.loads(hist_str)
    except:
        pass
    
    # 4. å°è¯•ä¿®å¤å¸¸è§çš„Python/JSONå·®å¼‚
    try:
        fixed_str = hist_str.replace('null', 'None').replace('true', 'True').replace('false', 'False')
        return ast.literal_eval(fixed_str)
    except:
        pass
    
    return []


# ğŸ”¥ V4ç‰ˆæœ¬ï¼šè§„èŒƒåŒ–historyå…ƒç´ 
def normalize_history_item(item: Any) -> Optional[Dict]:
    """
    å°† history ä¸­çš„å•é¡¹ï¼ˆå¯èƒ½æ˜¯ tuple, dict, æˆ– listï¼‰ç»Ÿä¸€è½¬ä¸º dict
    é˜²æ­¢ 'int' object has no attribute 'get' é”™è¯¯
    
    Args:
        item: historyä¸­çš„å•ä¸ªå…ƒç´ 
        
    Returns:
        è§„èŒƒåŒ–åçš„å­—å…¸ï¼Œå¦‚æœæ— æ³•è½¬æ¢è¿”å›None
    """
    # å¦‚æœæ˜¯int/float/boolç­‰åŸºæœ¬ç±»å‹ï¼Œç›´æ¥è¿”å›Noneï¼ˆæ— æ•ˆæ•°æ®ï¼‰
    if isinstance(item, (int, float, bool, type(None))):
        return None
    
    if isinstance(item, dict):
        # å¿…é¡»åŒ…å« content å’Œ agent/name/role
        result = dict(item)  # å¤åˆ¶å­—å…¸
        
        # ç¡®ä¿æœ‰contentå­—æ®µ
        if 'content' not in result:
            result['content'] = result.get('message', result.get('text', ''))
        
        # ç¡®ä¿æœ‰agent/nameå­—æ®µ
        if 'agent' not in result and 'name' not in result:
            result['agent'] = result.get('role', 'Unknown')
            result['name'] = result.get('agent', 'Unknown')
        elif 'agent' not in result:
            result['agent'] = result.get('name', result.get('role', 'Unknown'))
        elif 'name' not in result:
            result['name'] = result.get('agent', result.get('role', 'Unknown'))
        
        # ç¡®ä¿æœ‰roleå­—æ®µ
        if 'role' not in result:
            result['role'] = result.get('agent', result.get('name', 'assistant'))
        
        return result
    
    if isinstance(item, (list, tuple)):
        # å¤„ç†å…ƒç»„æ ¼å¼: (Content, Agent, Role, Step)
        # æˆ–è€…æ˜¯: (Content, Agent)
        if len(item) >= 2:
            return {
                'content': str(item[0]) if len(item) > 0 else '',
                'agent': str(item[1]) if len(item) > 1 else 'Unknown',
                'name': str(item[1]) if len(item) > 1 else 'Unknown',
                'role': str(item[2]) if len(item) > 2 else 'assistant',
                'step': item[3] if len(item) > 3 else 0
            }
    
    # å…¶ä»–ç±»å‹ï¼ˆå¦‚å­—ç¬¦ä¸²ï¼‰å°è¯•åŒ…è£…ä¸ºå­—å…¸
    if isinstance(item, str):
        return {
            'content': item,
            'agent': 'Unknown',
            'name': 'Unknown',
            'role': 'assistant',
            'step': 0
        }
    
    return None


# ğŸ”¥ å…³é”®ä¿®å¤ï¼šå¢å¼ºçš„Historyè§£æå‡½æ•°
def clean_and_parse_history(history_str: str) -> List:
    """
    å¼ºå¤§çš„ History å­—ç¬¦ä¸²æ¸…æ´—ä¸è§£æå‡½æ•°
    é’ˆå¯¹åŒ…å«ä»£ç ã€åæ–œæ ã€æˆªæ–­çš„è„æ•°æ®è¿›è¡Œä¿®å¤
    """
    if not isinstance(history_str, str):
        return []
        
    history_str = history_str.strip()
    if not history_str or history_str.lower() in ['nan', 'none', 'null', '']:
        return []

    # 1. å°è¯•ç›´æ¥è§£æ
    try:
        return ast.literal_eval(history_str)
    except:
        pass

    # 2. ä¿®å¤æ— æ•ˆè½¬ä¹‰ (Invalid Escape Sequences)
    # Python 3.12+ å¯¹åæ–œæ è½¬ä¹‰éå¸¸ä¸¥æ ¼ï¼Œéœ€è¦ä¿®å¤æ— æ•ˆè½¬ä¹‰
    try:
        # ä½¿ç”¨åŸå§‹å­—ç¬¦ä¸²å¤„ç†ï¼Œé¿å…è½¬ä¹‰é—®é¢˜
        # å…ˆå°è¯•ç›´æ¥è§£æï¼ˆå¯èƒ½å·²ç»æ˜¯æ­£ç¡®çš„ï¼‰
        return ast.literal_eval(history_str)
    except SyntaxError:
        # å¦‚æœæœ‰è¯­æ³•é”™è¯¯ï¼Œå°è¯•ä¿®å¤è½¬ä¹‰
        try:
            # å°†æ— æ•ˆè½¬ä¹‰åºåˆ—ä¿®å¤ï¼š\( -> \\(, \[ -> \\[, \` -> \\`, \l -> \\l
            # ä½†ä¿ç•™æœ‰æ•ˆè½¬ä¹‰ï¼š\n, \t, \r, \b, \f, \\, \', \"
            fixed_str = history_str
            # æ›¿æ¢æ— æ•ˆè½¬ä¹‰ï¼ˆä½†ä¿ç•™æœ‰æ•ˆè½¬ä¹‰ï¼‰
            # è¿™æ˜¯ä¸€ä¸ªä¿å®ˆçš„ä¿®å¤ï¼šåªä¿®å¤æ˜æ˜¾æ— æ•ˆçš„è½¬ä¹‰
            invalid_escapes = [r'\(', r'\)', r'\[', r'\]', r'\{', r'\}', r'\`', r'\l', r'\ ', r'\#']
            for esc in invalid_escapes:
                fixed_str = fixed_str.replace(esc, '\\\\' + esc[1:])
            
            return ast.literal_eval(fixed_str)
        except:
            pass
    except:
        pass

    # 3. å¤„ç† Python/JSON å…³é”®å­—å·®å¼‚
    try:
        # æ›¿æ¢ null -> None, true -> True, false -> False
        fixed_str = history_str.replace('null', 'None').replace('true', 'True').replace('false', 'False')
        return ast.literal_eval(fixed_str)
    except:
        pass

    # 4. ç»ˆææ–¹æ¡ˆï¼šå¦‚æœæ˜¯å› ä¸º CSV è¯»å–æˆªæ–­å¯¼è‡´æœ«å°¾ç¼ºå°‘ç¬¦å·
    # å°è¯•è¡¥å…¨åˆ—è¡¨å’Œå…ƒç»„çš„é—­åˆæ‹¬å·
    try:
        fixed_str = history_str
        open_brackets = fixed_str.count('[') - fixed_str.count(']')
        open_parens = fixed_str.count('(') - fixed_str.count(')')
        open_quotes_single = fixed_str.count("'") % 2
        open_quotes_double = fixed_str.count('"') % 2
        
        # ç²—æš´è¡¥å…¨ï¼ˆä»…ä½œå°è¯•ï¼‰
        if open_quotes_single: fixed_str += "'"
        if open_quotes_double: fixed_str += '"'
        if open_parens > 0: fixed_str += ')' * open_parens
        if open_brackets > 0: fixed_str += ']' * open_brackets
        
        return ast.literal_eval(fixed_str)
    except:
        pass

    # 5. å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œä¸”å­—ç¬¦ä¸²çœ‹èµ·æ¥åƒåˆ—è¡¨ï¼Œå°è¯•æ‰‹åŠ¨æ­£åˆ™æå–
    # é’ˆå¯¹ [('content', 'agent', ...), ...] ç»“æ„
    try:
        items = []
        # è¿™æ˜¯ä¸€ä¸ªæå…¶ç®€åŒ–çš„æ­£åˆ™ï¼Œå‡è®¾å…ƒç»„ç»“æ„æ¯”è¾ƒæ ‡å‡†
        # åŒ¹é… ('...', '...', '...', int)
        pattern = re.compile(r"\((?:'|\")(.*?)(?:'|\"),\s*(?:'|\")(.*?)(?:'|\"),\s*(?:'|\")(.*?)(?:'|\"),\s*(\d+)\)")
        matches = pattern.findall(history_str)
        for m in matches:
            items.append((m[0], m[1], m[2], int(m[3])))
        
        if items:
            return items
    except:
        pass

    # å½»åº•æ”¾å¼ƒï¼ŒæŠ›å‡ºå¼‚å¸¸
    raise ValueError(f"æ— æ³•è§£æhistory: {history_str[:100]}...")


def extract_trajectory_info(trajectory: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    ä»AgenTracerçš„trajectoryä¸­æå–ä¿¡æ¯
    
    Args:
        trajectory: AgenTraceræ ¼å¼çš„trajectoryåˆ—è¡¨
        
    Returns:
        {
            'history': å†å²äº‹ä»¶åˆ—è¡¨,
            'agents': Agentåˆ—è¡¨,
            'steps': Stepåˆ—è¡¨
        }
    """
    history = []
    agents = set()
    steps = []
    
    for idx, event in enumerate(trajectory):
        # æå–Agentä¿¡æ¯
        agent = event.get('agent', event.get('role', event.get('name', '')))
        if agent:
            agents.add(agent)
        
        # æå–Stepä¿¡æ¯
        step = event.get('step', event.get('step_id', idx))
        steps.append(step)
        
        # æ„å»ºå†å²äº‹ä»¶
        history.append({
            'step': step,
            'agent': agent,
            'content': event.get('content', event.get('message', '')),
            'action': event.get('action', ''),
            'timestamp': idx
        })
    
    return {
        'history': history,
        'agents': list(agents),
        'steps': steps
    }


def convert_tracertraj_to_graph(
    sample: Dict[str, Any],
    output_dir: Path,
    sample_id: str,
    domain: str
) -> Optional[str]:
    """
    å°†å•ä¸ªTracerTrajæ ·æœ¬è½¬æ¢ä¸ºHeteroGraph JSONæ ¼å¼
    
    ğŸ”¥ å…³é”®ä¿®å¤ï¼šAgenTracerä½¿ç”¨ 'history' å­—æ®µè€Œä¸æ˜¯ 'trajectory'
    
    Args:
        sample: TracerTrajæ ·æœ¬ï¼ˆåŒ…å«history, mistake_agent, mistake_stepç­‰ï¼‰
        output_dir: è¾“å‡ºç›®å½•
        sample_id: æ ·æœ¬ID
        domain: é¢†åŸŸæ ‡ç­¾ï¼ˆCode/Math/Agenticï¼‰
        
    Returns:
        è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    """
    try:
        # 1. æå–historyä¿¡æ¯ï¼ˆAgenTracerä½¿ç”¨historyå­—æ®µï¼Œä¸æ˜¯trajectoryï¼‰
        # ğŸ”¥ æ³¨æ„ï¼šhistoryåœ¨process_parquet_fileä¸­å·²ç»è§£æå¹¶è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        # è¿™é‡Œç›´æ¥ä½¿ç”¨å³å¯
        history = sample.get('history', sample.get('trajectory', []))
        
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šä¸¥æ ¼æ£€æŸ¥historyç±»å‹ï¼Œå¦‚æœæ˜¯int/floatç±»å‹ï¼ˆé”™è¯¯æ•°æ®ï¼‰ï¼Œç›´æ¥è¿”å›None
        if isinstance(history, (int, float)):
            print(f"   [è­¦å‘Š] æ ·æœ¬ {sample_id}: historyæ˜¯æ•°å­—ç±»å‹ï¼ˆå¯èƒ½æ˜¯é”™è¯¯æ•°æ®ï¼‰ï¼Œè·³è¿‡")
            return None
        
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šå¤„ç†numpy ndarrayç±»å‹
        import numpy as np
        if isinstance(history, np.ndarray):
            history = history.tolist()
        elif not isinstance(history, (list, tuple)):
            # å¦‚æœä¸æ˜¯åˆ—è¡¨æˆ–å…ƒç»„ï¼Œä¸”ä¸æ˜¯Noneï¼Œè¯´æ˜æ ¼å¼é”™è¯¯
            if history is not None:
                print(f"   [è­¦å‘Š] æ ·æœ¬ {sample_id}: historyä¸æ˜¯åˆ—è¡¨/å…ƒç»„ç±»å‹: {type(history)}ï¼Œè·³è¿‡")
            return None
        
        if not history:
            return None
        
        # ğŸ”¥ V4ç‰ˆæœ¬ï¼šè§„èŒƒåŒ–historyä¸­çš„æ¯ä¸ªå…ƒç´ ï¼Œç¡®ä¿éƒ½æ˜¯å­—å…¸æ ¼å¼
        # è¿™æ˜¯é˜²æ­¢ 'int' object has no attribute 'get' é”™è¯¯çš„å…³é”®æ­¥éª¤
        valid_history = []
        for item in history:
            norm_item = normalize_history_item(item)
            if norm_item:  # åªä¿ç•™æœ‰æ•ˆé¡¹ï¼ˆè·³è¿‡int/float/boolç­‰æ— æ•ˆæ•°æ®ï¼‰
                valid_history.append(norm_item)
        
        if not valid_history:
            print(f"   [è­¦å‘Š] æ ·æœ¬ {sample_id}: historyä¸­æ‰€æœ‰å…ƒç´ éƒ½æ˜¯æ— æ•ˆç±»å‹ï¼Œè·³è¿‡")
            return None
        
        history = valid_history
        
        # 2. æ„å»ºground_truth
        mistake_agent = sample.get('mistake_agent', sample.get('who', None))
        mistake_step = sample.get('mistake_step', sample.get('when', None))
        
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šmistake_stepå¯èƒ½æ˜¯å­—ç¬¦ä¸²ï¼Œéœ€è¦è½¬æ¢ä¸ºæ•´æ•°
        if mistake_step is not None:
            try:
                mistake_step = int(mistake_step)
            except (ValueError, TypeError):
                # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œå°è¯•ä»å­—ç¬¦ä¸²ä¸­æå–æ•°å­—
                if isinstance(mistake_step, str):
                    import re
                    match = re.search(r'\d+', str(mistake_step))
                    if match:
                        mistake_step = int(match.group())
                    else:
                        mistake_step = -1
                else:
                    mistake_step = -1
        
        # 4. ä½¿ç”¨æˆ‘ä»¬çš„è§£æå™¨æ„å»ºå›¾
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šAgenTracerçš„historyå­—æ®µå·²ç»è§„èŒƒåŒ–ï¼Œç¡®ä¿éƒ½æ˜¯å­—å…¸æ ¼å¼
        
        # æ„å»ºç¬¦åˆæˆ‘ä»¬æ ¼å¼çš„JSONæ•°æ®
        json_data = {
            'question': sample.get('question', sample.get('task', '')),
            'mistake_agent': mistake_agent or '',
            'mistake_step': mistake_step if mistake_step is not None else -1,
            'mistake_reason': sample.get('mistake_reason', ''),
            'ground_truth': {
                'mistake_agent': mistake_agent or '',
                'mistake_step': mistake_step if mistake_step is not None else -1,
                'mistake_reason': sample.get('mistake_reason', '')
            },
            'history': history  # ğŸ”¥ ä½¿ç”¨è§„èŒƒåŒ–åçš„historyï¼ˆç¡®ä¿æ¯ä¸ªå…ƒç´ éƒ½æ˜¯å­—å…¸ï¼‰
        }
        
        # ä½¿ç”¨MainParserè§£æï¼ˆè¿™æ˜¯æˆ‘ä»¬çš„ä¸»è§£æå‡½æ•°ï¼‰
        if HAS_MAIN_PARSER:
            try:
                # ğŸ”¥ æ·»åŠ è¿›åº¦æç¤ºï¼ˆCPUæ¨¡å¼ä¸‹embeddingè®¡ç®—ä¼šå¾ˆæ…¢ï¼‰
                import os
                import sys
                if os.getenv("FORCE_CPU", "").lower() in ["true", "1", "yes"]:
                    print(f"   [æç¤º] CPUæ¨¡å¼ï¼šæ­£åœ¨è§£æå›¾ï¼ˆæ„å»ºèŠ‚ç‚¹å’Œè¾¹ï¼‰...", flush=True)
                    sys.stdout.flush()
                    print(f"   [æç¤º] æ¥ä¸‹æ¥å°†è®¡ç®—èŠ‚ç‚¹embeddingï¼ˆæ¯ä¸ªèŠ‚ç‚¹çº¦10-30ç§’ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼‰...", flush=True)
                    sys.stdout.flush()
                else:
                    print(f"   [æç¤º] æ­£åœ¨è§£æå›¾...", flush=True)
                    sys.stdout.flush()
                graph = MainParser(json_data)
                if graph is not None:
                    if os.getenv("FORCE_CPU", "").lower() in ["true", "1", "yes"]:
                        print(f"   [æˆåŠŸ] å›¾è§£æå®Œæˆï¼š{len(graph.nodes)} ä¸ªèŠ‚ç‚¹ï¼Œ{len(graph.edges)} æ¡è¾¹")
                    else:
                        print(f"   [æˆåŠŸ] å›¾è§£æå®Œæˆï¼š{len(graph.nodes)} ä¸ªèŠ‚ç‚¹ï¼Œ{len(graph.edges)} æ¡è¾¹")
            except Exception as e:
                print(f"   [è­¦å‘Š] MainParserè§£æå¤±è´¥ {sample_id}: {e}")
                import traceback
                if "è½¬æ¢å¤±è´¥" not in str(e):  # é¿å…é‡å¤æ‰“å°
                    traceback.print_exc()
                return None
        elif HAS_MAIN_PARSER is False:
            # å¦‚æœMainParserä¸å­˜åœ¨ï¼Œå°è¯•ä½¿ç”¨parse_log_to_dynamic_graph
            try:
                # ä»historyä¸­æå–agentsåˆ—è¡¨
                agents = set()
                for event in history:
                    agent = event.get('name') or event.get('role', '')
                    if agent:
                        agents.add(agent)
                
                graph = parse_log_to_dynamic_graph(
                    history=history,
                    agents=list(agents)
                )
            except Exception as e:
                print(f"   [è­¦å‘Š] parse_log_to_dynamic_graphå¤±è´¥ {sample_id}: {e}")
                return None
        else:
            print(f"   [é”™è¯¯] æ— æ³•å¯¼å…¥è§£æå™¨å‡½æ•°")
            return None
        
        if graph is None:
            return None
        
        # 4. æ„å»ºè¾“å‡ºJSONæ ¼å¼ï¼ˆä¸æˆ‘ä»¬çš„æ ¼å¼ä¸€è‡´ï¼‰
        output_graph = {
            'question': sample.get('question', sample.get('task', '')),
            'ground_truth': {
                'mistake_agent': mistake_agent,
                'mistake_step': mistake_step,
                'mistake_reason': sample.get('mistake_reason', '')
            },
            'domain': domain,  # ğŸ”¥ å…³é”®ï¼šä¿ç•™é¢†åŸŸæ ‡ç­¾
            'benchmark': sample.get('benchmark', sample.get('data_source', '')),
            'nodes': {},
            'edges': []
        }
        
        # 5. è½¬æ¢èŠ‚ç‚¹
        for node_id, node in graph.nodes.items():
            output_graph['nodes'][node_id] = {
                'type': node.type,
                'features': {}
            }
            
            # è½¬æ¢ç‰¹å¾ï¼ˆå¦‚æœæœ‰ï¼‰
            if hasattr(node, 'features'):
                for t, feat in node.features.items():
                    output_graph['nodes'][node_id]['features'][str(t)] = feat
        
        # 6. è½¬æ¢è¾¹
        for edge in graph.edges:
            output_graph['edges'].append({
                'source': edge.source,
                'target': edge.target,
                'type': edge.type,
                'timestamp': edge.timestamp
            })
        
        # 7. ä¿å­˜JSONæ–‡ä»¶
        output_file = output_dir / f"TracerTraj_{domain}_{sample_id}_graph.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output_graph, f, ensure_ascii=False, indent=2)
        
        return str(output_file)
        
    except Exception as e:
        print(f"[è­¦å‘Š] è½¬æ¢å¤±è´¥ {sample_id}: {e}")
        import traceback
        if "è½¬æ¢å¤±è´¥" not in str(e):  # é¿å…é‡å¤æ‰“å°
            traceback.print_exc()
        return None


def process_parquet_file(
    input_file: Path,
    output_dir: Path,
    domain: Optional[str] = None,
    split_type: Optional[str] = None,
    max_samples: Optional[int] = None
) -> Dict[str, int]:
    """
    å¤„ç†parquet/CSVæ–‡ä»¶ï¼Œè½¬æ¢ä¸ºgraph JSONæ ¼å¼
    
    ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ ¹æ®æ–‡ä»¶åè¯†åˆ«split_typeï¼ˆtrain/testï¼‰ï¼Œä¸è¿›è¡Œéšæœºåˆ’åˆ†
    ğŸ”¥ æ–°å¢ï¼šæ”¯æŒCSVæ ¼å¼çš„è®­ç»ƒé›†æ–‡ä»¶
    
    Args:
        input_file: è¾“å…¥parquet/CSVæ–‡ä»¶
        output_dir: è¾“å‡ºç›®å½•
        domain: é¢†åŸŸæ ‡ç­¾ï¼ˆå¦‚æœæ–‡ä»¶ä¸­æ²¡æœ‰ï¼‰
        split_type: åˆ’åˆ†ç±»å‹ï¼ˆtrain/testï¼‰ï¼Œå¦‚æœä¸ºNoneåˆ™ä»æ–‡ä»¶åæ¨æ–­
        max_samples: æœ€å¤§å¤„ç†æ ·æœ¬æ•°ï¼ˆNoneè¡¨ç¤ºå…¨éƒ¨ï¼‰
        
    Returns:
        {'success': æˆåŠŸæ•°, 'failed': å¤±è´¥æ•°}
    """
    print(f"[è¯»å–æ–‡ä»¶] {input_file}")
    
    # ğŸ”¥ å…³é”®ï¼šä»æ–‡ä»¶åæ¨æ–­split_typeï¼ˆå¦‚æœä¸æŒ‡å®šï¼‰
    if split_type is None:
        filename_lower = input_file.name.lower()
        if 'test' in filename_lower or 'val' in filename_lower:
            split_type = 'test'
        elif 'train' in filename_lower:
            split_type = 'train'
        else:
            # é»˜è®¤æƒ…å†µéœ€è¦ç”¨æˆ·ç¡®è®¤
            print(f"[è­¦å‘Š] æ— æ³•ä»æ–‡ä»¶åæ¨æ–­split_type: {input_file.name}")
            print(f"   å‡è®¾ä¸º 'train'ï¼Œå¦‚æœä¸æ˜¯è¯·æ‰‹åŠ¨æŒ‡å®š --split_type")
            split_type = 'train'
    
    print(f"   è¯†åˆ«ä¸º: {split_type} æ•°æ®é›†")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆæŒ‰split_typeåˆ†ç±»ï¼‰
    output_split_dir = output_dir / split_type
    output_split_dir.mkdir(parents=True, exist_ok=True)
    
    # ğŸ”¥ æ–°å¢ï¼šæ”¯æŒCSVæ ¼å¼ï¼ˆä½¿ç”¨ä¸‰æ˜æ²»è§£ææ³•ï¼‰
    file_ext = input_file.suffix.lower()
    try:
        if file_ext == '.csv':
            print(f"   [ä¿¡æ¯] æ£€æµ‹åˆ°CSVæ ¼å¼ï¼Œä½¿ç”¨ä¸‰æ˜æ²»è§£ææ³•è¯»å–...")
            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šCSVæ–‡ä»¶ä¸­çš„historyå­—æ®µåŒ…å«å¤§é‡é€—å·ï¼Œå¯¼è‡´pandasé”™è¯¯åˆ†å‰²
            # ä½¿ç”¨"ä¸‰æ˜æ²»è§£ææ³•"ï¼šç›´æ¥ä»æ–‡æœ¬è¡Œä¸­æå–historyï¼ˆç¬¬ä¸€ä¸ª[åˆ°æœ€åä¸€ä¸ª]ï¼‰
            
            # å°è¯•å¤šç§ç¼–ç 
            encodings = ['gbk', 'utf-8', 'gb2312', 'latin-1']
            raw_lines = None
            used_encoding = None
            
            for encoding in encodings:
                try:
                    print(f"   [å°è¯•] ç¼–ç : {encoding}")
                    with open(input_file, 'r', encoding=encoding, errors='replace') as f:
                        raw_lines = f.readlines()
                    used_encoding = encoding
                    print(f"   [æˆåŠŸ] ä½¿ç”¨ç¼–ç  {encoding} è¯»å–äº† {len(raw_lines)} è¡Œ")
                    break
                except (UnicodeDecodeError, UnicodeError) as e:
                    print(f"   [å¤±è´¥] ç¼–ç  {encoding} å¤±è´¥: {str(e)[:100]}")
                    continue
                except Exception as e:
                    print(f"   [å¤±è´¥] ç¼–ç  {encoding} è¯»å–å¤±è´¥: {str(e)[:100]}")
                    continue
            
            if raw_lines is None:
                raise ValueError(f"æ— æ³•ä½¿ç”¨ä»»ä½•ç¼–ç è¯»å–CSVæ–‡ä»¶ã€‚")
            
            # ğŸ”¥ V4ç‰ˆæœ¬ï¼šä½¿ç”¨æœ€å¤§åˆ—è¡¨æå–æ³•ä»æ¯è¡Œä¸­æå–å­—æ®µ
            data_list = []
            header_skipped = False
            
            for line_idx, line in enumerate(raw_lines):
                line = line.strip()
                if not line:
                    continue
                
                # è·³è¿‡è¡¨å¤´
                if not header_skipped:
                    if 'question' in line.lower() and 'history' in line.lower():
                        header_skipped = True
                        continue
                    header_skipped = True
                
                # ğŸ”¥ V4ç‰ˆæœ¬ï¼šä½¿ç”¨æœ€å¤§åˆ—è¡¨æå–æ³•æå–history
                history_str = extract_longest_list_string(line)
                
                if not history_str:
                    # å¦‚æœæå–ä¸åˆ°historyï¼Œå°è¯•ä½¿ç”¨æ—§çš„ä¸‰æ˜æ²»è§£ææ³•
                    parsed = sandwich_parse_csv_line(line)
                    if parsed:
                        data_list.append(parsed)
                    continue
                
                # è§£æhistory
                history_list = safe_eval_history(history_str)
                
                if not history_list or not isinstance(history_list, list):
                    # è§£æå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æ—§æ–¹æ³•
                    parsed = sandwich_parse_csv_line(line)
                    if parsed:
                        data_list.append(parsed)
                    continue
                
                # ğŸ”¥ V4ç‰ˆæœ¬ï¼šè§„èŒƒåŒ–historyå…ƒç´ ï¼ˆé˜²æ­¢int/boolç±»å‹ï¼‰
                valid_history = []
                for item in history_list:
                    norm_item = normalize_history_item(item)
                    if norm_item:
                        valid_history.append(norm_item)
                
                if not valid_history:
                    # æ‰€æœ‰å…ƒç´ éƒ½æ— æ•ˆï¼Œè·³è¿‡
                    continue
                
                # æå–å…¶ä»–å­—æ®µï¼ˆä»lineä¸­ç§»é™¤history_strï¼Œå‰©ä¸‹çš„éƒ¨åˆ†ç”¨é€—å·åˆ†å‰²ï¼‰
                remaining = line.replace(history_str, '')
                parts = [p.strip() for p in remaining.split(',') if p.strip()]
                
                # å¯å‘å¼æå–ï¼šQuestioné€šå¸¸åœ¨æœ€å‰é¢ï¼ŒMistake Stepé€šå¸¸åœ¨æœ€åé¢ä¸”æ˜¯æ•°å­—
                question = parts[0] if parts else "Unknown Task"
                mistake_step = -1
                mistake_agent = "Unknown"
                
                if len(parts) >= 2:
                    # å°è¯•æ‰¾æœ€åçš„æ•°å­—ä½œä¸ºstep
                    try:
                        mistake_step = int(float(parts[-1]))
                        mistake_agent = parts[-2] if len(parts) >= 2 else "Unknown"
                    except:
                        pass
                
                # æ„å»ºæ ·æœ¬æ•°æ®
                parsed = {
                    'question': question,
                    'ground_truth': '',  # ground_truthå­—æ®µå¯èƒ½ä¹ŸåŒ…å«é€—å·ï¼Œæš‚æ—¶å¿½ç•¥
                    'history': valid_history,  # ä½¿ç”¨è§„èŒƒåŒ–åçš„history
                    'mistake_agent': mistake_agent,
                    'mistake_step': mistake_step
                }
                
                if parsed:
                    data_list.append(parsed)
            
            if not data_list:
                raise ValueError(f"æœªèƒ½ä»CSVæ–‡ä»¶ä¸­è§£æå‡ºä»»ä½•æœ‰æ•ˆæ•°æ®ã€‚")
            
            # è½¬æ¢ä¸ºDataFrame
            df = pd.DataFrame(data_list)
            print(f"   [ä¿¡æ¯] æˆåŠŸè§£æ {len(df)} è¡Œæ•°æ®")
            print(f"   [ä¿¡æ¯] æœ‰æ•ˆåˆ—: {list(df.columns)}")
            
        elif file_ext == '.parquet':
            df = pd.read_parquet(input_file)
        else:
            # å°è¯•è¯»å–JSONLæ ¼å¼
            print(f"   [ä¿¡æ¯] å°è¯•è¯»å–JSONLæ ¼å¼...")
            df = pd.read_json(input_file, lines=True)
    except Exception as e:
        print(f"   [è­¦å‘Š] è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        print(f"   å°è¯•å…¶ä»–æ ¼å¼...")
        try:
            if file_ext != '.csv':
                # å¯¹äºéCSVæ–‡ä»¶ï¼Œä¹Ÿå°è¯•å¤šç§ç¼–ç 
                encodings = ['utf-8', 'gbk', 'gb2312', 'latin-1']
                df = None
                for encoding in encodings:
                    try:
                        df = pd.read_csv(input_file, low_memory=False, encoding=encoding)
                        break
                    except:
                        continue
                if df is None:
                    raise e
            else:
                raise e
        except Exception as e2:
            print(f"   [é”™è¯¯] æ‰€æœ‰æ ¼å¼è¯»å–éƒ½å¤±è´¥: {e2}")
            import traceback
            traceback.print_exc()
            return {'success': 0, 'failed': 0}
    
    if max_samples:
        df = df.head(max_samples)
    
    print(f"   æ‰¾åˆ° {len(df)} ä¸ªæ ·æœ¬")
    
    # ğŸ”¥ è°ƒè¯•ï¼šæ‰“å°å‰å‡ ä¸ªæ ·æœ¬çš„ç»“æ„
    if len(df) > 0:
        print(f"   [æ ·æœ¬å­—æ®µ] {df.columns.tolist()}")
        first_row = df.iloc[0].to_dict()
        print(f"   [ç¬¬ä¸€ä¸ªæ ·æœ¬çš„é”®] {list(first_row.keys())[:10]}...")
        if 'history' in first_row:
            hist = first_row['history']
            import numpy as np
            if isinstance(hist, np.ndarray):
                hist = hist.tolist()
            print(f"   [historyç±»å‹] {type(first_row['history'])}, è½¬æ¢åé•¿åº¦: {len(hist) if isinstance(hist, list) else 'N/A'}")
    
    success_count = 0
    failed_count = 0
    
    # å¤„ç†æ¯ä¸ªæ ·æœ¬
    for idx, row in tqdm(df.iterrows(), total=len(df), desc="è½¬æ¢æ ·æœ¬"):
        try:
            # è½¬æ¢ä¸ºå­—å…¸
            sample = row.to_dict()
            
            # æå–domainï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            sample_domain = sample.get('domain', sample.get('benchmark', domain))
            if not sample_domain:
                # å°è¯•ä»data_sourceæ¨æ–­
                data_source = sample.get('data_source', '')
                filename_lower = input_file.name.lower()
                if 'code' in filename_lower or 'kodcode' in data_source.lower() or 'mbpp' in data_source.lower():
                    sample_domain = 'Code'
                elif 'math' in filename_lower or 'math' in data_source.lower() or 'gsm8k' in data_source.lower():
                    sample_domain = 'Math'
                elif 'agentic' in filename_lower or 'gaia' in filename_lower or 'gaia' in data_source.lower() or 'hotpot' in data_source.lower():
                    sample_domain = 'Agentic'
                else:
                    sample_domain = 'Unknown'
            
            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ£€æŸ¥historyå­—æ®µï¼ˆAgenTracerä½¿ç”¨historyè€Œä¸æ˜¯trajectoryï¼‰
            # ğŸ”¥ CSVæ ¼å¼ï¼šhistoryå¯èƒ½æ˜¯å­—ç¬¦ä¸²ï¼ˆJSONæ ¼å¼æˆ–Python repræ ¼å¼ï¼‰ï¼Œéœ€è¦è§£æ
            history = sample.get('history', sample.get('trajectory', []))
            
            # ğŸ”¥ ä¿®å¤ï¼šå¤„ç†å„ç§ç±»å‹çš„historyå­—æ®µ
            if history is None or (isinstance(history, float) and pd.isna(history)):
                if failed_count < 3:
                    print(f"   [è­¦å‘Š] æ ·æœ¬ {idx} historyä¸ºNoneæˆ–NaNï¼Œè·³è¿‡")
                failed_count += 1
                continue
            
            # å¤„ç†å­—ç¬¦ä¸²æ ¼å¼çš„historyï¼ˆCSVä¸­å¯èƒ½æ˜¯JSONå­—ç¬¦ä¸²æˆ–Python reprï¼‰
            if isinstance(history, str):
                history_str = history.strip()
                if not history_str or history_str.lower() in ['nan', 'none', 'null', '']:
                    if failed_count < 3:
                        print(f"   [è­¦å‘Š] æ ·æœ¬ {idx} historyå­—ç¬¦ä¸²ä¸ºç©ºï¼Œè·³è¿‡")
                    failed_count += 1
                    continue
                
                # ğŸ”¥ å…³é”®ä¿®å¤ï¼šä½¿ç”¨å¢å¼ºçš„è§£æå‡½æ•°
                try:
                    history = clean_and_parse_history(history_str)
                except ValueError as e:
                    if failed_count < 3:
                        print(f"   [è­¦å‘Š] æ ·æœ¬ {idx} historyè§£æå¤±è´¥: {str(e)[:100]}")
                    failed_count += 1
                    continue
            
            # å¤„ç†numpy ndarrayç±»å‹
            import numpy as np
            if isinstance(history, np.ndarray):
                history = history.tolist()
            
            # ğŸ”¥ ä¿®å¤ï¼šå¤„ç†int/floatç±»å‹ï¼ˆå¯èƒ½æ˜¯é”™è¯¯çš„æ•°æ®ï¼‰
            if isinstance(history, (int, float)):
                if failed_count < 3:
                    print(f"   [è­¦å‘Š] æ ·æœ¬ {idx} historyæ˜¯æ•°å­—ç±»å‹ï¼ˆå¯èƒ½æ˜¯é”™è¯¯æ•°æ®ï¼‰: {history}")
                failed_count += 1
                continue
            
            # ğŸ”¥ ä¿®å¤ï¼šæ£€æŸ¥historyæ˜¯å¦ä¸ºæœ‰æ•ˆåˆ—è¡¨æˆ–å…ƒç»„
            if not isinstance(history, (list, tuple)):
                if failed_count < 3:
                    print(f"   [è­¦å‘Š] æ ·æœ¬ {idx} historyä¸æ˜¯åˆ—è¡¨/å…ƒç»„ç±»å‹: {type(history)}")
                failed_count += 1
                continue
            
            # ğŸ”¥ V4ç‰ˆæœ¬ï¼šè§„èŒƒåŒ–historyä¸­çš„æ‰€æœ‰å…ƒç´ ï¼ˆç»Ÿä¸€ä½¿ç”¨normalize_history_itemï¼‰
            # è¿™èƒ½é˜²æ­¢int/boolç­‰æ— æ•ˆç±»å‹å¯¼è‡´MainParserå´©æºƒ
            valid_history = []
            for item in history:
                norm_item = normalize_history_item(item)
                if norm_item:  # åªä¿ç•™æœ‰æ•ˆé¡¹ï¼ˆè·³è¿‡int/float/boolç­‰æ— æ•ˆæ•°æ®ï¼‰
                    valid_history.append(norm_item)
            
            if not valid_history:
                if failed_count < 3:
                    print(f"   [è­¦å‘Š] æ ·æœ¬ {idx} historyä¸­æ‰€æœ‰å…ƒç´ éƒ½æ˜¯æ— æ•ˆç±»å‹ï¼Œè·³è¿‡")
                failed_count += 1
                continue
            
            history = valid_history
            
            # æ£€æŸ¥historyæ˜¯å¦ä¸ºç©º
            if len(history) == 0:
                if failed_count < 3:
                    print(f"   [è­¦å‘Š] æ ·æœ¬ {idx} historyä¸ºç©ºåˆ—è¡¨ï¼Œè·³è¿‡")
                failed_count += 1
                continue
            
            # è·å–æ ·æœ¬IDï¼ˆAgenTracerä½¿ç”¨question_IDï¼ŒCSVå¯èƒ½ä½¿ç”¨questionä½œä¸ºIDï¼‰
            sample_id = sample.get('question_ID', sample.get('task_id', sample.get('id', sample.get('idx', None))))
            # ğŸ”¥ CSVæ ¼å¼ï¼šå¦‚æœæ²¡æœ‰question_IDï¼Œä½¿ç”¨questionçš„å‰50ä¸ªå­—ç¬¦ä½œä¸ºID
            if sample_id is None:
                question = sample.get('question', '')
                if question:
                    # ä½¿ç”¨questionçš„å‰50ä¸ªå­—ç¬¦ä½œä¸ºIDï¼ˆå»é™¤ç‰¹æ®Šå­—ç¬¦ï¼‰
                    import re
                    sample_id = re.sub(r'[^\w-]', '_', question[:50])
                else:
                    sample_id = f'sample_{idx}'
            
            # è½¬æ¢ï¼ˆè¾“å‡ºåˆ°split_typeç›®å½•ï¼‰
            output_file = convert_tracertraj_to_graph(
                sample=sample,
                output_dir=output_split_dir,  # ğŸ”¥ å…³é”®ï¼šè¾“å‡ºåˆ°split_typeç›®å½•
                sample_id=str(sample_id),
                domain=sample_domain
            )
            
            if output_file:
                success_count += 1
                if success_count <= 3:  # å‰3ä¸ªæˆåŠŸæ—¶æ‰“å°
                    print(f"   [æˆåŠŸ] è½¬æ¢æ ·æœ¬ {idx}: {output_file}")
            else:
                failed_count += 1
                if failed_count <= 3:  # å‰3ä¸ªå¤±è´¥æ—¶æ‰“å°è¯¦ç»†é”™è¯¯
                    print(f"   [é”™è¯¯] è½¬æ¢å¤±è´¥æ ·æœ¬ {idx} (sample_id={sample_id})")
        except Exception as e:
            print(f"   [è­¦å‘Š] å¤„ç†æ ·æœ¬ {idx} æ—¶å¼‚å¸¸: {e}")
            import traceback
            if failed_count < 3:  # åªæ‰“å°å‰3ä¸ªå¼‚å¸¸çš„è¯¦ç»†traceback
                traceback.print_exc()
            failed_count += 1
            continue
    
    return {'success': success_count, 'failed': failed_count}


# ğŸ”¥ å…³é”®ä¿®å¤ï¼šç§»é™¤éšæœºåˆ’åˆ†é€»è¾‘
# AgenTracerä½¿ç”¨çš„æ˜¯å›ºå®šçš„å®˜æ–¹åˆ’åˆ†ï¼ˆé€šè¿‡æ–‡ä»¶åä¸­çš„train/testæ ‡è®°ï¼‰
# ç»å¯¹ä¸èƒ½è‡ªå·±éšæœºåˆ‡åˆ†ï¼Œå¦åˆ™ä¼šå¯¼è‡´ä¸å…¬å¹³å¯¹æ¯”


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="è½¬æ¢TracerTrajæ•°æ®é›†")
    parser.add_argument(
        "--input_file",
        type=str,
        required=True,
        help="è¾“å…¥parquet/CSVæ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        default="processed_graphs/graphs_tracertraj",
        help="è¾“å‡ºç›®å½•"
    )
    parser.add_argument(
        "--domain",
        type=str,
        default=None,
        help="é¢†åŸŸæ ‡ç­¾ï¼ˆCode/Math/Agenticï¼‰ï¼Œå¦‚æœä¸æŒ‡å®šä¼šä»æ•°æ®ä¸­æ¨æ–­"
    )
    parser.add_argument(
        "--max_samples",
        type=int,
        default=None,
        help="æœ€å¤§å¤„ç†æ ·æœ¬æ•°ï¼ˆNoneè¡¨ç¤ºå…¨éƒ¨ï¼‰"
    )
    parser.add_argument(
        "--split_type",
        type=str,
        default=None,
        choices=['train', 'test'],
        help="åˆ’åˆ†ç±»å‹ï¼ˆtrain/testï¼‰ã€‚å¦‚æœä¸ºNoneï¼Œåˆ™ä»æ–‡ä»¶åè‡ªåŠ¨æ¨æ–­ï¼ˆåŒ…å«'test'æˆ–'val'ä¸ºtestï¼Œå¦åˆ™ä¸ºtrainï¼‰"
    )
    
    args = parser.parse_args()
    
    # å¤„ç†æ–‡ä»¶
    input_file = Path(args.input_file)
    output_dir = Path(args.output_dir)
    
    if not input_file.exists():
        print(f"[é”™è¯¯] è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        exit(1)
    
    print("="*60)
    print("è½¬æ¢TracerTrajæ•°æ®é›†")
    print("="*60)
    print(f"è¾“å…¥æ–‡ä»¶: {input_file}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print()
    
    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ ¹æ®æ–‡ä»¶åè¯†åˆ«split_typeï¼Œä¸è¿›è¡Œéšæœºåˆ’åˆ†
    # è½¬æ¢
    stats = process_parquet_file(
        input_file=input_file,
        output_dir=output_dir,
        domain=args.domain,
        split_type=args.split_type,  # ğŸ”¥ ä¼ é€’split_typeå‚æ•°
        max_samples=args.max_samples
    )
    
    print()
    print("="*60)
    print("è½¬æ¢å®Œæˆ")
    print("="*60)
    print(f"æˆåŠŸ: {stats['success']}")
    print(f"å¤±è´¥: {stats['failed']}")
    print()
    
    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šç§»é™¤éšæœºåˆ’åˆ†é€»è¾‘
    # AgenTracerä½¿ç”¨çš„æ˜¯å›ºå®šçš„å®˜æ–¹åˆ’åˆ†ï¼Œå¿…é¡»å°Šé‡æ–‡ä»¶åä¸­çš„train/testæ ‡è®°
    if stats['success'] > 0:
        split_type = args.split_type
        if split_type is None:
            filename_lower = input_file.name.lower()
            if 'test' in filename_lower or 'val' in filename_lower:
                split_type = 'test'
            else:
                split_type = 'train'
        print(f"[æˆåŠŸ] æ•°æ®å·²ä¿å­˜åˆ°: {output_dir}/{split_type}/")
        print(f"   ï¼ˆå…± {stats['success']} ä¸ªæ–‡ä»¶ï¼‰")
    
    print()
    print("="*60)
    print("å®Œæˆ")
    print("="*60)

